{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "155663a3",
   "metadata": {},
   "source": [
    "# scVelo + PAGA notebook (cleaned)\n",
    "This notebook is a cleaned, runnable version of your original workflow."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4dcdd42b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === P1: imports, settings, constants, helpers =================================\n",
    "# This notebook runs a scVelo + PAGA workflow on planarian scRNA-seq:\n",
    "#  - merge loom files (spliced/unspliced)\n",
    "#  - attach Seurat-derived celltype labels + fixed Seurat UMAP coordinates\n",
    "#  - compute PCA/neighbors on a curated gene set (HVGs minus confounders + forced markers)\n",
    "#  - compute PAGA connectivities per (condition × timepoint), with bootstrap uncertainty\n",
    "#  - compute ELAC2-specific deltas: (KD - WT) - (GFP - WT)\n",
    "#  - run RNA velocity and derive a simple potency surrogate from latent time\n",
    "#  - plot PAGA graphs using a fixed template layout (Seurat UMAP centroids → FA2)\n",
    "\n",
    "from __future__ import annotations\n",
    "\n",
    "import os\n",
    "import re\n",
    "import math\n",
    "import gc\n",
    "from pathlib import Path\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.sparse as sp\n",
    "\n",
    "import scanpy as sc\n",
    "import anndata as ad\n",
    "import scvelo as scv\n",
    "import loompy\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# --- Jupyter-only niceties (safe no-op outside IPython) -----------------------\n",
    "try:\n",
    "    import IPython\n",
    "    if not hasattr(IPython.display, \"set_matplotlib_formats\"):\n",
    "        from matplotlib_inline.backend_inline import set_matplotlib_formats as _set_mpl_formats\n",
    "        IPython.display.set_matplotlib_formats = _set_mpl_formats\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# --- global plotting defaults ------------------------------------------------\n",
    "sc.settings.verbosity = 2\n",
    "sc.settings.set_figure_params(dpi=300, facecolor=\"white\", ipython_format=[\"png\"])\n",
    "sc.settings.file_format_figs = \"pdf\"\n",
    "scv.settings.set_figure_params(dpi_save=300, format=\"pdf\")\n",
    "\n",
    "# --- deterministic seed ------------------------------------------------------\n",
    "RND = 1337\n",
    "np.random.seed(RND)\n",
    "\n",
    "# --- folders -----------------------------------------------------------------\n",
    "CACHE = Path(\"cache\"); CACHE.mkdir(exist_ok=True)\n",
    "PLOTS = Path(\"plots\"); PLOTS.mkdir(exist_ok=True)\n",
    "sc.settings.figdir = str(PLOTS)\n",
    "\n",
    "# --- inputs (EDIT HERE) ------------------------------------------------------\n",
    "# Seurat-exported metadata with at least: barcode, celltype, UMAP1, UMAP2\n",
    "META_CSV = \"/mnt/d/scRNA-seq/AZ_final_obj/metadata_for_scvelo_final_final.csv\"\n",
    "\n",
    "# Loom files (spliced/unspliced). Keys are prefixes that become part of barcodes.\n",
    "LOOMS = {\n",
    "    \"wt0_\":    \"/mnt/d/scRNA-seq/loom_new_anno/W0_possorted_genome_bam_Q0IEG.loom\",\n",
    "    \"wt16_\":   \"/mnt/d/scRNA-seq/loom_new_anno/W16_possorted_genome_bam_HEHGJ.loom\",\n",
    "    \"wt24_\":   \"/mnt/d/scRNA-seq/loom_new_anno/W24_possorted_genome_bam_MUMHX.loom\",\n",
    "    \"wt72_\":   \"/mnt/d/scRNA-seq/loom_new_anno/W72_possorted_genome_bam_3VCHX.loom\",\n",
    "    \"gfp0_\":   \"/mnt/d/scRNA-seq/loom_new_anno/G0_possorted_genome_bam_SPQ1C.loom\",\n",
    "    \"gfp16_\":  \"/mnt/d/scRNA-seq/loom_new_anno/G16_possorted_genome_bam_6NW0I.loom\",\n",
    "    \"gfp24_\":  \"/mnt/d/scRNA-seq/loom_new_anno/G24_possorted_genome_bam_8AAIZ.loom\",\n",
    "    \"gfp72_\":  \"/mnt/d/scRNA-seq/loom_new_anno/G72_possorted_genome_bam_KS8Y2.loom\",\n",
    "    \"elac0_\":  \"/mnt/d/scRNA-seq/loom_new_anno/E0_possorted_genome_bam_J4ERS.loom\",\n",
    "    \"elac16_\": \"/mnt/d/scRNA-seq/loom_new_anno/E16_possorted_genome_bam_3AJSP.loom\",\n",
    "    \"elac24_\": \"/mnt/d/scRNA-seq/loom_new_anno/E24_possorted_genome_bam_KL9NW.loom\",\n",
    "    \"elac72_\": \"/mnt/d/scRNA-seq/loom_new_anno/E72_possorted_genome_bam_NT2B6.loom\",\n",
    "}\n",
    "\n",
    "TP_ORDER   = [\"0hpa\", \"16hpa\", \"24hpa\", \"72hpa\"]\n",
    "COND_ORDER = [\"WT\", \"GFP\", \"ELAC2 KD\"]\n",
    "\n",
    "# --- preprocessing constants --------------------------------------------------\n",
    "N_TOP_GENES       = 3000\n",
    "MIN_SHARED_COUNTS = 10\n",
    "\n",
    "# --- helpers -----------------------------------------------------------------\n",
    "def ensure_float32_layers(adx: ad.AnnData, layers=(\"spliced\", \"unspliced\")) -> None:\n",
    "    \"\"\"Force spliced/unspliced layers to float32 to reduce memory use.\"\"\"\n",
    "    for L in layers:\n",
    "        if L in adx.layers and hasattr(adx.layers[L], \"dtype\") and adx.layers[L].dtype != np.float32:\n",
    "            adx.layers[L] = adx.layers[L].astype(np.float32)\n",
    "\n",
    "def _norm_label(x: str) -> str:\n",
    "    \"\"\"Normalize labels: unify dash variants, strip extra whitespace.\"\"\"\n",
    "    if x is None or (isinstance(x, float) and math.isnan(x)):\n",
    "        return x\n",
    "    x = str(x)\n",
    "    x = re.sub(r\"[‐‒–—]\", \"–\", x)           # normalize dashes to en dash\n",
    "    x = re.sub(r\"[\\r\\t]+\", \" \", x)\n",
    "    x = re.sub(r\"\\s{2,}\", \" \", x).strip()\n",
    "    return x\n",
    "\n",
    "def derive_cond_time_from_barcode(adx: ad.AnnData) -> ad.AnnData:\n",
    "    \"\"\"Derive condition + timepoint from barcode prefixes (wt/gfp/elac + 0/16/24/72).\"\"\"\n",
    "    pref = adx.obs_names.to_series().str.extract(r\"^(wt|gfp|elac)(0|16|24|72)_\", expand=True)\n",
    "    adx.obs[\"cond\"] = pref[0].map({\"wt\": \"WT\", \"gfp\": \"GFP\", \"elac\": \"ELAC2 KD\"}).astype(\"category\")\n",
    "    adx.obs[\"timepoint\"] = pref[1].map({\"0\": \"0hpa\", \"16\": \"16hpa\", \"24\": \"24hpa\", \"72\": \"72hpa\"}).astype(\"category\")\n",
    "    adx.obs[\"cond\"] = adx.obs[\"cond\"].cat.set_categories(COND_ORDER, ordered=True)\n",
    "    adx.obs[\"timepoint\"] = adx.obs[\"timepoint\"].cat.set_categories(TP_ORDER, ordered=True)\n",
    "    return adx\n",
    "\n",
    "# --- celltype → family mapping (keep deterministic, no external deps) ---------\n",
    "import unicodedata\n",
    "\n",
    "def add_families_inplace(adx: ad.AnnData, source_key: str = \"celltype\", target_key: str = \"celltype_family\") -> ad.AnnData:\n",
    "    \"\"\"Map detailed celltype labels to broader celltype families.\"\"\"\n",
    "\n",
    "    def _canon(x: str) -> str:\n",
    "        x = \"\" if x is None else str(x)\n",
    "        x = x.replace(\"⁺\", \"+\").replace(\"–\", \"-\").replace(\"’\", \"'\")\n",
    "        x = unicodedata.normalize(\"NFKD\", x)\n",
    "        x = \"\".join(ch for ch in x if not unicodedata.combining(ch))\n",
    "        x = x.lower()\n",
    "        x = re.sub(r\"[\\s_\\-()/]+\", \"\", x)\n",
    "        return x\n",
    "\n",
    "    def family_label(lbl: str) -> str:\n",
    "        c = _canon(lbl)\n",
    "\n",
    "        # Neoblast subtypes (specific first)\n",
    "        if (\"σ\" in c) and (\"neoblast\" in c):            return \"σ-neoblast\"\n",
    "        if (\"ν\" in c) and (\"neoblast\" in c):            return \"ν-neoblast\"\n",
    "        if (\"ζ\" in c) and (\"neoblast\" in c):            return \"ζ-neoblast\"\n",
    "        if (\"γ\" in c) and (\"neoblast\" in c):            return \"γ-neoblast\"\n",
    "        if (\"pharyngeal\" in c) and (\"neoblast\" in c):   return \"Pharyngeal neoblast\"\n",
    "        if (\"muscle\" in c) and (\"neoblast\" in c):       return \"Muscle neoblast\"\n",
    "        if (\"protonephrid\" in c) and (\"neoblast\" in c): return \"Protonephridial neoblast\"\n",
    "        if (\"parenchymal\" in c) and (\"neoblast\" in c):  return \"Parenchymal neoblast\"\n",
    "        if (\"eye\" in c) and (\"neoblast\" in c):          return \"Eye neoblast\"\n",
    "\n",
    "        # Progenitors\n",
    "        if (\"epiderm\" in c) and (\"progenitor\" in c):    return \"Epidermal progenitor\"\n",
    "        if (\"eye\" in c) and (\"progenitor\" in c):        return \"Eye progenitor\"\n",
    "        if (\"pharyngeal\" in c) and (\"progenitor\" in c): return \"Pharyngeal progenitor\"\n",
    "        if (\"protonephrid\" in c) and (\"progenitor\" in c): return \"Protonephridial progenitor\"\n",
    "        if (\"parenchymal\" in c) and (\"progenitor\" in c):  return \"Parenchymal progenitor\"\n",
    "        if (\"neural\" in c) and (\"progenitor\" in c):     return \"Neural progenitor\"\n",
    "        if (\"pigment\" in c) and (\"progenitor\" in c):    return \"Pigment progenitor\"\n",
    "\n",
    "        # Pigment\n",
    "        if \"pigment\" in c:                              return \"Pigment\"\n",
    "\n",
    "        # Broad families\n",
    "        if any(k in c for k in [\"epidermis\", \"epidermal\"]): return \"Epidermis\"\n",
    "        if any(k in c for k in [\"photoreceptor\", \"cup\"]) or (\"eye\" in c): return \"Eye\"\n",
    "        if any(k in c for k in [\"neuron\", \"glia\", \"neural\"]): return \"Nervous system\"\n",
    "        if (\"pharyngeal\" in c) or (\"parapharyngeal\" in c): return \"Pharynx\"\n",
    "        if any(k in c for k in [\"muscle\", \"bwm\", \"pole\", \"pcg\", \"ecmproducing\"]): return \"Muscle\"\n",
    "        if \"protonephrid\" in c:                          return \"Protonephridia\"\n",
    "\n",
    "        if any(k in c for k in [\"intestine\", \"intestinal\", \"goblet\", \"phagocyte\", \"basal\"]): return \"Intestine\"\n",
    "        if any(k in c for k in [\"abracada\", \"abracadacell\"]): return \"Parenchyma\"\n",
    "        if \"parenchymal\" in c:                           return \"Parenchyma\"\n",
    "\n",
    "        return \"other\"\n",
    "\n",
    "    fam = adx.obs[source_key].astype(str).map(family_label)\n",
    "    adx.obs[target_key] = fam.astype(\"category\")\n",
    "    return adx\n",
    "\n",
    "# placeholders populated later (after neighbors are computed)\n",
    "GLOBAL_ADJ: sp.csr_matrix | None = None\n",
    "GLOBAL_DIST: sp.csr_matrix | None = None\n",
    "NEIGH_CONN_KEY: str | None = None\n",
    "NEIGH_DIST_KEY: str | None = None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19ee6367",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === P2: memory-safe loom loading ==========================================\n",
    "\n",
    "RAW = CACHE / \"adata_raw_loom_merged.h5ad\"\n",
    "\n",
    "CHUNK_COLS = 25000\n",
    "LAYER_SPLICED   = \"spliced\"\n",
    "LAYER_UNSPLICED = \"unspliced\"\n",
    "\n",
    "def _pick_first_key(d, candidates):\n",
    "    for k in candidates:\n",
    "        if k in d:\n",
    "            return k\n",
    "    raise KeyError(f\"None of the keys {candidates} found. Available: {list(d.keys())}\")\n",
    "\n",
    "def _fix_one_bc(bc: str) -> str:\n",
    "    bc = re.sub(\".*:\", \"\", bc)\n",
    "    bc = re.sub(\"x$\", \"\", bc)\n",
    "    bc = f\"{bc}-1\"\n",
    "    bc = re.sub(r\"-\\d+$\", \"-1\", bc)\n",
    "    return bc\n",
    "\n",
    "def _loom_genes(ds) -> np.ndarray:\n",
    "    key = _pick_first_key(ds.ra, [\"Gene\", \"GeneName\", \"gene\", \"Accession\"])\n",
    "    g = ds.ra[key].astype(str)\n",
    "    g = np.array([re.sub(r\"\\s+\", \"\", x) for x in g])\n",
    "    return g\n",
    "\n",
    "def _loom_barcodes(ds) -> np.ndarray:\n",
    "    key = _pick_first_key(ds.ca, [\"CellID\", \"cellid\", \"Barcode\", \"barcode\", \"obs_names\"])\n",
    "    return ds.ca[key].astype(str)\n",
    "\n",
    "def _prefixed_barcodes(raw_bcs: np.ndarray, prefix: str) -> np.ndarray:\n",
    "    fixed = np.array([prefix + _fix_one_bc(bc) for bc in raw_bcs], dtype=object)\n",
    "    return fixed\n",
    "\n",
    "def _read_layers(ds, cols: np.ndarray):\n",
    "    S = ds.layers[LAYER_SPLICED][:, cols]\n",
    "    U = ds.layers[LAYER_UNSPLICED][:, cols]\n",
    "    if not sp.issparse(S): S = sp.csc_matrix(S)\n",
    "    if not sp.issparse(U): U = sp.csc_matrix(U)\n",
    "    S = S.T.astype(np.float32, copy=False).tocsr()\n",
    "    U = U.T.astype(np.float32, copy=False).tocsr()\n",
    "    return S, U\n",
    "\n",
    "if RAW.exists():\n",
    "    adata = sc.read_h5ad(RAW)\n",
    "else:\n",
    "    meta = pd.read_csv(META_CSV, usecols=[\"barcode\"])\n",
    "    meta_bcs = (\n",
    "        meta[\"barcode\"].astype(str).str.strip()\n",
    "        .str.replace(\"–\", \"-\", regex=False)\n",
    "        .tolist()\n",
    "    )\n",
    "    meta_set = set(meta_bcs)\n",
    "    del meta\n",
    "\n",
    "    tmp_files = []\n",
    "\n",
    "    for prefix, path in LOOMS.items():\n",
    "        with loompy.connect(path, mode=\"r\") as ds:\n",
    "            genes    = _loom_genes(ds)\n",
    "            raw_bcs  = _loom_barcodes(ds)\n",
    "            prefixed = _prefixed_barcodes(raw_bcs, prefix)\n",
    "\n",
    "            keep_mask = np.fromiter((b in meta_set for b in prefixed),\n",
    "                                    dtype=bool, count=prefixed.size)\n",
    "            keep_idx = np.where(keep_mask)[0]\n",
    "            if keep_idx.size == 0:\n",
    "                continue\n",
    "\n",
    "            for start in range(0, keep_idx.size, CHUNK_COLS):\n",
    "                cols = keep_idx[start:start + CHUNK_COLS]\n",
    "                if cols.size == 0:\n",
    "                    continue\n",
    "\n",
    "                S, U = _read_layers(ds, cols)\n",
    "\n",
    "                obs_names = prefixed[cols]\n",
    "                var = pd.DataFrame(index=genes)\n",
    "                obs = pd.DataFrame(index=obs_names)\n",
    "                obs.index.name = \"barcode\"\n",
    "                obs[\"batch\"] = prefix.rstrip(\"_\")\n",
    "\n",
    "                if S.shape[0] != obs.shape[0] or S.shape[1] != var.shape[0]:\n",
    "                    raise ValueError(f\"Shape mismatch: X={S.shape}, obs={obs.shape[0]}, var={var.shape[0]}\")\n",
    "\n",
    "                ad_chunk = ad.AnnData(\n",
    "                    X=S,\n",
    "                    obs=obs,\n",
    "                    var=var,\n",
    "                    layers={LAYER_SPLICED: S, LAYER_UNSPLICED: U},\n",
    "                    dtype=np.float32,\n",
    "                )\n",
    "                ad_chunk.var_names_make_unique()\n",
    "\n",
    "                tmp_path = CACHE / f\"tmp_{prefix}{start:07d}.h5ad\"\n",
    "                ad_chunk.write(tmp_path)\n",
    "                tmp_files.append(tmp_path)\n",
    "\n",
    "                del S, U, ad_chunk, obs, var\n",
    "                gc.collect()\n",
    "\n",
    "            del genes, raw_bcs, prefixed, keep_mask, keep_idx\n",
    "            gc.collect()\n",
    "\n",
    "    if len(tmp_files) == 0:\n",
    "        raise RuntimeError(\"No cells matched metadata barcodes; check META_CSV vs loom barcodes/prefixes.\")\n",
    "\n",
    "    ad_merged = None\n",
    "    for i, f in enumerate(tmp_files):\n",
    "        ad_i = sc.read_h5ad(f, backed=None)\n",
    "        if ad_merged is None:\n",
    "            ad_merged = ad_i\n",
    "        else:\n",
    "            ad_merged = sc.concat([ad_merged, ad_i],\n",
    "                                  join=\"outer\", merge=\"same\",\n",
    "                                  label=None, index_unique=None)\n",
    "        del ad_i\n",
    "        gc.collect()\n",
    "\n",
    "    ad_merged.obs.index.name = \"barcode\"\n",
    "    ad_merged.var_names_make_unique()\n",
    "    assert {LAYER_SPLICED, LAYER_UNSPLICED} <= set(ad_merged.layers.keys())\n",
    "\n",
    "    ad_merged.write(RAW)\n",
    "\n",
    "    for f in tmp_files:\n",
    "        try:\n",
    "            os.remove(f)\n",
    "        except Exception:\n",
    "            pass\n",
    "\n",
    "    adata = ad_merged\n",
    "    del ad_merged\n",
    "    gc.collect()\n",
    "\n",
    "adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79f0a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === P3: annotate from Seurat metadata, freeze Seurat UMAP ==================\n",
    "\n",
    "ANNO = CACHE / \"adata_annotated.h5ad\"\n",
    "# --- robust palette handling (drop-in replacement for apply_palette) -------\n",
    "# Colors (families)\n",
    "FAMILY_COLORS = {\n",
    "    # Neoblast subtypes \n",
    "    \"σ-neoblast\":               \"#E3E3E3\",\n",
    "    \"ν-neoblast\":               \"#707070\",\n",
    "    \"ζ-neoblast\":               \"#8D8D8D\",\n",
    "    \"γ-neoblast\":               \"#AAAAAA\",\n",
    "    \"Muscle neoblast\":          \"#D5D5D5\",\n",
    "    \"Protonephridial neoblast\": \"#B8B8B8\",\n",
    "    \"Parenchymal neoblast\":     \"#B3B3B3\",\n",
    "    \"Pharyngeal neoblast\":      \"#7F7F7F\",\n",
    "    \"Eye neoblast\":             \"#00D3D3\",   \n",
    "\n",
    "    # Progenitors \n",
    "    \"Epidermal progenitor\":     \"#ABCEDF\",   # Early epidermal progenitor\n",
    "    \"Eye progenitor\":           \"#00D3D3\",   # Eye progenitor\n",
    "    \"Pharyngeal progenitor\":    \"#D9D900\",   # Pharyngeal progenitor\n",
    "    \"Parenchymal progenitor\":   \"#E39F55\",   # NKX2⁺ parenchymal progenitor\n",
    "    \"Protonephridial progenitor\":\"#874A68\",  # align to protonephridia wine block\n",
    "    \"Neural progenitor\":        \"#DED5F6\",   # Glutamatergic neural progenitor\n",
    "    \"Pigment progenitor\":       \"#C08A5A\",\n",
    "\n",
    "    # Mature \n",
    "    \"Epidermis\":                \"#5685BD\",   # Epidermis (broad)\n",
    "    \"Eye\":                      \"#00D3D3\",   # Eye progenitor (cyan block)\n",
    "    \"Intestine\":                \"#497F46\",   # Phagocyte (broad)\n",
    "    \"Pigment\":                  \"#8E5A3C\",   # Body pigment cell\n",
    "    \"Muscle\":                   \"#CC5C5D\",   # ECM-producing muscle\n",
    "    \"Nervous system\":           \"#9171BF\",   # Mechanosensory neuron (representative violet)\n",
    "    \"Parenchyma\":               \"#F3D38E\",   # LDLRR-1⁺ parenchymal cell\n",
    "    \"Pharynx\":                  \"#FFFF00\",   # Pharyngeal epithelium\n",
    "    \"Protonephridia\":           \"#874A68\",   # Protonephridial flame cell\n",
    "\n",
    "    \"other\":                    \"#BDBDBD\",\n",
    "}\n",
    "# Colors (detailed cell types)\n",
    "DETAILED_COLS = {\n",
    "  # --- Epidermis (blue) ---\n",
    "  \"Early epidermal progenitor\"             : \"#ABCEDF\",\n",
    "  \"Late epidermal progenitor\"              : \"#6693C4\",\n",
    "  \"Epidermis (broad)\"                      : \"#5685BD\",\n",
    "  \"Epidermis (multiciliated)\"              : \"#3468B0\",\n",
    "  \"Epidermal progenitor (multiciliated)\"   : \"#4576B6\",\n",
    "  \"Epidermal secretory gland progenitor\"   : \"#99BFD8\",\n",
    "  \n",
    "  # --- Eye (cyan) ---\n",
    "  \"Eye progenitor\"                         : \"#00D3D3\",\n",
    "  \n",
    "  # --- Intestine / immune-like (green) ---\n",
    "  \"Basal cell\"                             : \"#D3E4BA\",\n",
    "  \"Goblet cell\"                            : \"#8DB180\",\n",
    "  \"Phagocyte (broad)\"                     : \"#497F46\",\n",
    "  \n",
    "  # --- Pigment (brown) ---\n",
    "  \"Body pigment progenitor\"                : \"#C08A5A\",\n",
    "  \"Body pigment cell\"                      : \"#8E5A3C\",\n",
    "  \n",
    "  # --- Muscle (red) ---\n",
    "  \"Muscle progenitor\"                      : \"#F2C7CA\",\n",
    "  \"BWM (dorsal midline)\"                   : \"#E6A3A6\",\n",
    "  \"ECM-producing muscle\"                   : \"#CC5C5D\",\n",
    "  \"Posterior pole/PCG muscle\"              : \"#C1393A\",\n",
    "  \n",
    "  # --- Neoblasts (grey) ---\n",
    "  \"σ-neoblast (broad-lineage)\"             : \"#E3E3E3\",\n",
    "  \"Muscle neoblast\"                        : \"#D5D5D5\",\n",
    "  \"Protonephridial neoblast\"               : \"#B8B8B8\",\n",
    "  \"Pharyngeal neoblast\"                    : \"#7F7F7F\",\n",
    "  \"γ-neoblast (intestinal-fated)\"          : \"#AAAAAA\",\n",
    "  \"ζ-neoblast (epidermal-fated)\"           : \"#8D8D8D\",\n",
    "  \"ν-neoblast (neural-fated)\"              : \"#707070\",\n",
    "  \"GLIRP-1⁺ parenchymal neoblast\"          : \"#B3B3B3\",\n",
    "  \"PGRN⁺ parenchymal neoblast\"             : \"#BEBEBE\",\n",
    "  \"FER3L-2⁺ parenchymal neoblast\"          : \"#C7C7C7\",\n",
    "  \n",
    "  # --- Neural lineage (violet) ---\n",
    "  \"Neural progenitor (broad)\"              : \"#E9E4FA\",\n",
    "  \"Glutamatergic neural progenitor\"        : \"#DED5F6\",\n",
    "  \"Neuropeptidergic neural progenitor\"     : \"#D3C7F2\",\n",
    "  \"Mechanosensory neural progenitor\"       : \"#C9BAEE\",\n",
    "  \"PKD⁺ sensory neural progenitor\"         : \"#BFADE8\",\n",
    "  \"Glia\"                                   : \"#AF98D5\",\n",
    "  \"Brain branch neuron\"                    : \"#D8CCF3\",\n",
    "  \"Catecholaminergic neuron\"               : \"#CDBFEB\",\n",
    "  \"Cholinergic neuron\"                     : \"#C3B2E4\",\n",
    "  \"Glutamatergic neuron\"                   : \"#A58ACE\",\n",
    "  \"Mechanosensory neuron\"                  : \"#9171BF\",\n",
    "  \"Neuropeptidergic neuron\"                : \"#8764B8\",\n",
    "  \"PKD⁺ sensory neuron\"                    : \"#7349A9\",\n",
    "  \"Serotonergic neuron\"                    : \"#693CA2\",\n",
    "  \n",
    "  # --- Parenchyma (sand) ---\n",
    "  \"AQP⁺ parenchymal cell\"                  : \"#F9E29D\",\n",
    "  \"LDLRR-1⁺ parenchymal cell\"              : \"#F3D38E\",\n",
    "  \"GLIRP-1⁺ parenchymal progenitor\"        : \"#EDC281\",\n",
    "  \"PSAP⁺ parenchymal progenitor\"           : \"#F1D6A0\",\n",
    "  \"PSAP⁺ parenchymal cell\"                 : \"#EBB670\",\n",
    "  \"PGRN⁺ parenchymal cell\"                 : \"#EFC57F\",\n",
    "  \"FER3L-2⁺ parenchymal progenitor\"        : \"#E8B567\",\n",
    "  \"NKX2⁺ parenchymal progenitor\"           : \"#E39F55\",\n",
    "  \"PTF⁺ head parenchymal progenitor\"       : \"#E6A860\",\n",
    "  \"SSPO⁺ parenchymal progenitor\"           : \"#E19A51\",\n",
    "  \"SSPO⁺ parenchymal cell\"                 : \"#DD8B42\",\n",
    "  \"Abraçada cell\"                          : \"#FAE8B4\",\n",
    "  \n",
    "  # --- Pharynx (yellow) ---\n",
    "  \"Pharyngeal epithelium\"                  : \"#FFFF00\",\n",
    "  \"Pharyngeal progenitor\"                  : \"#D9D900\",\n",
    "  \"Pharyngeal phagocytic-type cell\"        : \"#C9C900\",\n",
    "  \n",
    "  # --- Protonephridia (wine) ---\n",
    "  \"Protonephridial flame cell\"             : \"#874A68\",\n",
    "  \"Protonephridial tubule cell\"            : \"#87345F\"\n",
    "}\n",
    "\n",
    "def _canon_label_for_palette(x: str) -> str:\n",
    "    \"\"\"\n",
    "    Canonicalize labels to match palette keys irrespective of case, plus signs,\n",
    "    spaces, unicode variants.\n",
    "    \"\"\"\n",
    "    x = str(x)\n",
    "    x = x.replace(\"⁺\", \"+\").replace(\"–\", \"-\").replace(\"—\", \"-\").replace(\"’\", \"'\")\n",
    "    x = re.sub(r\"\\s+\", \" \", x).strip()\n",
    "    return x.lower()\n",
    "\n",
    "def _canon_palette(pal: dict) -> dict:\n",
    "    \"\"\"Return dict keyed by canonical labels, preserving original color values.\"\"\"\n",
    "    return {_canon_label_for_palette(k): v for k, v in pal.items()}\n",
    "\n",
    "def apply_palette(adx: ad.AnnData, key: str, palette: dict,\n",
    "                  fallback: str = \"#808080\", strict: bool = True):\n",
    "    \"\"\"\n",
    "    Attach a color list to adx.uns[f\"{key}_colors\"] matching the categories\n",
    "    of adx.obs[key].\n",
    "\n",
    "    - Canonicalizes both palette keys and category labels to avoid mismatches.\n",
    "    - If strict=True, raises with a list of missing labels so you catch typos early.\n",
    "    \"\"\"\n",
    "    if key not in adx.obs:\n",
    "        raise KeyError(f\"obs[{key}] not found\")\n",
    "\n",
    "    cats   = list(adx.obs[key].astype(\"category\").cat.categories)\n",
    "    pal_map = _canon_palette(palette)\n",
    "\n",
    "    colors  = []\n",
    "    missing = []\n",
    "    for c in cats:\n",
    "        cc = _canon_label_for_palette(c)\n",
    "        col = pal_map.get(cc, None)\n",
    "        if col is None:\n",
    "            missing.append(c)\n",
    "            col = fallback\n",
    "        colors.append(col)\n",
    "\n",
    "    if strict and missing:\n",
    "        raise ValueError(f\"Palette missing colors for categories in '{key}': {missing}\")\n",
    "\n",
    "    adx.uns[f\"{key}_colors\"] = colors\n",
    "    return missing  # so you can log or inspect if strict=False\n",
    "\n",
    "def audit_palette_coverage(adx: ad.AnnData, key: str, palette: dict):\n",
    "    \"\"\"\n",
    "    Print a concise audit of palette coverage for debugging.\n",
    "    \"\"\"\n",
    "    if key not in adx.obs:\n",
    "        raise KeyError(f\"obs[{key}] not found\")\n",
    "\n",
    "    cats    = list(adx.obs[key].astype(\"category\").cat.categories)\n",
    "    pal_map = _canon_palette(palette)\n",
    "    miss    = [c for c in cats if _canon_label_for_palette(c) not in pal_map]\n",
    "\n",
    "    if miss:\n",
    "        print(f\"[audit] {key}: {len(miss)}/{len(cats)} categories missing in palette:\")\n",
    "        for c in miss:\n",
    "            print(\"   -\", c)\n",
    "    else:\n",
    "        print(f\"[audit] {key}: full coverage for {len(cats)} categories\")\n",
    "\n",
    "if ANNO.exists():\n",
    "    adata = sc.read_h5ad(ANNO)\n",
    "else:\n",
    "    meta = pd.read_csv(META_CSV)\n",
    "    need = {\"barcode\",\"celltype\",\"UMAP1\",\"UMAP2\"}\n",
    "    missing = need - set(meta.columns)\n",
    "    if missing:\n",
    "        raise ValueError(f\"Metadata missing columns: {missing}\")\n",
    "\n",
    "    meta[\"barcode\"]  = meta[\"barcode\"].astype(str).str.strip().str.replace(\"–\", \"-\", regex=False)\n",
    "    meta[\"celltype\"] = meta[\"celltype\"].astype(str).map(_norm_label)\n",
    "    meta = meta.set_index(\"barcode\")\n",
    "\n",
    "    overlap = adata.obs.index.intersection(meta.index)\n",
    "    if len(overlap) == 0:\n",
    "        raise ValueError(\"No overlap in barcodes between AnnData and metadata\")\n",
    "\n",
    "    adata = adata[overlap, :].copy()\n",
    "    adata.obs[\"celltype\"] = meta.loc[overlap, \"celltype\"].astype(\"category\")\n",
    "\n",
    "    # >>> Seurat UMAP, used everywhere <<<\n",
    "    seurat_umap = meta.loc[overlap, [\"UMAP1\",\"UMAP2\"]].to_numpy()\n",
    "    adata.obsm[\"X_umap_seurat\"] = seurat_umap\n",
    "    adata.obsm[\"X_umap\"]        = seurat_umap.copy()\n",
    "    adata.obsm[\"X_umap_joint\"]  = seurat_umap.copy()  # for your template code later\n",
    "\n",
    "    derive_cond_time_from_barcode(adata)\n",
    "    add_families_inplace(adata, \"celltype\", \"celltype_family\")\n",
    "\n",
    "    adata.obs[\"celltype\"]        = adata.obs[\"celltype\"].cat.remove_unused_categories()\n",
    "    adata.obs[\"celltype_family\"] = adata.obs[\"celltype_family\"].cat.remove_unused_categories()\n",
    "\n",
    "    # palettes (soft, non-strict)\n",
    "    apply_palette(adata, \"celltype\",        DETAILED_COLS, strict=False)\n",
    "    apply_palette(adata, \"celltype_family\", FAMILY_COLORS, strict=False)\n",
    "    audit_palette_coverage(adata, \"celltype\",        DETAILED_COLS)\n",
    "    audit_palette_coverage(adata, \"celltype_family\", FAMILY_COLORS)\n",
    "\n",
    "    adata.write(ANNO)\n",
    "\n",
    "adata\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23eac01b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === P4: global preprocessing (HVG, confounder mask, PCA, neighbors) ======\n",
    "\n",
    "PP = CACHE / \"adata_preprocessed.h5ad\"\n",
    "\n",
    "marker_ids = [\n",
    "        \"SMESG000041758.1\",\"SMESG000006121.1\",\"SMESG000025003.1\",\"SMESG000025013.1\",\"SMESG000054781.1\",\n",
    "        \"SMESG000028264.1\",\"SMESG000000720.1\",\"SMESG000077404.1\",\"SMESG000077405.1\",\"SMESG000019274.1\",\n",
    "        \"SMESG000005380.1\",\"SMESG000051964.1\",\"SMESG000075230.1\",\"SMESG000001180.1\",\"SMESG000040332.1\",\n",
    "        \"SMESG000043036.1\",\"SMESG000052888.1\",\"SMESG000022963.1\",\"SMESG000022668.1\",\"SMESG000062589.1\",\n",
    "        \"SMESG000027543.1\",\"SMESG000066594.1\",\"SMESG000001830.1\",\"SMESG000001839.1\",\"SMESG000023117.1\",\n",
    "        \"SMESG000072183.1\",\"SMESG000016228.1\",\"SMESG000039906.1\",\"SMESG000081245.1\",\"SMESG000026446.1\",\n",
    "        \"SMESG000050057.1\",\"SMESG000065255.1\",\"SMESG000020792.1\",\"SMESG000021346.1\",\"SMESG000062615.1\",\n",
    "        \"SMESG000016881.1\",\"SMESG000068903.1\",\"SMESG000026025.1\",\"SMESG000074489.1\",\"SMESG000001561.1\",\n",
    "        \"SMESG000031965.1\",\"SMESG000005975.1\",\"SMESG000001687.1\",\"SMESG000045025.1\",\"SMESG000050160.1\",\n",
    "        \"SMESG000020910.1\",\"SMESG000031796.1\",\"SMESG000031800.1\",\"SMESG000032489.1\",\"SMESG000035182.1\",\n",
    "        \"SMESG000013991.1\",\"SMESG000013992.1\",\"SMESG000049781.1\",\"SMESG000049783.1\",\"SMESG000044930.1\",\n",
    "        \"SMESG000077075.1\",\"SMESG000027359.1\",\"SMESG000004222.1\",\"SMESG000052644.1\",\"SMESG000041571.1\",\n",
    "        \"SMESG000051002.1\",\"SMESG000000615.1\",\"SMESG000054829.1\",\"SMESG000034317.1\",\"SMESG000002557.1\",\n",
    "        \"SMESG000037029.1\",\"SMESG000014725.1\",\"SMESG000014728.1\",\"SMESG000014733.1\",\"SMESG000021248.1\",\n",
    "        \"SMESG000037982.1\",\"SMESG000014322.1\",\"SMESG000074928.1\",\"SMESG000069322.1\",\"SMESG000072430.1\",\n",
    "        \"SMESG000024191.1\",\"SMESG000066476.1\",\"SMESG000005930.1\",\"SMESG000006550.1\",\"SMESG000081129.1\",\n",
    "        \"SMESG000034317.1\",\"SMESG000003513.1\",\"SMESG000036363.1\",\"SMESG000036385.1\",\"SMESG000062915.1\",\n",
    "        \"SMESG000076173.1\",\"SMESG000037031.1\",\"SMESG000039559.1\",\"SMESG000014588.1\",\"SMESG000079512.1\",\n",
    "        \"SMESG000068287.1\",\"SMESG000004840.1\",\"SMESG000051170.1\",\"SMESG000078256.1\",\"SMESG000065235.1\",\n",
    "        \"SMESG000066244.1\",\"SMESG000002774.1\",\"SMESG000081885.1\",\"SMESG000011244.1\",\"SMESG000017305.1\",\n",
    "        \"SMESG000027459.1\",\"SMESG000081970.1\",\"SMESG000070309.1\",\"SMESG000002173.1\",\"SMESG000010063.1\",\n",
    "        \"SMESG000074761.1\",\"SMESG000036375.1\",\"SMESG000069984.1\",\"SMESG000021009.1\",\"SMESG000026774.1\",\n",
    "        \"SMESG000068398.1\",\"SMESG000034472.1\",\"SMESG000051357.1\",\"SMESG000041535.1\",\"SMESG000069017.1\",\n",
    "        \"SMESG000051356.1\",\"SMESG000024277.1\",\"SMESG000050934.1\",\"SMESG000050924.1\",\"SMESG000018924.1\",\n",
    "        \"SMESG000026791.1\",\"SMESG000030049.1\",\"SMESG000052932.1\",\"SMESG000032477.1\",\"SMESG000061339.1\",\n",
    "        \"SMESG000012683.1\",\"SMESG000029269.1\",\"SMESG000029304.1\",\"SMESG000066649.1\",\"SMESG000013430.1\",\n",
    "        \"SMESG000008070.1\",\"SMESG000037720.1\",\"SMESG000014268.1\",\"SMESG000067397.1\",\"SMESG000067002.1\",\n",
    "        \"SMESG000066980.1\",\"SMESG000005014.1\",\"SMESG000059487.1\",\"SMESG000018492.1\",\"SMESG000018504.1\",\n",
    "        \"SMESG000033381.1\",\"SMESG000014723.1\",\"SMESG000081952.1\",\"SMESG000022856.1\",\"SMESG000010916.1\",\n",
    "        \"SMESG000001774.1\",\"SMESG000057112.1\",\"SMESG000016568.1\",\"SMESG000043039.1\",\"SMESG000020988.1\",\n",
    "        \"SMESG000053732.1\",\"SMESG000080359.1\",\"SMESG000021044.1\",\"SMESG000001598.1\",\"SMESG000001609.1\",\n",
    "        \"SMESG000000522.1\",\"SMESG000019737.1\",\"SMESG000067985.1\",\"SMESG000023346.1\",\"SMESG000023352.1\",\n",
    "        \"SMESG000028474.1\",\"SMESG000005963.1\",\"SMESG000023353.1\",\"SMESG000027826.1\",\"SMESG000002628.1\",\n",
    "        \"SMESG000019973.1\",\"SMESG000019976.1\",\"SMESG000019984.1\",\"SMESG000044960.1\",\"SMESG000019457.1\",\n",
    "        \"SMESG000025547.1\",\"SMESG000041532.1\",\"SMESG000042714.1\",\"SMESG000042718.1\",\"SMESG000048406.1\",\n",
    "        \"SMESG000029000.1\",\"SMESG000065670.1\",\"SMESG000023052.1\",\"SMESG000004239.1\",\"SMESG000006530.1\",\n",
    "        \"SMESG000018258.1\",\"SMESG000069088.1\",\"SMESG000031846.1\",\"SMESG000022958.1\",\"SMESG000022356.1\",\n",
    "        \"SMESG000033462.1\",\"SMESG000074524.1\",\"SMESG000044603.1\",\"SMESG000069765.1\",\"SMESG000003437.1\",\n",
    "        \"SMESG000061191.1\",\"SMESG000071069.1\",\"SMESG000001687.1\",\"SMESG000005975.1\",\"SMESG000022725.1\",\n",
    "        \"SMESG000017121.1\",\"SMESG000062486.1\",\"SMESG000072084.1\"\n",
    "    ]\n",
    "\n",
    "if PP.exists():\n",
    "    adata = sc.read_h5ad(PP)\n",
    "else:\n",
    "    # Geometry based on spliced counts\n",
    "    if \"spliced\" in adata.layers:\n",
    "        adata.X = adata.layers[\"spliced\"]\n",
    "\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "\n",
    "    # HVGs\n",
    "    try:\n",
    "        import skmisc  # noqa: F401\n",
    "        HVG_FLAVOR = \"seurat_v3\"\n",
    "    except Exception:\n",
    "        HVG_FLAVOR = \"seurat\"\n",
    "\n",
    "    sc.pp.highly_variable_genes(\n",
    "        adata,\n",
    "        n_top_genes=N_TOP_GENES,\n",
    "        flavor=HVG_FLAVOR,\n",
    "        subset=False\n",
    "    )\n",
    "\n",
    "    # Confounder genes (DNA replication, ribosome, etc.) – keep as you defined\n",
    "    pattern = r\"(SMESG000046293.1|SMESG000005389.1|SMESG000038798.1|SMESG000060238.1|SMESG000057772.1|SMESG000070153.1|SMESG000036830.1|SMESG000014909.1|SMESG000000804.1|SMESG000006063.1|SMESG000006068.1|SMESG000006083.1|SMESG000018037.1|SMESG000023149.1|SMESG000035458.1|SMESG000077264.1|SMESG000074436.1|SMESG000057110.1|SMESG000028669.1|SMESG000054290.1|SMESG000060055.1|SMESG000059543.1|SMESG000036986.|SMESG000022017.1|SMESG000017173.1|SMESG000017172.1)\"\n",
    "    conf = pd.Series(\n",
    "        pd.Index(adata.var_names).str.contains(pattern, case=False, regex=True),\n",
    "        index=adata.var_names\n",
    "    ).to_numpy()\n",
    "\n",
    "    # Force-keep marker genes in geometry\n",
    "    try:\n",
    "        def _canon_id(x: str):\n",
    "            x = re.sub(r\"\\s+\", \"\", str(x))\n",
    "            return re.sub(r\"\\.\\d+$\", \"\", x).lower()\n",
    "        canon_map = {_canon_id(v): v for v in adata.var_names}\n",
    "        must_keep = [canon_map[_canon_id(m)] for m in marker_ids if _canon_id(m) in canon_map]\n",
    "        must_keep_mask = adata.var_names.isin(must_keep).to_numpy()\n",
    "    except Exception:\n",
    "        must_keep_mask = np.zeros(adata.n_vars, dtype=bool)\n",
    "\n",
    "    hvg_mask  = adata.var[\"highly_variable\"].to_numpy()\n",
    "    geom_mask = (hvg_mask & ~conf) | must_keep_mask\n",
    "    adata     = adata[:, geom_mask].copy()\n",
    "\n",
    "    # PCA / neighbors only – UMAP stays Seurat-based\n",
    "    sc.tl.pca(\n",
    "        adata,\n",
    "        n_comps=50,\n",
    "        svd_solver=\"arpack\",\n",
    "        random_state=RND,\n",
    "        zero_center=False\n",
    "    )\n",
    "    sc.pp.neighbors(adata, use_rep=\"X_pca\", n_neighbors=20, n_pcs=30, random_state=RND)\n",
    "\n",
    "    # Do not overwrite X_umap; keep Seurat embedding\n",
    "    # Keep joint alias pointing to Seurat UMAP\n",
    "    if \"X_umap_seurat\" in adata.obsm:\n",
    "        adata.obsm[\"X_umap_joint\"] = adata.obsm[\"X_umap_seurat\"].copy()\n",
    "\n",
    "    apply_palette(adata, \"celltype\",        DETAILED_COLS, strict=False)\n",
    "    apply_palette(adata, \"celltype_family\", FAMILY_COLORS, strict=False)\n",
    "\n",
    "    adata.write(PP)\n",
    "\n",
    "# Global adjacency\n",
    "nbrs = adata.uns.get(\"neighbors\", {})\n",
    "NEIGH_CONN_KEY = nbrs.get(\"connectivities_key\", \"connectivities\")\n",
    "NEIGH_DIST_KEY = nbrs.get(\"distances_key\", \"distances\")\n",
    "\n",
    "if NEIGH_CONN_KEY not in adata.obsp or NEIGH_DIST_KEY not in adata.obsp:\n",
    "    raise KeyError(\"Neighbor graphs not found in .obsp\")\n",
    "\n",
    "GLOBAL_ADJ  = adata.obsp[NEIGH_CONN_KEY].tocsr()\n",
    "GLOBAL_DIST = adata.obsp[NEIGH_DIST_KEY].tocsr()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f74e305",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === P5: balanced subset for fair plotting =================================\n",
    "\n",
    "BAL = CACHE / \"adata_balanced.h5ad\"\n",
    "def balance_per_group(adx, by=(\"cond\",\"timepoint\",\"celltype\"), max_n=None, seed=RND):\n",
    "    df = adx.obs[list(by)].copy()\n",
    "    grp = df.groupby(list(by)).size().rename(\"n\").reset_index()\n",
    "    if max_n is None:\n",
    "        max_n = int(grp[\"n\"].median()); max_n = max(100, min(max_n, grp[\"n\"].min()))\n",
    "    keep_idx = []\n",
    "    rng = np.random.default_rng(seed)\n",
    "    for _, row in grp.iterrows():\n",
    "        mask = np.logical_and.reduce([adx.obs[k].values == row[k] for k in by])\n",
    "        idx = np.where(mask)[0]\n",
    "        keep_idx.extend(idx.tolist() if idx.size <= max_n else rng.choice(idx, size=max_n, replace=False).tolist())\n",
    "    keep_idx = np.array(sorted(keep_idx))\n",
    "    return adx[keep_idx, :].copy()\n",
    "if BAL.exists():\n",
    "    adata_bal = sc.read_h5ad(BAL)\n",
    "else:\n",
    "    adata_bal = balance_per_group(adata, by=(\"cond\",\"timepoint\",\"celltype\"), max_n=None, seed=RND)\n",
    "    adata_bal.obsm[\"X_umap_joint\"] = adata.obsm[\"X_umap_joint\"][adata.obs_names.get_indexer(adata_bal.obs_names), :]\n",
    "    apply_palette(adata_bal, \"celltype\",        DETAILED_COLS, strict=False)\n",
    "    apply_palette(adata_bal, \"celltype_family\", FAMILY_COLORS, strict=False)\n",
    "    adata_bal.write(BAL)\n",
    "\n",
    "adata_bal\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74944c89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === P6: PAGA edge tables using global neighbors ==========================\n",
    "def bootstrap_edge_deltas(boot_tbl: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    From bootstrap edge weights, compute ELAC2-specific delta per replicate,\n",
    "    then summarize per (src, dst, timepoint):\n",
    "\n",
    "    returns:\n",
    "      wide:    per-bootstrap table with columns\n",
    "               src, dst, timepoint, boot,\n",
    "               WT, GFP, ELAC2 KD, delta_KD, delta_GFP, delta_ELAC2_specific\n",
    "      summary: per-edge summary with mean/std/2.5%/97.5% of delta_ELAC2_specific\n",
    "    \"\"\"\n",
    "    if boot_tbl.empty:\n",
    "        return (pd.DataFrame(), pd.DataFrame())\n",
    "\n",
    "    wide = boot_tbl.pivot_table(\n",
    "        index=[\"src\", \"dst\", \"timepoint\", \"boot\"],\n",
    "        columns=\"cond\",\n",
    "        values=\"weight\",\n",
    "        aggfunc=\"mean\",\n",
    "    ).reset_index()\n",
    "\n",
    "    # ensure columns present\n",
    "    for c in COND_ORDER:\n",
    "        if c not in wide.columns:\n",
    "            wide[c] = 0.0\n",
    "\n",
    "    wide[\"delta_KD\"]  = wide[\"ELAC2 KD\"] - wide[\"WT\"]\n",
    "    wide[\"delta_GFP\"] = wide[\"GFP\"]      - wide[\"WT\"]\n",
    "    wide[\"delta_ELAC2_specific\"] = wide[\"delta_KD\"] - wide[\"delta_GFP\"]\n",
    "\n",
    "    def q025(x): return np.quantile(x, 0.025)\n",
    "    def q975(x): return np.quantile(x, 0.975)\n",
    "\n",
    "    summary = (\n",
    "        wide\n",
    "        .groupby([\"src\", \"dst\", \"timepoint\"])[\"delta_ELAC2_specific\"]\n",
    "        .agg(mean=\"mean\", std=\"std\", q025=q025, q975=q975)\n",
    "        .reset_index()\n",
    "    )\n",
    "    return wide, summary\n",
    "\n",
    "def _subset(adx, cond=None, tp=None, keep_ct=None, min_cells_per_cat=10):\n",
    "    q = np.ones(adx.n_obs, dtype=bool)\n",
    "    if cond is not None: q &= (adx.obs[\"cond\"].values == cond)\n",
    "    if tp   is not None: q &= (adx.obs[\"timepoint\"].values == tp)\n",
    "    sub = adx[q, :].copy()\n",
    "    if keep_ct is not None: sub = sub[sub.obs[\"celltype\"].isin(keep_ct)].copy()\n",
    "    sub.obs[\"celltype\"] = sub.obs[\"celltype\"].astype(\"category\").cat.remove_unused_categories()\n",
    "    cats = sub.obs[\"celltype\"].cat.categories\n",
    "    keep = [c for c in cats if (sub.obs[\"celltype\"] == c).sum() >= min_cells_per_cat]\n",
    "    sub = sub[sub.obs[\"celltype\"].isin(keep)].copy()\n",
    "    sub.obs[\"celltype\"] = sub.obs[\"celltype\"].cat.remove_unused_categories()\n",
    "    sub.obs[\"celltype_family\"] = sub.obs[\"celltype_family\"].astype(\"category\").cat.remove_unused_categories()\n",
    "    return sub\n",
    "    \n",
    "def set_subset_neighbors_from_global(sub: ad.AnnData):\n",
    "    idx = adata.obs_names.get_indexer(sub.obs_names)\n",
    "    sub.obsp[NEIGH_CONN_KEY] = GLOBAL_ADJ[idx[:, None], idx].tocsr()\n",
    "    sub.obsp[NEIGH_DIST_KEY] = GLOBAL_DIST[idx[:, None], idx].tocsr()\n",
    "    sub.uns[\"neighbors\"] = dict(adata.uns[\"neighbors\"])\n",
    "    sub.uns[\"neighbors\"][\"connectivities_key\"] = NEIGH_CONN_KEY\n",
    "    sub.uns[\"neighbors\"][\"distances_key\"]      = NEIGH_DIST_KEY\n",
    "\n",
    "def paga_connectivities_from_global(adx: ad.AnnData, group=\"celltype\"):\n",
    "    idx     = adata.obs_names.get_indexer(adx.obs_names)\n",
    "    sub_adj = GLOBAL_ADJ[idx[:, None], idx].tocsr()\n",
    "    cats    = list(adx.obs[group].cat.categories)\n",
    "    cl      = adx.obs[group].to_numpy()\n",
    "    label_to_idx = {c: np.where(cl == c)[0] for c in cats if (cl == c).sum() > 0}\n",
    "\n",
    "    coo  = sub_adj.tocoo()\n",
    "    used = set()\n",
    "    for i, j, _ in zip(coo.row, coo.col, coo.data):\n",
    "        if i == j:\n",
    "            continue\n",
    "        a, b = (i, j) if i < j else (j, i)\n",
    "        used.add((a, b))\n",
    "    total_mass = float(sum(sub_adj[a, b] for (a, b) in used))\n",
    "    if total_mass <= 0:\n",
    "        total_mass = 1.0\n",
    "\n",
    "    rows = []\n",
    "    for i, ci in enumerate(cats):\n",
    "        if ci not in label_to_idx:\n",
    "            continue\n",
    "        Ii = label_to_idx[ci]\n",
    "        for j, cj in enumerate(cats[i:], start=i):\n",
    "            if cj not in label_to_idx:\n",
    "                continue\n",
    "            Ij = label_to_idx[cj]\n",
    "            block = sub_adj[Ii[:, None], Ij]\n",
    "            w = float(block.sum())\n",
    "            if i == j:\n",
    "                diag_w = float(sub_adj.diagonal()[Ii].sum())\n",
    "                w = max(0.0, w - diag_w)\n",
    "            rows.append((ci, cj, w))\n",
    "\n",
    "    df = pd.DataFrame(rows, columns=[\"src\",\"dst\",\"w_raw\"])\n",
    "    df[\"weight\"] = df[\"w_raw\"] / total_mass\n",
    "    df = df[df[\"src\"] != df[\"dst\"]].copy()\n",
    "    return df[[\"src\",\"dst\",\"weight\"]]\n",
    "\n",
    "def paga_tables_by_subset_global(adx: ad.AnnData, group=\"celltype\"):\n",
    "    rows = []\n",
    "    for tp in TP_ORDER:\n",
    "        for cond in COND_ORDER:\n",
    "            sub = _subset(adx, cond=cond, tp=tp)\n",
    "            if sub.n_obs == 0 or sub.obs[group].nunique() < 2:\n",
    "                continue\n",
    "            df = paga_connectivities_from_global(sub, group=group)\n",
    "            for _, r in df.iterrows():\n",
    "                rows.append((r[\"src\"], r[\"dst\"], cond, tp, float(r[\"weight\"])))\n",
    "    return pd.DataFrame(rows, columns=[\"src\",\"dst\",\"cond\",\"timepoint\",\"weight\"])\n",
    "\n",
    "# Edge tables\n",
    "EDGES_CELLTYPE_CSV = CACHE / \"paga_edges_long_celltype.csv\"\n",
    "if EDGES_CELLTYPE_CSV.exists():\n",
    "    edge_tbl_cell = pd.read_csv(EDGES_CELLTYPE_CSV)\n",
    "else:\n",
    "    edge_tbl_cell = paga_tables_by_subset_global(adata, group=\"celltype\")\n",
    "    edge_tbl_cell.to_csv(EDGES_CELLTYPE_CSV, index=False)\n",
    "\n",
    "EDGES_FAMILY_CSV = CACHE / \"paga_edges_long_family.csv\"\n",
    "if EDGES_FAMILY_CSV.exists():\n",
    "    edge_tbl_fam = pd.read_csv(EDGES_FAMILY_CSV)\n",
    "else:\n",
    "    edge_tbl_fam = paga_tables_by_subset_global(adata, group=\"celltype_family\")\n",
    "    edge_tbl_fam.to_csv(EDGES_FAMILY_CSV, index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91105664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === B1: bootstrap PAGA connectivities =====================================\n",
    "def subset_by_cond_tp(\n",
    "    adx,\n",
    "    group: str,\n",
    "    cond=None,\n",
    "    tp=None,\n",
    "    keep_labels=None,\n",
    "    min_cells_per_cat: int = 10,\n",
    "):\n",
    "    \"\"\"\n",
    "    Subset AnnData by cond/timepoint, keep only categories with >= min_cells_per_cat,\n",
    "    and ensure adx.obs[group] is categorical with unused categories removed.\n",
    "    \"\"\"\n",
    "    q = np.ones(adx.n_obs, dtype=bool)\n",
    "\n",
    "    if cond is not None:\n",
    "        q &= (adx.obs[\"cond\"].to_numpy() == cond)\n",
    "    if tp is not None:\n",
    "        q &= (adx.obs[\"timepoint\"].to_numpy() == tp)\n",
    "\n",
    "    sub = adx[q, :].copy()\n",
    "\n",
    "    if keep_labels is not None:\n",
    "        sub = sub[sub.obs[group].isin(keep_labels)].copy()\n",
    "\n",
    "    # force categorical and drop unused\n",
    "    sub.obs[group] = sub.obs[group].astype(\"category\")\n",
    "    sub.obs[group] = sub.obs[group].cat.remove_unused_categories()\n",
    "\n",
    "    # enforce min cells per category\n",
    "    vc = sub.obs[group].value_counts()\n",
    "    keep = vc[vc >= min_cells_per_cat].index\n",
    "    sub = sub[sub.obs[group].isin(keep)].copy()\n",
    "\n",
    "    sub.obs[group] = sub.obs[group].astype(\"category\")\n",
    "    sub.obs[group] = sub.obs[group].cat.remove_unused_categories()\n",
    "\n",
    "    return sub\n",
    "\n",
    "def _bootstrap_sample_cells(sub: ad.AnnData, group: str, frac: float, rng: np.random.Generator):\n",
    "    labels = sub.obs[group].astype(\"category\")\n",
    "    cats   = list(labels.cat.categories)\n",
    "    arr    = labels.to_numpy()\n",
    "\n",
    "    idx_all = []\n",
    "    for c in cats:\n",
    "        mask = (arr == c)\n",
    "        base_idx = np.where(mask)[0]\n",
    "        if base_idx.size == 0:\n",
    "            continue\n",
    "        n = max(1, int(round(frac * base_idx.size)))\n",
    "        resampled = rng.choice(base_idx, size=n, replace=True)\n",
    "        idx_all.append(resampled)\n",
    "\n",
    "    if len(idx_all) == 0:\n",
    "        return sub[:0, :].copy()\n",
    "\n",
    "    idx_all = np.concatenate(idx_all)\n",
    "    return sub[idx_all, :].copy()\n",
    "\n",
    "def paga_bootstrap_edges(\n",
    "    adx,\n",
    "    group: str = \"celltype\",\n",
    "    n_boot: int = 100,\n",
    "    frac: float = 0.8,\n",
    "    seed: int = RND,\n",
    "    min_cells_per_cat: int = 10,\n",
    ") -> pd.DataFrame:\n",
    "    rng = np.random.default_rng(seed)\n",
    "    all_rows = []\n",
    "\n",
    "    for tp in TP_ORDER:\n",
    "        for cond in COND_ORDER:\n",
    "            base = subset_by_cond_tp(\n",
    "                adx, group=group, cond=cond, tp=tp,\n",
    "                min_cells_per_cat=min_cells_per_cat\n",
    "            )\n",
    "            if base.n_obs == 0 or base.obs[group].nunique() < 2:\n",
    "                continue\n",
    "\n",
    "            for b in range(n_boot):\n",
    "                boot_sub = _bootstrap_sample_cells(base, group=group, frac=frac, rng=rng)\n",
    "                if boot_sub.n_obs == 0 or boot_sub.obs[group].nunique() < 2:\n",
    "                    continue\n",
    "\n",
    "                # ensure categorical after resampling\n",
    "                boot_sub.obs[group] = boot_sub.obs[group].astype(\"category\")\n",
    "                boot_sub.obs[group] = boot_sub.obs[group].cat.remove_unused_categories()\n",
    "\n",
    "                df = paga_connectivities_from_global(boot_sub, group=group)\n",
    "                df[\"cond\"]      = cond\n",
    "                df[\"timepoint\"] = tp\n",
    "                df[\"boot\"]      = b\n",
    "                all_rows.append(df)\n",
    "\n",
    "    if not all_rows:\n",
    "        return pd.DataFrame(columns=[\"src\",\"dst\",\"cond\",\"timepoint\",\"boot\",\"weight\"])\n",
    "\n",
    "    boot_tbl = pd.concat(all_rows, ignore_index=True)\n",
    "    return boot_tbl[[\"src\",\"dst\",\"cond\",\"timepoint\",\"boot\",\"weight\"]]\n",
    "\n",
    "\n",
    "def summarize_bootstrap_edges(boot_tbl: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Summaries per edge × condition × timepoint:\n",
    "      mean, std, q025, q975\n",
    "    \"\"\"\n",
    "    if boot_tbl.empty:\n",
    "        return pd.DataFrame()\n",
    "\n",
    "    def q025(x): return np.quantile(x, 0.025)\n",
    "    def q975(x): return np.quantile(x, 0.975)\n",
    "\n",
    "    agg = (\n",
    "        boot_tbl\n",
    "        .groupby([\"src\",\"dst\",\"cond\",\"timepoint\"])[\"weight\"]\n",
    "        .agg(mean=\"mean\", std=\"std\", q025=q025, q975=q975)\n",
    "        .reset_index()\n",
    "    )\n",
    "    return agg\n",
    "\n",
    "# Run bootstrap for cell types and families (you can reduce n_boot initially)\n",
    "BOOT_CELL_CSV = CACHE / \"paga_bootstrap_edges_celltype.csv\"\n",
    "if BOOT_CELL_CSV.exists():\n",
    "    boot_cell = pd.read_csv(BOOT_CELL_CSV)\n",
    "else:\n",
    "    boot_cell = paga_bootstrap_edges(adata, group=\"celltype\", n_boot=100, frac=0.8, seed=RND)\n",
    "    boot_cell.to_csv(BOOT_CELL_CSV, index=False)\n",
    "\n",
    "BOOT_FAM_CSV = CACHE / \"paga_bootstrap_edges_family.csv\"\n",
    "if BOOT_FAM_CSV.exists():\n",
    "    boot_fam = pd.read_csv(BOOT_FAM_CSV)\n",
    "else:\n",
    "    boot_fam = paga_bootstrap_edges(adata, group=\"celltype_family\", n_boot=100, frac=0.8, seed=RND)\n",
    "    boot_fam.to_csv(BOOT_FAM_CSV, index=False)\n",
    "\n",
    "boot_summary_cell = summarize_bootstrap_edges(boot_cell)\n",
    "boot_summary_fam  = summarize_bootstrap_edges(boot_fam)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5268df68",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === B2: summarize bootstrap and build mean-weight lookup ==================\n",
    "# lookup: (src, dst, cond, timepoint) -> mean bootstrap weight\n",
    "boot_mean_cell = (\n",
    "    boot_summary_cell\n",
    "    .set_index([\"src\", \"dst\", \"cond\", \"timepoint\"])[\"mean\"]\n",
    ")\n",
    "\n",
    "boot_mean_fam = (\n",
    "    boot_summary_fam\n",
    "    .set_index([\"src\", \"dst\", \"cond\", \"timepoint\"])[\"mean\"]\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9a34902",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === P7: ELAC2-specific deltas =============================================\n",
    "\n",
    "def compute_elac2_specific_edge_deltas(df_edges: pd.DataFrame):\n",
    "    pivot = df_edges.pivot_table(index=[\"src\",\"dst\",\"timepoint\"],\n",
    "                                 columns=\"cond\",\n",
    "                                 values=\"weight\", aggfunc=\"mean\").reset_index()\n",
    "    for c in COND_ORDER:\n",
    "        if c not in pivot.columns:\n",
    "            pivot[c] = 0.0\n",
    "    pivot[\"delta_KD\"]  = pivot[\"ELAC2 KD\"] - pivot[\"WT\"]\n",
    "    pivot[\"delta_GFP\"] = pivot[\"GFP\"]      - pivot[\"WT\"]\n",
    "    pivot[\"delta_ELAC2_specific\"] = pivot[\"delta_KD\"] - pivot[\"delta_GFP\"]\n",
    "\n",
    "    long = pivot.melt(\n",
    "        id_vars=[\"src\",\"dst\",\"timepoint\"],\n",
    "        value_vars=[\"WT\",\"GFP\",\"ELAC2 KD\",\"delta_KD\",\"delta_GFP\",\"delta_ELAC2_specific\"],\n",
    "        var_name=\"metric\", value_name=\"value\"\n",
    "    )\n",
    "    return pivot, long\n",
    "\n",
    "# celltype\n",
    "EDGE_PIVOT_CELL = CACHE / \"paga_EDGE_ELAC2_specific_celltype.csv\"\n",
    "EDGE_LONG_CELL  = CACHE / \"paga_EDGE_ELAC2_specific_long_celltype.csv\"\n",
    "if EDGE_PIVOT_CELL.exists() and EDGE_LONG_CELL.exists():\n",
    "    pivot_cell = pd.read_csv(EDGE_PIVOT_CELL)\n",
    "    long_cell  = pd.read_csv(EDGE_LONG_CELL)\n",
    "else:\n",
    "    pivot_cell, long_cell = compute_elac2_specific_edge_deltas(edge_tbl_cell)\n",
    "    pivot_cell.to_csv(EDGE_PIVOT_CELL, index=False)\n",
    "    long_cell.to_csv(EDGE_LONG_CELL,   index=False)\n",
    "# From bootstrap edge tables boot_cell / boot_fam    \n",
    "boot_wide_cell, boot_delta_cell = bootstrap_edge_deltas(boot_cell)\n",
    "# Merge bootstrap CI onto deterministic pivot tables\n",
    "if not boot_delta_cell.empty:\n",
    "    pivot_cell = pivot_cell.merge(\n",
    "        boot_delta_cell.rename(\n",
    "            columns={\n",
    "                \"mean\": \"delta_ELAC2_boot_mean\",\n",
    "                \"std\": \"delta_ELAC2_boot_std\",\n",
    "                \"q025\": \"delta_ELAC2_boot_q025\",\n",
    "                \"q975\": \"delta_ELAC2_boot_q975\",\n",
    "            }\n",
    "        ),\n",
    "        on=[\"src\", \"dst\", \"timepoint\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    \n",
    "for tp in TP_ORDER:\n",
    "    sub = pivot_cell[pivot_cell[\"timepoint\"] == tp].copy()\n",
    "    sub = sub[sub[\"src\"] != sub[\"dst\"]]\n",
    "    sub.sort_values(\"delta_ELAC2_specific\", ascending=False).head(30).to_csv(\n",
    "        CACHE / f\"paga_EDGE_ELAC2_specific_TOP_increase_celltype_{tp}.csv\", index=False\n",
    "    )\n",
    "    sub.sort_values(\"delta_ELAC2_specific\", ascending=True).head(30).to_csv(\n",
    "        CACHE / f\"paga_EDGE_ELAC2_specific_TOP_decrease_celltype_{tp}.csv\", index=False\n",
    "    )\n",
    "\n",
    "# family\n",
    "EDGE_PIVOT_FAM = CACHE / \"paga_EDGE_ELAC2_specific_family.csv\"\n",
    "EDGE_LONG_FAM  = CACHE / \"paga_EDGE_ELAC2_specific_long_family.csv\"\n",
    "if EDGE_PIVOT_FAM.exists() and EDGE_LONG_FAM.exists():\n",
    "    pivot_fam = pd.read_csv(EDGE_PIVOT_FAM)\n",
    "    long_fam  = pd.read_csv(EDGE_LONG_FAM)\n",
    "else:\n",
    "    pivot_fam, long_fam = compute_elac2_specific_edge_deltas(edge_tbl_fam)\n",
    "    pivot_fam.to_csv(EDGE_PIVOT_FAM, index=False)\n",
    "    long_fam.to_csv(EDGE_LONG_FAM,   index=False)\n",
    "\n",
    "\n",
    "# From bootstrap edge tables boot_cell / boot_fam\n",
    "boot_wide_fam,  boot_delta_fam  = bootstrap_edge_deltas(boot_fam)\n",
    "\n",
    "if not boot_delta_fam.empty:\n",
    "    pivot_fam = pivot_fam.merge(\n",
    "        boot_delta_fam.rename(\n",
    "            columns={\n",
    "                \"mean\": \"delta_ELAC2_boot_mean\",\n",
    "                \"std\": \"delta_ELAC2_boot_std\",\n",
    "                \"q025\": \"delta_ELAC2_boot_q025\",\n",
    "                \"q975\": \"delta_ELAC2_boot_q975\",\n",
    "            }\n",
    "        ),\n",
    "        on=[\"src\", \"dst\", \"timepoint\"],\n",
    "        how=\"left\",\n",
    "    )\n",
    "    \n",
    "for tp in TP_ORDER:\n",
    "    sub = pivot_fam[pivot_fam[\"timepoint\"] == tp].copy()\n",
    "    sub = sub[sub[\"src\"] != sub[\"dst\"]]\n",
    "    sub.sort_values(\"delta_ELAC2_specific\", ascending=False).head(30).to_csv(\n",
    "        CACHE / f\"paga_EDGE_ELAC2_specific_TOP_increase_family_{tp}.csv\", index=False\n",
    "    )\n",
    "    sub.sort_values(\"delta_ELAC2_specific\", ascending=True).head(30).to_csv(\n",
    "        CACHE / f\"paga_EDGE_ELAC2_specific_TOP_decrease_family_{tp}.csv\", index=False\n",
    "    )\n",
    "\n",
    "pivot_cell.head(10), pivot_fam.head(10)\n",
    "\n",
    "for tp in TP_ORDER:\n",
    "    sub = pivot_cell[(pivot_cell[\"timepoint\"] == tp) & (pivot_cell[\"src\"] != pivot_cell[\"dst\"])].copy()\n",
    "\n",
    "    # robust increases: 2.5% CI > 0\n",
    "    inc = sub[sub[\"delta_ELAC2_boot_q025\"] > 0].sort_values(\n",
    "        \"delta_ELAC2_specific\", ascending=False\n",
    "    )\n",
    "    inc.head(30).to_csv(\n",
    "        CACHE / f\"paga_BS_EDGE_ELAC2_specific_TOP_increase_celltype_{tp}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "    # robust decreases: 97.5% CI < 0\n",
    "    dec = sub[sub[\"delta_ELAC2_boot_q975\"] < 0].sort_values(\n",
    "        \"delta_ELAC2_specific\", ascending=True\n",
    "    )\n",
    "    dec.head(30).to_csv(\n",
    "        CACHE / f\"paga_BS_EDGE_ELAC2_specific_TOP_decrease_celltype_{tp}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "for tp in TP_ORDER:\n",
    "    sub = pivot_fam[(pivot_fam[\"timepoint\"] == tp) & (pivot_fam[\"src\"] != pivot_fam[\"dst\"])].copy()\n",
    "\n",
    "    # robust increases: 2.5% CI > 0\n",
    "    inc = sub[sub[\"delta_ELAC2_boot_q025\"] > 0].sort_values(\n",
    "        \"delta_ELAC2_specific\", ascending=False\n",
    "    )\n",
    "    inc.head(30).to_csv(\n",
    "        CACHE / f\"paga_BS_EDGE_ELAC2_specific_TOP_increase_family_{tp}.csv\",\n",
    "        index=False,\n",
    "    )\n",
    "\n",
    "    # robust decreases: 97.5% CI < 0\n",
    "    dec = sub[sub[\"delta_ELAC2_boot_q975\"] < 0].sort_values(\n",
    "        \"delta_ELAC2_specific\", ascending=True\n",
    "    )\n",
    "    dec.head(30).to_csv(\n",
    "        CACHE / f\"paga_BS_EDGE_ELAC2_specific_TOP_decrease_family_{tp}.csv\",\n",
    "        index=False,\n",
    "    )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "693039c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === V1_correct: RNA velocity + latent time + potency surrogate ====================\n",
    "\n",
    "VEL = CACHE / \"adata_velocity.h5ad\"\n",
    "\n",
    "if VEL.exists():\n",
    "    adata_vel = sc.read_h5ad(VEL)\n",
    "else:\n",
    "    # Start from the merged object but reset X to raw spliced counts\n",
    "    adata_vel = adata.copy()\n",
    "    ensure_float32_layers(adata_vel, layers=(\"spliced\", \"unspliced\"))\n",
    "\n",
    "    # Use spliced counts as X for scVelo preprocessing\n",
    "    adata_vel.X = adata_vel.layers[\"spliced\"].copy()\n",
    "\n",
    "    # Standard scVelo preprocessing (counts -> normalized/log1p, moments)\n",
    "    scv.pp.filter_and_normalize(\n",
    "        adata_vel,\n",
    "        min_shared_counts=MIN_SHARED_COUNTS,\n",
    "        n_top_genes=N_TOP_GENES,\n",
    "        # use default layer handling: operates on X and 'spliced'/'unspliced'\n",
    "    )\n",
    "    scv.pp.moments(adata_vel, n_pcs=30, n_neighbors=30)\n",
    "\n",
    "    # Dynamical model so that latent_time is defined\n",
    "    # (this is heavier, but what scVelo uses in the Plass 2018-type analyses)\n",
    "    scv.tl.recover_dynamics(adata_vel)          # you can pass n_jobs=.. if desired\n",
    "    scv.tl.velocity(adata_vel, mode=\"dynamical\")\n",
    "    scv.tl.velocity_graph(adata_vel)\n",
    "    scv.tl.terminal_states(adata_vel)\n",
    "    scv.tl.velocity_pseudotime(adata_vel)\n",
    "    scv.tl.latent_time(adata_vel)\n",
    "\n",
    "    # Make sure UMAP basis is the fixed Seurat UMAP\n",
    "    idx = adata.obs_names.get_indexer(adata_vel.obs_names)\n",
    "    adata_vel.obsm[\"X_umap\"] = adata.obsm[\"X_umap_seurat\"][idx, :]\n",
    "\n",
    "    adata_vel.write(VEL)\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Propagate velocity-based time metrics back to the main AnnData\n",
    "# -------------------------------------------------------------------------\n",
    "# join keeps cond/timepoint and celltype_family already present in adata.obs\n",
    "cols = [\"velocity_pseudotime\", \"latent_time\"]\n",
    "\n",
    "# Drop any stale versions\n",
    "for c in cols:\n",
    "    if c in adata.obs:\n",
    "        del adata.obs[c]\n",
    "\n",
    "# Overwrite from adata_vel, aligned by index\n",
    "adata.obs[cols] = adata_vel.obs.loc[adata.obs_names, cols].to_numpy()\n",
    "\n",
    "\n",
    "# Potency surrogate (Plass-style: early cells high potency, late cells low)\n",
    "#lt = adata.obs[\"latent_time\"].to_numpy()\n",
    "#lt_min = np.nanmin(lt)\n",
    "#lt_max = np.nanmax(lt)\n",
    "#pot   = 1.0 - (lt - lt_min) / (lt_max - lt_min + 1e-9)\n",
    "#adata.obs[\"potency_surrogate\"] = pot\n",
    "# -------------------------------------------------------------------------\n",
    "# Re-orient potency so σ-neoblast is high-potency\n",
    "# -------------------------------------------------------------------------\n",
    "# Ensure numeric latent_time on adata_vel\n",
    "adata_vel.obs[\"latent_time\"] = pd.to_numeric(\n",
    "    adata_vel.obs[\"latent_time\"], errors=\"coerce\"\n",
    ")\n",
    "\n",
    "lt = adata_vel.obs[\"latent_time\"].to_numpy()\n",
    "lt_min = np.nanmin(lt)\n",
    "lt_max = np.nanmax(lt)\n",
    "t_scaled = (lt - lt_min) / (lt_max - lt_min + 1e-9)   # in [0, 1]\n",
    "\n",
    "fam = adata_vel.obs[\"celltype_family\"].astype(\"category\")\n",
    "root_family = \"σ-neoblast\"\n",
    "\n",
    "if root_family in list(fam.cat.categories):\n",
    "    root_mask = (fam == root_family).to_numpy()\n",
    "    root_mean = np.nanmean(t_scaled[root_mask])\n",
    "else:\n",
    "    root_mean = np.nan  # fallback if σ-neoblast not present\n",
    "\n",
    "# Decide orientation:\n",
    "# - if σ-neoblast already early (<= 0.5), potency = 1 - t_scaled\n",
    "# - if σ-neoblast late      (>  0.5), potency = t_scaled\n",
    "if np.isnan(root_mean) or root_mean <= 0.5:\n",
    "    cell_pot = 1.0 - t_scaled\n",
    "else:\n",
    "    cell_pot = t_scaled\n",
    "\n",
    "# Store per-cell potency in both velocity and main objects\n",
    "adata_vel.obs[\"potency_surrogate\"] = cell_pot\n",
    "adata.obs[\"potency_surrogate\"] = adata_vel.obs.loc[\n",
    "    adata.obs_names, \"potency_surrogate\"\n",
    "].to_numpy()\n",
    "\n",
    "sc.pl.violin(\n",
    "    adata,\n",
    "    keys=\"potency_surrogate\",\n",
    "    groupby=\"celltype_family\",\n",
    "    rotation=90\n",
    ")\n",
    "\n",
    "\n",
    "family_mean_pot = (\n",
    "    adata.obs[[\"celltype_family\", \"potency_surrogate\"]]\n",
    "    .groupby(\"celltype_family\")[\"potency_surrogate\"]\n",
    "    .mean()\n",
    ")\n",
    "\n",
    "fmin, fmax = family_mean_pot.min(), family_mean_pot.max()\n",
    "family_pot_norm = (family_mean_pot - fmin) / (fmax - fmin + 1e-9)\n",
    "\n",
    "adata.obs[\"family_potency_norm\"] = (\n",
    "    adata.obs[\"celltype_family\"].map(family_pot_norm).astype(float)\n",
    ")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Helper: subset velocity object by condition/timepoint and subset graph\n",
    "# -------------------------------------------------------------------------\n",
    "def subset_velocity_by_cond_tp(adata_vel, cond=None, tp=None):\n",
    "    mask = np.ones(adata_vel.n_obs, dtype=bool)\n",
    "    if cond is not None:\n",
    "        mask &= (adata_vel.obs[\"cond\"].values == cond)\n",
    "    if tp is not None:\n",
    "        mask &= (adata_vel.obs[\"timepoint\"].values == tp)\n",
    "\n",
    "    sub = adata_vel[mask, :].copy()\n",
    "    if sub.n_obs == 0:\n",
    "        return sub\n",
    "\n",
    "    idx = np.where(mask)[0]\n",
    "\n",
    "    # subset velocity_graph (and the negative/transition variants if present)\n",
    "    for key in [\"velocity_graph\", \"velocity_graph_neg\", \"velocity_graph_diff\"]:\n",
    "        if key in adata_vel.uns:\n",
    "            G = adata_vel.uns[key]\n",
    "            if sp.issparse(G):\n",
    "                sub.uns[key] = G[idx[:, None], idx].tocsr()\n",
    "            else:\n",
    "                sub.uns[key] = G[np.ix_(idx, idx)]\n",
    "\n",
    "    # UMAP basis is already per-cell, slicing handled by AnnData\n",
    "    return sub\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Velocity plots – per condition & timepoint, using Seurat UMAP as basis\n",
    "# -------------------------------------------------------------------------\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_velocity_grid_per_cond_tp(color_key=\"celltype\",\n",
    "                                   density=0.7,\n",
    "                                   arrow_size=1.0,\n",
    "                                   arrow_length=1.0,\n",
    "                                   linewidth=0.7):\n",
    "    for tp in TP_ORDER:\n",
    "        for cond in COND_ORDER:\n",
    "            sub = subset_velocity_by_cond_tp(adata_vel, cond=cond, tp=tp)\n",
    "            if sub.n_obs == 0:\n",
    "                continue\n",
    "\n",
    "            # Ensure color key exists\n",
    "            if color_key not in sub.obs.columns:\n",
    "                continue\n",
    "\n",
    "            ax = scv.pl.velocity_embedding_grid(\n",
    "                sub,\n",
    "                basis=\"umap\",\n",
    "                color=color_key,\n",
    "                density=density,\n",
    "                arrow_size=arrow_size,\n",
    "                arrow_length=arrow_length,\n",
    "                linewidth=linewidth,\n",
    "                min_mass=1.0,\n",
    "                show=False,\n",
    "                legend_loc=\"right margin\",\n",
    "            )\n",
    "            fig = ax.get_figure()\n",
    "            fig.savefig(\n",
    "                PLOTS / f\"velocity_grid_{color_key}_umap_seurat_{cond}_{tp}.pdf\",\n",
    "                dpi=300,\n",
    "                bbox_inches=\"tight\"\n",
    "            )\n",
    "            plt.close(fig)\n",
    "\n",
    "# Per-condition & timepoint grids, by detailed celltype and by family\n",
    "plot_velocity_grid_per_cond_tp(color_key=\"celltype\")\n",
    "plot_velocity_grid_per_cond_tp(color_key=\"celltype_family\")\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Latent time distributions (robustness check: pile-up or shift per cond/tp)\n",
    "# -------------------------------------------------------------------------\n",
    "sc.pl.violin(\n",
    "    adata,\n",
    "    keys=\"latent_time\",\n",
    "    groupby=\"celltype\",\n",
    "    split=\"timepoint\",\n",
    "    rotation=45\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f931de6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === P8: template positions + FA2 layout (fixed geometry) ======================\n",
    "# We build node positions for PAGA plots that are:\n",
    "#   1) stable across subsets (cond × timepoint), and\n",
    "#   2) anchored to Seurat UMAP (centroids per category).\n",
    "#\n",
    "# Steps:\n",
    "#   - compute PAGA on the global neighbor graph restricted to a subset\n",
    "#   - prune edges (top-k per node and/or quantile) and keep an MST backbone\n",
    "#   - place nodes by ForceAtlas2 starting from Seurat-UMAP centroids\n",
    "\n",
    "from fa2 import ForceAtlas2\n",
    "import networkx as nx\n",
    "\n",
    "# Scanpy expects these keys under .obsp and .uns[\"neighbors\"]\n",
    "NEIGH_CONN_KEY = \"connectivities\"\n",
    "NEIGH_DIST_KEY = \"distances\"\n",
    "\n",
    "# Ensure the global graphs are present on adata (persist to disk if you save later)\n",
    "assert GLOBAL_ADJ is not None and GLOBAL_DIST is not None, \"Run P4 (neighbors) first.\"\n",
    "assert GLOBAL_ADJ.shape == (adata.n_obs, adata.n_obs)\n",
    "assert GLOBAL_DIST.shape == (adata.n_obs, adata.n_obs)\n",
    "\n",
    "adata.obsp[NEIGH_CONN_KEY] = GLOBAL_ADJ.tocsr()\n",
    "adata.obsp[NEIGH_DIST_KEY] = GLOBAL_DIST.tocsr()\n",
    "\n",
    "adata.uns.setdefault(\"neighbors\", {})\n",
    "adata.uns[\"neighbors\"][\"connectivities_key\"] = NEIGH_CONN_KEY\n",
    "adata.uns[\"neighbors\"][\"distances_key\"] = NEIGH_DIST_KEY\n",
    "adata.uns[\"neighbors\"].setdefault(\"params\", {})\n",
    "adata.uns[\"neighbors\"][\"params\"].setdefault(\"n_neighbors\", 20)\n",
    "\n",
    "def _subset_neighbors_from_global(sub: ad.AnnData) -> None:\n",
    "    \"\"\"Attach global neighbor graphs restricted to subset cells.\"\"\"\n",
    "    idx = adata.obs_names.get_indexer(sub.obs_names)\n",
    "    if np.any(idx < 0):\n",
    "        raise ValueError(\"Some subset obs_names are not present in the global adata.\")\n",
    "\n",
    "    sub.obsp[NEIGH_CONN_KEY] = adata.obsp[NEIGH_CONN_KEY][idx[:, None], idx].tocsr()\n",
    "    sub.obsp[NEIGH_DIST_KEY] = adata.obsp[NEIGH_DIST_KEY][idx[:, None], idx].tocsr()\n",
    "    sub.uns[\"neighbors\"] = {\n",
    "        \"connectivities_key\": NEIGH_CONN_KEY,\n",
    "        \"distances_key\": NEIGH_DIST_KEY,\n",
    "        \"params\": dict(adata.uns.get(\"neighbors\", {}).get(\"params\", {})),\n",
    "    }\n",
    "    sub.uns[\"neighbors\"][\"params\"].setdefault(\"n_neighbors\", adata.uns[\"neighbors\"][\"params\"].get(\"n_neighbors\", 20))\n",
    "\n",
    "def _paga_compute(sub: ad.AnnData, groups: str) -> sp.csr_matrix:\n",
    "    _subset_neighbors_from_global(sub)\n",
    "    sc.tl.paga(sub, groups=groups)\n",
    "    C = sub.uns[\"paga\"][\"connectivities\"].tocsr(copy=True)\n",
    "    C = C.maximum(C.T)        # enforce symmetry\n",
    "    C.setdiag(0.0)\n",
    "    C.eliminate_zeros()\n",
    "    return C\n",
    "\n",
    "def _ensure_min_degree(C: sp.csr_matrix, dmin: int) -> sp.csr_matrix:\n",
    "    \"\"\"Add strongest missing edges so every node has at least dmin degree.\"\"\"\n",
    "    n = C.shape[0]\n",
    "    C_lil = C.tolil(copy=True)\n",
    "    full = C.tocsr()\n",
    "    for i in range(n):\n",
    "        deg = C_lil.getrow(i).nnz\n",
    "        if deg >= dmin:\n",
    "            continue\n",
    "        neigh = full.getrow(i).toarray().ravel()\n",
    "        for j in np.argsort(-neigh):\n",
    "            if j == i:\n",
    "                continue\n",
    "            w = float(full[i, j])\n",
    "            if w <= 0 or C_lil[i, j] != 0:\n",
    "                continue\n",
    "            C_lil[i, j] = w\n",
    "            C_lil[j, i] = w\n",
    "            deg += 1\n",
    "            if deg >= dmin:\n",
    "                break\n",
    "    C2 = C_lil.tocsr()\n",
    "    C2.setdiag(0.0)\n",
    "    C2.eliminate_zeros()\n",
    "    return C2\n",
    "\n",
    "def _paga_prune(C: sp.csr_matrix, topk: int | None, q: float | None, keep_mst: bool, dmin: int | None) -> sp.csr_matrix:\n",
    "    \"\"\"Prune PAGA adjacency by top-k edges per node and/or global quantile; keep an MST backbone.\"\"\"\n",
    "    n = C.shape[0]\n",
    "    keep = set()\n",
    "\n",
    "    if topk and topk > 0:\n",
    "        for i in range(n):\n",
    "            row = C.getrow(i)\n",
    "            if row.nnz == 0:\n",
    "                continue\n",
    "            idx, dat = row.indices, row.data\n",
    "            k = min(topk, dat.size)\n",
    "            top_idx = idx[np.argpartition(dat, -k)[-k:]]\n",
    "            for j in top_idx:\n",
    "                keep.add((min(i, j), max(i, j)))\n",
    "\n",
    "    if q is not None:\n",
    "        d = C.data\n",
    "        d = d[d > 0]\n",
    "        if d.size:\n",
    "            thr = float(np.quantile(d, q))\n",
    "            coo = C.tocoo()\n",
    "            for i, j, w in zip(coo.row, coo.col, coo.data):\n",
    "                if i != j and w >= thr:\n",
    "                    keep.add((min(i, j), max(i, j)))\n",
    "\n",
    "    if keep_mst and C.nnz > 0:\n",
    "        G = nx.Graph()\n",
    "        coo = C.tocoo()\n",
    "        for i, j, w in zip(coo.row, coo.col, coo.data):\n",
    "            if i != j:\n",
    "                G.add_edge(i, j, weight=1.0 / (w + 1e-9))\n",
    "        T = nx.minimum_spanning_tree(G, weight=\"weight\")\n",
    "        keep |= {(min(u, v), max(u, v)) for u, v in T.edges()}\n",
    "\n",
    "    rows, cols, vals = [], [], []\n",
    "    for (i, j) in keep:\n",
    "        w = float(C[i, j])\n",
    "        if w > 0:\n",
    "            rows += [i, j]\n",
    "            cols += [j, i]\n",
    "            vals += [w, w]\n",
    "\n",
    "    C2 = sp.csr_matrix((vals, (rows, cols)), shape=C.shape)\n",
    "    C2.setdiag(0.0)\n",
    "    C2.eliminate_zeros()\n",
    "\n",
    "    if dmin and dmin > 0:\n",
    "        C2 = _ensure_min_degree(C2, dmin=dmin)\n",
    "\n",
    "    return C2\n",
    "\n",
    "def _fa2_layout(C: sp.csr_matrix, seed_xy: np.ndarray, iters=1000, gravity=1.0, scaling_ratio=2.0) -> np.ndarray:\n",
    "    \"\"\"ForceAtlas2 layout, initialized from seed positions.\"\"\"\n",
    "    fa = ForceAtlas2(\n",
    "        outboundAttractionDistribution=False,\n",
    "        linLogMode=False,\n",
    "        adjustSizes=False,\n",
    "        edgeWeightInfluence=1.0,\n",
    "        jitterTolerance=0.2,\n",
    "        barnesHutOptimize=True,\n",
    "        barnesHutTheta=1.2,\n",
    "        scalingRatio=scaling_ratio,\n",
    "        strongGravityMode=False,\n",
    "        gravity=gravity,\n",
    "        verbose=False,\n",
    "    )\n",
    "    M = C.tolil().astype(np.float32)\n",
    "    P = fa.forceatlas2(M, pos=seed_xy.astype(np.float32), iterations=iters)\n",
    "    return np.asarray(P, dtype=float)\n",
    "\n",
    "def _umap_centroids(sub: ad.AnnData, groups: str) -> tuple[np.ndarray, list[str]]:\n",
    "    \"\"\"Centroids on the (fixed) UMAP for each category.\"\"\"\n",
    "    cats = list(sub.obs[groups].astype(\"category\").cat.categories)\n",
    "    XY = pd.DataFrame(sub.obsm[\"X_umap\"], index=sub.obs_names, columns=[\"x\", \"y\"])\n",
    "    cent = XY.join(sub.obs[groups]).groupby(groups)[[\"x\", \"y\"]].mean().reindex(cats).to_numpy()\n",
    "    return cent, cats\n",
    "\n",
    "def _build_template_positions(adx: ad.AnnData, groups: str, topk: int, q: float, dmin: int, keep_mst=True) -> dict[str, np.ndarray]:\n",
    "    tmp = adx.copy()\n",
    "    # Ensure the basis is Seurat UMAP, not a re-computed scanpy UMAP\n",
    "    if \"X_umap_joint\" in tmp.obsm:\n",
    "        tmp.obsm[\"X_umap\"] = tmp.obsm[\"X_umap_joint\"].copy()\n",
    "    C = _paga_compute(tmp, groups)\n",
    "    Cp = _paga_prune(C, topk=topk, q=q, keep_mst=keep_mst, dmin=dmin)\n",
    "    seed, cats = _umap_centroids(tmp, groups)\n",
    "    P = _fa2_layout(Cp, seed_xy=seed, iters=1000, gravity=1.0, scaling_ratio=2.0)\n",
    "    return {cats[i]: P[i, :] for i in range(len(cats))}\n",
    "\n",
    "# Build templates (global, reused for all subsets)\n",
    "DET_TEMPLATE_POS = _build_template_positions(adata, \"celltype\", topk=3, q=0.60, dmin=2)\n",
    "FAM_TEMPLATE_POS = _build_template_positions(adata, \"celltype_family\", topk=2, q=0.40, dmin=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f652a511",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === P9: PAGA graphs and overlays using Seurat UMAP templates =============\n",
    "metric_key = \"family_potency_norm\"\n",
    "MIN_PAGA_WEIGHT = 0.0  # graph sparsity controlled by _paga_prune, not here\n",
    "\n",
    "def apply_bootstrap_to_Cpr(\n",
    "    Cpr: sp.csr_matrix,\n",
    "    sub: ad.AnnData,\n",
    "    group: str,\n",
    "    boot_mean: pd.Series,\n",
    "    cond: str,\n",
    "    tp: str,\n",
    "    min_weight: float | None = None,\n",
    ") -> sp.csr_matrix:\n",
    "    \"\"\"\n",
    "    Replace PAGA edge weights in Cpr by bootstrap mean weights when available.\n",
    "\n",
    "    - Cpr:       pruned adjacency (csr, symmetric) in group-category order\n",
    "    - sub:       subset AnnData (one cond × timepoint)\n",
    "    - group:     obs column with group labels ('celltype' or 'celltype_family')\n",
    "    - boot_mean: Series indexed by (src, dst, cond, timepoint) -> mean weight\n",
    "    - cond, tp:  current condition and timepoint\n",
    "\n",
    "    We do not drop edges here. Graph sparsity is controlled upstream by\n",
    "    _paga_prune (topk, q, MST, dmin). Any display thresholding is handled\n",
    "    only in the plotting helpers via MIN_PAGA_WEIGHT.\n",
    "    \"\"\"\n",
    "    cats = list(sub.obs[group].astype(\"category\").cat.categories)\n",
    "    if len(cats) == 0:\n",
    "        return Cpr\n",
    "\n",
    "    C = Cpr.tolil(copy=True)\n",
    "    n = len(cats)\n",
    "\n",
    "    # For each existing edge in C, try to replace with bootstrap mean\n",
    "    for i in range(n):\n",
    "        src = cats[i]\n",
    "        row_idx = C.rows[i]\n",
    "        row_dat = C.data[i]\n",
    "        for k, j in enumerate(row_idx):\n",
    "            if j <= i:\n",
    "                continue\n",
    "            if row_dat[k] <= 0:\n",
    "                continue\n",
    "            dst = cats[j]\n",
    "\n",
    "            key     = (src, dst, cond, tp)\n",
    "            key_sym = (dst, src, cond, tp)\n",
    "\n",
    "            w_boot = None\n",
    "            if key in boot_mean.index:\n",
    "                w_boot = float(boot_mean.loc[key])\n",
    "            elif key_sym in boot_mean.index:\n",
    "                w_boot = float(boot_mean.loc[key_sym])\n",
    "\n",
    "            if w_boot is not None:\n",
    "                C[i, j] = w_boot\n",
    "                C[j, i] = w_boot\n",
    "\n",
    "    C = C.tocsr()\n",
    "    C.setdiag(0.0)\n",
    "    C.eliminate_zeros()\n",
    "    return C\n",
    "\n",
    "\n",
    "def _recolor_paga_edges(ax, color=\"0.6\", alpha=0.9):\n",
    "    for coll in ax.collections:\n",
    "        if isinstance(coll, LineCollection):\n",
    "            coll.set_color(color)\n",
    "            coll.set_alpha(alpha)\n",
    "\n",
    "def _paga_plot_with_template(\n",
    "    sub: ad.AnnData,\n",
    "    groups: str,\n",
    "    template_pos: dict[str, np.ndarray],\n",
    "    Cpruned: sp.csr_matrix,\n",
    "    figsize=(18, 14),\n",
    "    node_size_scale=8,\n",
    "    edge_width_scale=0.8,\n",
    "    fontsize=5,\n",
    "    fname=None,\n",
    "):\n",
    "    C_orig = sub.uns[\"paga\"][\"connectivities\"]\n",
    "\n",
    "    # Thresholded copy for plotting\n",
    "    Cplot = Cpruned.copy()\n",
    "    Cplot.data[Cplot.data < MIN_PAGA_WEIGHT] = 0.0\n",
    "    Cplot.eliminate_zeros()\n",
    "\n",
    "    sub.uns[\"paga\"][\"connectivities\"] = Cplot\n",
    "\n",
    "    pos = _map_template_pos(sub, groups, template_pos)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sc.pl.paga(\n",
    "        sub,\n",
    "        pos=pos,\n",
    "        frameon=False,\n",
    "        threshold=0.0,\n",
    "        node_size_scale=node_size_scale,\n",
    "        node_size_power=0.6,\n",
    "        edge_width_scale=edge_width_scale,\n",
    "        fontsize=fontsize,\n",
    "        ax=ax,\n",
    "        show=False,\n",
    "        save=False,\n",
    "        title=\"\",\n",
    "    )\n",
    "    _recolor_paga_edges(ax, \"0.6\", 0.9)\n",
    "\n",
    "    # Edge-confidence legend based on Cplot\n",
    "    from matplotlib.lines import Line2D\n",
    "\n",
    "    Ccoo = Cplot.tocoo()\n",
    "    mask = Ccoo.row < Ccoo.col\n",
    "    edge_w = Ccoo.data[mask]\n",
    "\n",
    "    if edge_w.size > 0:\n",
    "        wmin = float(edge_w.min())\n",
    "        wmax = float(edge_w.max())\n",
    "        min_edge_width = 0.2\n",
    "        max_edge_width = 4.0\n",
    "\n",
    "        w_low  = wmin\n",
    "        w_med  = float(np.median(edge_w))\n",
    "        w_high = wmax\n",
    "        if np.isclose(w_med, w_high) or np.isclose(w_med, w_low):\n",
    "            w_med = w_low + 0.5 * (w_high - w_low)\n",
    "\n",
    "        w_samples = [w_low, w_med, w_high]\n",
    "        labels = [f\"{w_low:.2f} (low)\",\n",
    "                  f\"{w_med:.2f} (mid)\",\n",
    "                  f\"{w_high:.2f} (high)\"]\n",
    "\n",
    "        def _map_width(w):\n",
    "            if wmax > wmin:\n",
    "                base = min_edge_width + (w - wmin) / (wmax - wmin) * (max_edge_width - min_edge_width)\n",
    "            else:\n",
    "                base = (min_edge_width + max_edge_width) * 0.5\n",
    "            return edge_width_scale * base\n",
    "\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color=\"0.6\", linewidth=_map_width(w), label=lab)\n",
    "            for w, lab in zip(w_samples, labels)\n",
    "        ]\n",
    "\n",
    "        ax.legend(\n",
    "            handles=legend_elements,\n",
    "            title=\"PAGA weight\\n(edge confidence)\",\n",
    "            loc=\"upper right\",\n",
    "            frameon=True,\n",
    "            fontsize=fontsize,\n",
    "        )\n",
    "\n",
    "    if fname:\n",
    "        fig.savefig(PLOTS / fname, dpi=450, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    sub.uns[\"paga\"][\"connectivities\"] = C_orig\n",
    "\n",
    "def _paga_plot_metric_with_template(\n",
    "    sub: ad.AnnData,\n",
    "    groups: str,\n",
    "    metric_key: str,\n",
    "    template_pos: dict[str, np.ndarray],\n",
    "    Cpruned: sp.csr_matrix,\n",
    "    figsize=(16, 12),\n",
    "    node_size_scale=8.0,\n",
    "    edge_width_scale=0.8,\n",
    "    fontsize=6,\n",
    "    fname=None,\n",
    "    cmap_name=\"viridis\",\n",
    "    min_edge_width=0.2,\n",
    "    max_edge_width=4.0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Custom PAGA plot where nodes are colored by the average of `metric_key`\n",
    "    per group. Uses precomputed template positions and a pruned adjacency.\n",
    "\n",
    "    - `groups`      : obs column with cluster labels (e.g. 'celltype')\n",
    "    - `metric_key`  : obs column with continuous metric (e.g. 'latent_time')\n",
    "    - `template_pos`: dict {group_label -> (x, y)} from DET/FAM_TEMPLATE_POS\n",
    "    - `Cpruned`     : csr_matrix of shape (n_groups, n_groups) in category order\n",
    "    \"\"\"\n",
    "    if metric_key not in sub.obs.columns:\n",
    "        raise KeyError(f\"{metric_key} not found in sub.obs\")\n",
    "\n",
    "    # Categories (node order) and template positions\n",
    "    cats = list(sub.obs[groups].astype(\"category\").cat.categories)\n",
    "    if len(cats) == 0:\n",
    "        return\n",
    "\n",
    "    pos = _map_template_pos(sub, groups, template_pos)  # shape (n_nodes, 2)\n",
    "\n",
    "    # Mean metric per group (node color)\n",
    "    metric_mean = (\n",
    "        sub.obs[[groups, metric_key]]\n",
    "        .groupby(groups)[metric_key]\n",
    "        .mean()\n",
    "        .reindex(cats)\n",
    "    )\n",
    "    metric_vals = metric_mean.to_numpy()\n",
    "\n",
    "    # Node sizes proportional to cell counts in each group\n",
    "    counts = (\n",
    "        sub.obs[groups]\n",
    "        .value_counts()\n",
    "        .reindex(cats)\n",
    "        .fillna(0)\n",
    "        .to_numpy()\n",
    "    )\n",
    "    # Avoid zeros to keep nodes visible\n",
    "    counts = np.maximum(counts, 1.0)\n",
    "    node_sizes = node_size_scale * np.sqrt(counts)\n",
    "\n",
    "    # Edge list from pruned adjacency\n",
    "    Ccoo = Cpruned.tocoo()\n",
    "    edge_i = []\n",
    "    edge_j = []\n",
    "    edge_w = []\n",
    "    for i, j, w in zip(Ccoo.row, Ccoo.col, Ccoo.data):\n",
    "        if i >= j:\n",
    "            continue  # plot each undirected edge once\n",
    "        edge_i.append(i)\n",
    "        edge_j.append(j)\n",
    "        edge_w.append(w)\n",
    "    edge_w = np.array(edge_w, dtype=float)\n",
    "    if edge_w.size > 0:\n",
    "        # Rescale edge weights to a sensible linewidth range\n",
    "        wmin = edge_w.min()\n",
    "        wmax = edge_w.max()\n",
    "        if wmax > wmin:\n",
    "            edge_widths = min_edge_width + (edge_w - wmin) / (wmax - wmin) * (max_edge_width - min_edge_width)\n",
    "        else:\n",
    "            edge_widths = np.full_like(edge_w, (min_edge_width + max_edge_width) * 0.5)\n",
    "    else:\n",
    "        edge_widths = np.array([])\n",
    "\n",
    "    # Plot\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "\n",
    "    # Edges\n",
    "    for (i, j, lw) in zip(edge_i, edge_j, edge_widths):\n",
    "        x0, y0 = pos[i, 0], pos[i, 1]\n",
    "        x1, y1 = pos[j, 0], pos[j, 1]\n",
    "        ax.plot(\n",
    "            [x0, x1],\n",
    "            [y0, y1],\n",
    "            color=\"0.6\",\n",
    "            alpha=0.9,\n",
    "            linewidth=edge_width_scale * lw,\n",
    "            zorder=1,\n",
    "        )\n",
    "\n",
    "    # Nodes (colored by metric)\n",
    "    cmap = plt.get_cmap(cmap_name)\n",
    "    sc_nodes = ax.scatter(\n",
    "        pos[:, 0],\n",
    "        pos[:, 1],\n",
    "        c=metric_vals,\n",
    "        cmap=cmap,\n",
    "        s=node_sizes,\n",
    "        edgecolor=\"black\",\n",
    "        linewidths=0.3,\n",
    "        zorder=2,\n",
    "    )\n",
    "\n",
    "    # Labels\n",
    "    for k, lbl in enumerate(cats):\n",
    "        ax.text(\n",
    "            pos[k, 0],\n",
    "            pos[k, 1],\n",
    "            str(lbl),\n",
    "            fontsize=fontsize,\n",
    "            ha=\"center\",\n",
    "            va=\"center\",\n",
    "            zorder=3,\n",
    "        )\n",
    "\n",
    "    # Colorbar\n",
    "    cbar = plt.colorbar(sc_nodes, ax=ax)\n",
    "    cbar.set_label(metric_key)\n",
    "\n",
    "    ax.set_aspect(\"equal\")\n",
    "    ax.set_axis_off()\n",
    "    ax.set_title(f\"{groups} – {metric_key}\", fontsize=fontsize + 1)\n",
    "\n",
    "    if fname is not None:\n",
    "        fig.savefig(PLOTS / fname, dpi=450, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "    else:\n",
    "        plt.show()\n",
    "\n",
    "def _paga_overlay_with_template(\n",
    "    sub: ad.AnnData,\n",
    "    groups: str,\n",
    "    template_pos: dict[str, np.ndarray],\n",
    "    Cpruned: sp.csr_matrix,\n",
    "    point_size=3,\n",
    "    point_alpha=0.12,\n",
    "    figsize=(18, 14),\n",
    "    node_size_scale=8,\n",
    "    edge_width_scale=0.8,\n",
    "    fontsize=5,\n",
    "    fname=None,\n",
    "):\n",
    "    C_orig = sub.uns[\"paga\"][\"connectivities\"]\n",
    "\n",
    "    # Use thresholded copy of Cpruned for plotting\n",
    "    Cplot = Cpruned.copy()\n",
    "    Cplot.data[Cplot.data < MIN_PAGA_WEIGHT] = 0.0\n",
    "    Cplot.eliminate_zeros()\n",
    "\n",
    "    sub.uns[\"paga\"][\"connectivities\"] = Cplot\n",
    "\n",
    "    pos = _map_template_pos(sub, groups, template_pos)\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=figsize)\n",
    "    sc.pl.umap(\n",
    "        sub,\n",
    "        color=groups,\n",
    "        alpha=point_alpha,\n",
    "        size=point_size,\n",
    "        frameon=False,\n",
    "        show=False,\n",
    "        title=\"\",\n",
    "        ax=ax,\n",
    "    )\n",
    "    sc.pl.paga(\n",
    "        sub,\n",
    "        pos=pos,\n",
    "        frameon=False,\n",
    "        threshold=0.0,   # already thresholded via Cplot\n",
    "        node_size_scale=node_size_scale,\n",
    "        node_size_power=0.6,\n",
    "        edge_width_scale=edge_width_scale,\n",
    "        fontsize=fontsize,\n",
    "        ax=ax,\n",
    "        show=False,\n",
    "        save=False,\n",
    "        title=\"\",\n",
    "    )\n",
    "    _recolor_paga_edges(ax, \"0.6\", 0.9)\n",
    "\n",
    "    # Edge-confidence legend based on Cplot\n",
    "    from matplotlib.lines import Line2D\n",
    "\n",
    "    Ccoo = Cplot.tocoo()\n",
    "    mask = Ccoo.row < Ccoo.col\n",
    "    edge_w = Ccoo.data[mask]\n",
    "\n",
    "    if edge_w.size > 0:\n",
    "        wmin = float(edge_w.min())\n",
    "        wmax = float(edge_w.max())\n",
    "        min_edge_width = 0.2\n",
    "        max_edge_width = 4.0\n",
    "\n",
    "        w_low  = wmin\n",
    "        w_med  = float(np.median(edge_w))\n",
    "        w_high = wmax\n",
    "        if np.isclose(w_med, w_high) or np.isclose(w_med, w_low):\n",
    "            w_med = w_low + 0.5 * (w_high - w_low)\n",
    "\n",
    "        w_samples = [w_low, w_med, w_high]\n",
    "        labels = [f\"{w_low:.2f} (low)\",\n",
    "                  f\"{w_med:.2f} (mid)\",\n",
    "                  f\"{w_high:.2f} (high)\"]\n",
    "\n",
    "        def _map_width(w):\n",
    "            if wmax > wmin:\n",
    "                base = min_edge_width + (w - wmin) / (wmax - wmin) * (max_edge_width - min_edge_width)\n",
    "            else:\n",
    "                base = (min_edge_width + max_edge_width) * 0.5\n",
    "            return edge_width_scale * base\n",
    "\n",
    "        legend_elements = [\n",
    "            Line2D([0], [0], color=\"0.6\", linewidth=_map_width(w), label=lab)\n",
    "            for w, lab in zip(w_samples, labels)\n",
    "        ]\n",
    "\n",
    "        ax.legend(\n",
    "            handles=legend_elements,\n",
    "            title=\"PAGA weight\\n(edge confidence)\",\n",
    "            loc=\"upper right\",\n",
    "            frameon=True,\n",
    "            fontsize=fontsize,\n",
    "        )\n",
    "\n",
    "    if fname:\n",
    "        fig.savefig(PLOTS / fname, dpi=450, bbox_inches=\"tight\")\n",
    "        plt.close(fig)\n",
    "\n",
    "    sub.uns[\"paga\"][\"connectivities\"] = C_orig\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Detailed cell types\n",
    "# -------------------------------------------------------------------------\n",
    "for tp in TP_ORDER:\n",
    "    for cond in COND_ORDER:\n",
    "        sub = _subset(adata, cond=cond, tp=tp)\n",
    "        if sub.n_obs == 0 or sub.obs[\"celltype\"].nunique() < 2:\n",
    "            continue\n",
    "\n",
    "        apply_palette(sub, \"celltype\", DETAILED_COLS, strict=False)\n",
    "        _subset_neighbors_from_global(sub)\n",
    "        sc.tl.paga(sub, groups=\"celltype\")  # undirected, topology only\n",
    "\n",
    "        C = sub.uns[\"paga\"][\"connectivities\"].tocsr().maximum(\n",
    "            sub.uns[\"paga\"][\"connectivities\"].T\n",
    "        ).tocsr()\n",
    "        C.setdiag(0.0)\n",
    "        C.eliminate_zeros()\n",
    "        Cpr = _paga_prune(C, topk=3, q=0.60, keep_mst=True, dmin=2)\n",
    "        # replace PAGA weights by bootstrap mean weights and threshold\n",
    "        #Cpr = apply_bootstrap_to_Cpr(\n",
    "        #    Cpr,\n",
    "        #    sub,\n",
    "        #    group=\"celltype\",\n",
    "        #    boot_mean=boot_mean_cell,\n",
    "        #    cond=cond,\n",
    "        #    tp=tp,\n",
    "        #    min_weight=MIN_PAGA_WEIGHT,        \n",
    "        #)\n",
    "\n",
    "        # PAGA graph and overlay (cells colored by celltype)\n",
    "        _paga_plot_with_template(\n",
    "            sub,\n",
    "            \"celltype\",\n",
    "            DET_TEMPLATE_POS,\n",
    "            Cpr,\n",
    "            figsize=(20, 16),\n",
    "            node_size_scale=20,\n",
    "            edge_width_scale=0.9,\n",
    "            fontsize=12,\n",
    "            fname=f\"PAGA_GRAPH_celltype_tpl_top3_q60_{cond}_{tp}.pdf\",\n",
    "        )\n",
    "        _paga_overlay_with_template(\n",
    "            sub,\n",
    "            \"celltype\",\n",
    "            DET_TEMPLATE_POS,\n",
    "            Cpr,\n",
    "            figsize=(20, 16),\n",
    "            node_size_scale=20,\n",
    "            edge_width_scale=0.9,\n",
    "            fontsize=12,\n",
    "            fname=f\"PAGA_OVERLAY_celltype_tpl_top3_q60_{cond}_{tp}.pdf\",\n",
    "        )\n",
    "\n",
    "        # PAGA colored by latent time and potency (per node = mean over cells)\n",
    "        if \"latent_time\" in sub.obs.columns:\n",
    "            _paga_plot_metric_with_template(\n",
    "                sub,\n",
    "                \"celltype\",\n",
    "                \"latent_time\",\n",
    "                DET_TEMPLATE_POS,\n",
    "                Cpr,\n",
    "                figsize=(20, 16),\n",
    "                node_size_scale=20,\n",
    "                edge_width_scale=0.9,\n",
    "                fontsize=12,\n",
    "                fname=f\"PAGA_LATENTTIME_celltype_tpl_{cond}_{tp}.pdf\",\n",
    "            )\n",
    "        if \"potency_surrogate\" in sub.obs.columns:\n",
    "            _paga_plot_metric_with_template(\n",
    "                sub,\n",
    "                \"celltype\",\n",
    "                \"potency_surrogate\",\n",
    "                DET_TEMPLATE_POS,\n",
    "                Cpr,\n",
    "                figsize=(20, 16),\n",
    "                node_size_scale=20,\n",
    "                edge_width_scale=0.9,\n",
    "                fontsize=12,\n",
    "                fname=f\"PAGA_POTENCY_celltype_tpl_{cond}_{tp}.pdf\",\n",
    "            )\n",
    "\n",
    "# -------------------------------------------------------------------------\n",
    "# Families\n",
    "# -------------------------------------------------------------------------\n",
    "for tp in TP_ORDER:\n",
    "    for cond in COND_ORDER:\n",
    "        sub = _subset(adata, cond=cond, tp=tp)\n",
    "        if sub.n_obs == 0 or sub.obs[\"celltype_family\"].nunique() < 2:\n",
    "            continue\n",
    "\n",
    "        apply_palette(sub, \"celltype_family\", FAMILY_COLORS, strict=False)\n",
    "        _subset_neighbors_from_global(sub)\n",
    "        sc.tl.paga(sub, groups=\"celltype_family\")\n",
    "\n",
    "        C = sub.uns[\"paga\"][\"connectivities\"].tocsr().maximum(\n",
    "            sub.uns[\"paga\"][\"connectivities\"].T\n",
    "        ).tocsr()\n",
    "        C.setdiag(0.0)\n",
    "        C.eliminate_zeros()\n",
    "        Cpr = _paga_prune(C, topk=2, q=0.40, keep_mst=True, dmin=1)\n",
    "        #Cpr = apply_bootstrap_to_Cpr(\n",
    "        #    Cpr,\n",
    "        #    sub,\n",
    "        #    group=\"celltype_family\",\n",
    "        #    boot_mean=boot_mean_fam,\n",
    "        #    cond=cond,\n",
    "        #    tp=tp,\n",
    "        #    min_weight=MIN_PAGA_WEIGHT,\n",
    "        #)\n",
    "        _paga_plot_with_template(\n",
    "            sub,\n",
    "            \"celltype_family\",\n",
    "            FAM_TEMPLATE_POS,\n",
    "            Cpr,\n",
    "            figsize=(16, 12),\n",
    "            node_size_scale=20,\n",
    "            edge_width_scale=0.8,\n",
    "            fontsize=12,\n",
    "            fname=f\"PAGA_GRAPH_family_tpl_top2_q40_{cond}_{tp}.pdf\",\n",
    "        )\n",
    "        _paga_overlay_with_template(\n",
    "            sub,\n",
    "            \"celltype_family\",\n",
    "            FAM_TEMPLATE_POS,\n",
    "            Cpr,\n",
    "            figsize=(16, 12),\n",
    "            node_size_scale=20,\n",
    "            edge_width_scale=0.8,\n",
    "            fontsize=12,\n",
    "            fname=f\"PAGA_OVERLAY_family_tpl_top2_q40_{cond}_{tp}.pdf\",\n",
    "        )\n",
    "\n",
    "        if \"latent_time\" in sub.obs.columns:\n",
    "            _paga_plot_metric_with_template(\n",
    "                sub,\n",
    "                \"celltype_family\",\n",
    "                \"latent_time\",\n",
    "                FAM_TEMPLATE_POS,\n",
    "                Cpr,\n",
    "                figsize=(16, 12),\n",
    "                node_size_scale=20,\n",
    "                edge_width_scale=0.8,\n",
    "                fontsize=12,\n",
    "                fname=f\"PAGA_LATENTTIME_family_tpl_{cond}_{tp}.pdf\",\n",
    "            )\n",
    "        if \"potency_surrogate\" in sub.obs.columns:\n",
    "            _paga_plot_metric_with_template(\n",
    "                sub,\n",
    "                \"celltype_family\",\n",
    "                \"potency_surrogate\",\n",
    "                FAM_TEMPLATE_POS,\n",
    "                Cpr,\n",
    "                figsize=(16, 12),\n",
    "                node_size_scale=20,\n",
    "                edge_width_scale=0.8,\n",
    "                fontsize=12,\n",
    "                fname=f\"PAGA_POTENCY_family_tpl_{cond}_{tp}.pdf\",\n",
    "            )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa30289a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# === P10: concise summary plots (optional) ======================================\n",
    "# These are quick, publication-style summaries of ELAC2-specific deltas\n",
    "# derived in P7 (pivot_fam/long_fam and pivot_cell/long_cell).\n",
    "#\n",
    "# Outputs go to ./plots as PDF.\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "def _ensure_dir(p: Path) -> None:\n",
    "    p.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "_ensure_dir(PLOTS)\n",
    "\n",
    "def plot_family_delta_heatmap(long_fam: pd.DataFrame, tp: str, vlim: float = 0.02) -> None:\n",
    "    \"\"\"Heatmap of family-level Δ connectivity (ELAC2-specific) for one timepoint.\"\"\"\n",
    "    sub = long_fam[(long_fam[\"metric\"] == \"delta_ELAC2_specific\") & (long_fam[\"timepoint\"] == tp)].copy()\n",
    "    if sub.empty:\n",
    "        return\n",
    "\n",
    "    labels = sorted(set(sub[\"src\"]) | set(sub[\"dst\"]))\n",
    "    mat = pd.DataFrame(0.0, index=labels, columns=labels)\n",
    "    for _, r in sub.iterrows():\n",
    "        mat.loc[r[\"src\"], r[\"dst\"]] = r[\"value\"]\n",
    "        mat.loc[r[\"dst\"], r[\"src\"]] = r[\"value\"]\n",
    "\n",
    "    plt.figure(figsize=(8, 7))\n",
    "    sns.heatmap(\n",
    "        mat, cmap=\"coolwarm\", center=0.0,\n",
    "        vmin=-vlim, vmax=vlim,\n",
    "        square=True,\n",
    "        cbar_kws={\"label\": \"Δ connectivity (ELAC2-specific)\"},\n",
    "    )\n",
    "    plt.title(f\"Family-level ELAC2-specific Δ connectivity, {tp}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS / f\"PAGA_family_delta_heatmap_{tp}.pdf\", dpi=450, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "def degree_delta(long_tbl: pd.DataFrame, tp: str) -> pd.DataFrame:\n",
    "    \"\"\"Undirected degree-like net delta per node (sum of incident Δ edges).\"\"\"\n",
    "    d = long_tbl[(long_tbl[\"metric\"] == \"delta_ELAC2_specific\") & (long_tbl[\"timepoint\"] == tp)].copy()\n",
    "    if d.empty:\n",
    "        return pd.DataFrame(columns=[\"node\", \"deg_delta\"])\n",
    "    a = d[[\"src\", \"value\"]].rename(columns={\"src\": \"node\"})\n",
    "    b = d[[\"dst\", \"value\"]].rename(columns={\"dst\": \"node\"})\n",
    "    both = pd.concat([a, b], ignore_index=True)\n",
    "    out = both.groupby(\"node\", as_index=False)[\"value\"].sum().rename(columns={\"value\": \"deg_delta\"})\n",
    "    return out\n",
    "\n",
    "def plot_family_degree_delta(long_fam: pd.DataFrame, tp: str) -> None:\n",
    "    df = degree_delta(long_fam, tp).sort_values(\"deg_delta\")\n",
    "    if df.empty:\n",
    "        return\n",
    "\n",
    "    plt.figure(figsize=(6, 5))\n",
    "    colors = [\"#d73027\" if v < 0 else \"#1a9850\" for v in df[\"deg_delta\"]]\n",
    "    sns.barplot(data=df, x=\"deg_delta\", y=\"node\", palette=colors)\n",
    "    plt.axvline(0, color=\"k\", linewidth=0.5)\n",
    "    plt.xlabel(\"Net Δ connectivity (ELAC2-specific)\")\n",
    "    plt.ylabel(\"\")\n",
    "    plt.title(f\"Net gain/loss of connectivity per family, {tp}\")\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(PLOTS / f\"PAGA_family_net_delta_{tp}.pdf\", dpi=450, bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "\n",
    "# Run summary plots for all timepoints\n",
    "for tp in TP_ORDER:\n",
    "    plot_family_delta_heatmap(long_fam, tp)\n",
    "    plot_family_degree_delta(long_fam, tp)\n"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 5
}
