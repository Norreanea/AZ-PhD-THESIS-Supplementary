<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>Scripts</title>

<script src="site_libs/header-attrs-2.30/header-attrs.js"></script>
<script src="site_libs/jquery-3.6.0/jquery-3.6.0.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="site_libs/bootstrap-3.3.5/css/flatly.min.css" rel="stylesheet" />
<script src="site_libs/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="site_libs/bootstrap-3.3.5/shim/respond.min.js"></script>
<style>h1 {font-size: 34px;}
       h1.title {font-size: 38px;}
       h2 {font-size: 30px;}
       h3 {font-size: 24px;}
       h4 {font-size: 18px;}
       h5 {font-size: 16px;}
       h6 {font-size: 12px;}
       code {color: inherit; background-color: rgba(0, 0, 0, 0.04);}
       pre:not([class]) { background-color: white }</style>
<script src="site_libs/jqueryui-1.13.2/jquery-ui.min.js"></script>
<link href="site_libs/tocify-1.9.1/jquery.tocify.css" rel="stylesheet" />
<script src="site_libs/tocify-1.9.1/jquery.tocify.js"></script>
<script src="site_libs/navigation-1.1/tabsets.js"></script>
<link href="site_libs/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="site_libs/highlightjs-9.12.0/highlight.js"></script>
<link href="site_libs/pagedtable-1.1/css/pagedtable.css" rel="stylesheet" />
<script src="site_libs/pagedtable-1.1/js/pagedtable.js"></script>
<link href="site_libs/htmltools-fill-0.5.8.1/fill.css" rel="stylesheet" />
<script src="site_libs/htmlwidgets-1.6.4/htmlwidgets.js"></script>
<link href="site_libs/datatables-css-0.0.0/datatables-crosstalk.css" rel="stylesheet" />
<script src="site_libs/datatables-binding-0.34.0/datatables.js"></script>
<link href="site_libs/dt-core-1.13.6/css/jquery.dataTables.min.css" rel="stylesheet" />
<link href="site_libs/dt-core-1.13.6/css/jquery.dataTables.extra.css" rel="stylesheet" />
<script src="site_libs/dt-core-1.13.6/js/jquery.dataTables.min.js"></script>
<link href="site_libs/crosstalk-1.2.2/css/crosstalk.min.css" rel="stylesheet" />
<script src="site_libs/crosstalk-1.2.2/js/crosstalk.min.js"></script>

<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>

<style type="text/css">code{white-space: pre;}</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>









<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
details > summary > p:only-child {
  display: inline;
}
pre code {
  padding: 0;
}
</style>


<style type="text/css">
.dropdown-submenu {
  position: relative;
}
.dropdown-submenu>.dropdown-menu {
  top: 0;
  left: 100%;
  margin-top: -6px;
  margin-left: -1px;
  border-radius: 0 6px 6px 6px;
}
.dropdown-submenu:hover>.dropdown-menu {
  display: block;
}
.dropdown-submenu>a:after {
  display: block;
  content: " ";
  float: right;
  width: 0;
  height: 0;
  border-color: transparent;
  border-style: solid;
  border-width: 5px 0 5px 5px;
  border-left-color: #cccccc;
  margin-top: 5px;
  margin-right: -10px;
}
.dropdown-submenu:hover>a:after {
  border-left-color: #adb5bd;
}
.dropdown-submenu.pull-left {
  float: none;
}
.dropdown-submenu.pull-left>.dropdown-menu {
  left: -100%;
  margin-left: 10px;
  border-radius: 6px 0 6px 6px;
}
</style>

<script type="text/javascript">
// manage active state of menu based on current page
$(document).ready(function () {
  // active menu anchor
  href = window.location.pathname
  href = href.substr(href.lastIndexOf('/') + 1)
  if (href === "")
    href = "index.html";
  var menuAnchor = $('a[href="' + href + '"]');

  // mark the anchor link active (and if it's in a dropdown, also mark that active)
  var dropdown = menuAnchor.closest('li.dropdown');
  if (window.bootstrap) { // Bootstrap 4+
    menuAnchor.addClass('active');
    dropdown.find('> .dropdown-toggle').addClass('active');
  } else { // Bootstrap 3
    menuAnchor.parent().addClass('active');
    dropdown.addClass('active');
  }

  // Navbar adjustments
  var navHeight = $(".navbar").first().height() + 15;
  var style = document.createElement('style');
  var pt = "padding-top: " + navHeight + "px; ";
  var mt = "margin-top: -" + navHeight + "px; ";
  var css = "";
  // offset scroll position for anchor links (for fixed navbar)
  for (var i = 1; i <= 6; i++) {
    css += ".section h" + i + "{ " + pt + mt + "}\n";
  }
  style.innerHTML = "body {" + pt + "padding-bottom: 40px; }\n" + css;
  document.head.appendChild(style);
});
</script>

<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before, .tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "\e259";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "\e258";
  font-family: 'Glyphicons Halflings';
  border: none;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
  background-color: transparent;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->



<style type="text/css">

#TOC {
  margin: 25px 0px 20px 0px;
}
@media (max-width: 768px) {
#TOC {
  position: relative;
  width: 100%;
}
}

@media print {
.toc-content {
  /* see https://github.com/w3c/csswg-drafts/issues/4434 */
  float: right;
}
}

.toc-content {
  padding-left: 30px;
  padding-right: 40px;
}

div.main-container {
  max-width: 1200px;
}

div.tocify {
  width: 20%;
  max-width: 260px;
  max-height: 85%;
}

@media (min-width: 768px) and (max-width: 991px) {
  div.tocify {
    width: 25%;
  }
}

@media (max-width: 767px) {
  div.tocify {
    width: 100%;
    max-width: none;
  }
}

.tocify ul, .tocify li {
  line-height: 20px;
}

.tocify-subheader .tocify-item {
  font-size: 0.90em;
}

.tocify .list-group-item {
  border-radius: 0px;
}


</style>



</head>

<body>


<div class="container-fluid main-container">


<!-- setup 3col/9col grid for toc_float and main content  -->
<div class="row">
<div class="col-xs-12 col-sm-4 col-md-3">
<div id="TOC" class="tocify">
</div>
</div>

<div class="toc-content col-xs-12 col-sm-8 col-md-9">




<div class="navbar navbar-default  navbar-fixed-top" role="navigation">
  <div class="container">
    <div class="navbar-header">
      <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-bs-toggle="collapse" data-target="#navbar" data-bs-target="#navbar">
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
        <span class="icon-bar"></span>
      </button>
      <a class="navbar-brand" href="index.html">Supplementary</a>
    </div>
    <div id="navbar" class="navbar-collapse collapse">
      <ul class="nav navbar-nav">
        <li>
  <a href="index.html">Home</a>
</li>
<li>
  <a href="umap.html">UMAP</a>
</li>
<li>
  <a href="figures.html">Figures</a>
</li>
<li>
  <a href="tables.html">Tables</a>
</li>
<li>
  <a href="scripts.html">Scripts</a>
</li>
      </ul>
      <ul class="nav navbar-nav navbar-right">
        
      </ul>
    </div><!--/.nav-collapse -->
  </div><!--/.container -->
</div><!--/.navbar -->

<div id="header">



<h1 class="title toc-ignore">Scripts</h1>

</div>


<div class="datatables html-widget html-fill-item" id="htmlwidget-621f2315e47bb9171c0c" style="width:100%;height:auto;"></div>
<script type="application/json" data-for="htmlwidget-621f2315e47bb9171c0c">{"x":{"filter":"none","vertical":false,"data":[["script_1.R","script_2.py","script_3.R","script_4.R","script_5.R","script_6.ipynb","script_7.sh","script_8.R"],["r","py","r","r","r","ipynb","sh","r"],["<a href=\"scripts/script_1.R\" target=\"_blank\" rel=\"noopener\">Open<\/a>","<a href=\"scripts/script_2.py\" target=\"_blank\" rel=\"noopener\">Open<\/a>","<a href=\"scripts/script_3.R\" target=\"_blank\" rel=\"noopener\">Open<\/a>","<a href=\"scripts/script_4.R\" target=\"_blank\" rel=\"noopener\">Open<\/a>","<a href=\"scripts/script_5.R\" target=\"_blank\" rel=\"noopener\">Open<\/a>","<a href=\"scripts/script_6.ipynb\" target=\"_blank\" rel=\"noopener\">Open<\/a>","<a href=\"scripts/script_7.sh\" target=\"_blank\" rel=\"noopener\">Open<\/a>","<a href=\"scripts/script_8.R\" target=\"_blank\" rel=\"noopener\">Open<\/a>"],["<a href=\"scripts/script_1.R\" download>Download<\/a>","<a href=\"scripts/script_2.py\" download>Download<\/a>","<a href=\"scripts/script_3.R\" download>Download<\/a>","<a href=\"scripts/script_4.R\" download>Download<\/a>","<a href=\"scripts/script_5.R\" download>Download<\/a>","<a href=\"scripts/script_6.ipynb\" download>Download<\/a>","<a href=\"scripts/script_7.sh\" download>Download<\/a>","<a href=\"scripts/script_8.R\" download>Download<\/a>"]],"container":"<table class=\"display\">\n  <thead>\n    <tr>\n      <th>File<\/th>\n      <th>Type<\/th>\n      <th>Open<\/th>\n      <th>Download<\/th>\n    <\/tr>\n  <\/thead>\n<\/table>","options":{"pageLength":25,"scrollX":true,"dom":"Bfrtip","buttons":["copy","csv"],"columnDefs":[{"name":"File","targets":0},{"name":"Type","targets":1},{"name":"Open","targets":2},{"name":"Download","targets":3}],"order":[],"autoWidth":false,"orderClasses":false},"selection":{"mode":"multiple","selected":null,"target":"row","selectable":null}},"evals":[],"jsHooks":[]}</script>
<div id="previews-r-and-shell-scripts" class="section level2">
<h2>Previews (R and shell scripts)</h2>
<div id="script_1.r" class="section level3">
<h3>script_1.R</h3>
<ul>
<li><a href="scripts/script_1.R" target="_blank" rel="noopener">Open</a>
- <a href="scripts/script_1.R" download>Download</a></li>
</ul>
<pre class="r"><code>
#   Clean, reproducible pipeline to:
#   1) read Bowtie2-mapped small-RNA tables from multiple references (RNAcentral,
#      planarian tRNA set, rRNA set, transcriptome, genome),
#   2) assign an RNA class (miRNA, tRF, rRF, etc.) using consistent rules,
#   3) compute a *consensus* annotation per unique sequence (resolve multi-hits),
#   4) build a sample-by-feature count matrix and CPM-filter it for DGE.


# ----------------------------
# 0) Packages 
# ----------------------------
install_if_missing &lt;- function(pkgs, bioc = FALSE) {
  for (p in pkgs) {
    if (!requireNamespace(p, quietly = TRUE)) {
      if (!bioc) {
        install.packages(p, repos = &quot;https://cloud.r-project.org&quot;)
      } else {
        if (!requireNamespace(&quot;BiocManager&quot;, quietly = TRUE)) {
          install.packages(&quot;BiocManager&quot;, repos = &quot;https://cloud.r-project.org&quot;)
        }
        BiocManager::install(p, update = FALSE, ask = FALSE)
      }
    }
  }
}

cran_pkgs &lt;- c(&quot;data.table&quot;, &quot;dplyr&quot;, &quot;stringr&quot;, &quot;purrr&quot;, &quot;tidyr&quot;, &quot;forcats&quot;, &quot;ggplot2&quot;, &quot;ggrepel&quot;, &quot;scales&quot;)
bioc_pkgs &lt;- c(&quot;GenomicAlignments&quot;, &quot;Biostrings&quot;, &quot;edgeR&quot;)

install_if_missing(cran_pkgs, bioc = FALSE)
install_if_missing(bioc_pkgs, bioc = TRUE)

# ----------------------------
# 1) Configuration
# ----------------------------
cfg &lt;- list(
  # Input directories
  dir_rnacentral  = &quot;F:/PARN_ELAC_silencing/smallRNA/calculated_data_bowtie2_end_to_end/mapped_to_RNAcentral/mapped_seq_with_strand_new/&quot;,
  dir_trna_map    = &quot;E:/Illumina/PARN_ELAC2_silencing/smallRNA/smallRNAwithAdapters/miRNA/bowtie2_mapped_SM_tRNA_seq_with_strand/&quot;,
  dir_rrna_map    = &quot;F:/PARN_ELAC_silencing/smallRNA/calculated_data_bowtie2_end_to_end/mapped_to_rRNA_and_genome/rRNA_seq_with_strand/&quot;,
  dir_transcript  = &quot;F:/PARN_ELAC_silencing/smallRNA/calculated_data_bowtie2_end_to_end/mapped_to_transcriptome/mapped_seq_with_strand/&quot;,
  dir_genome      = &quot;F:/PARN_ELAC_silencing/smallRNA/calculated_data_bowtie2_end_to_end/mapped_to_genome/mapped_seq_with_strand/&quot;,
  
  # Output
  out_dir         = &quot;F:/PARN_ELAC_silencing/smallRNA/clean_pipeline_out/&quot;,
  
  # Filtering
  keep_strand     = 0L,   # keep only strand == 0 
  max_total_mm    = 3L,   # keep reads with (XM + non-match cigar ops) &lt;= 3
  
  # CPM filtering for DGE
  cpm_threshold   = 10,
  cpm_min_samples = 2L
)

if (!dir.exists(cfg$out_dir)) dir.create(cfg$out_dir, recursive = TRUE)

# ----------------------------
# 2) Helpers
# ----------------------------


revcomp_chr &lt;- function(x) {
  as.character(Biostrings::reverseComplement(Biostrings::DNAStringSet(x)))
}

# Read a mapping table 
read_map_tbl &lt;- function(path) {
  dt &lt;- data.table::fread(
    path,
    header = FALSE,
    fill = TRUE,
    showProgress = FALSE
  )
  
  # Keep only the first 9 columns and name them consistently.
  if (ncol(dt) &lt; 9) {
    stop(&quot;File has &lt; 9 columns: &quot;, path)
  }
  dt &lt;- dt[, 1:9]
  data.table::setnames(dt, c(&quot;read&quot;, &quot;strand&quot;, &quot;ref&quot;, &quot;position&quot;, &quot;qual&quot;, &quot;cigar&quot;, &quot;seq&quot;, &quot;XM&quot;, &quot;MD&quot;))
  dt
}

parse_xm &lt;- function(xm_chr) {
  out &lt;- suppressWarnings(as.integer(stringr::str_replace(xm_chr, &quot;^XM:i:&quot;, &quot;&quot;)))
  out[is.na(out)] &lt;- 0L
  out
}

# Compute non-match operations in CIGAR using GenomicAlignments::cigarOpTable.
cigar_nonmatch_ops &lt;- function(cigar_chr) {
  op &lt;- GenomicAlignments::cigarOpTable(cigar_chr)
  
  # Count matches separately (M plus &quot;=&quot; if present); everything else is &quot;non-match ops&quot;.
  match_cols &lt;- intersect(colnames(op), c(&quot;M&quot;, &quot;=&quot;))
  nonmatch_cols &lt;- setdiff(colnames(op), match_cols)
  
  nonmatch &lt;- if (length(nonmatch_cols) == 0) rep.int(0L, nrow(op)) else rowSums(op[, nonmatch_cols, drop = FALSE])
  match    &lt;- if (length(match_cols) == 0) rep.int(0L, nrow(op)) else rowSums(op[, match_cols, drop = FALSE])
  
  list(nonmatch = as.integer(nonmatch), match = as.integer(match))
}

# RNA class assignment (single source of truth, used everywhere).
rna_type_from_ref &lt;- function(ref_chr) {
  # Priority is encoded by order of case_when clauses (top wins).
  dplyr::case_when(
    stringr::str_detect(ref_chr, stringr::regex(&quot;multiple_hits&quot;, ignore_case = TRUE)) ~ &quot;multiple_hits&quot;,
    stringr::str_detect(ref_chr, stringr::regex(&quot;dd_Smed_v6&quot;, ignore_case = TRUE)) ~ &quot;mRNA fragments&quot;,
    
    # rRNA-like
    stringr::str_detect(ref_chr, stringr::regex(&quot;ribosomal|\\brRNA\\b|ITS1|ITS2|SpacerA|\\b28S\\b|\\b12S\\b|\\b16S\\b|5\\.8S|Schmed_cloneH735c&quot;, ignore_case = TRUE)) ~ &quot;rRNA fragments&quot;,
    
    # tRNA-like
    stringr::str_detect(ref_chr, stringr::regex(&quot;\\btRNA\\b|transfer&quot;, ignore_case = TRUE)) ~ &quot;tRNA fragments&quot;,
    
    # sno/sn
    stringr::str_detect(ref_chr, stringr::regex(&quot;snoRNA|nucleolar&quot;, ignore_case = TRUE)) ~ &quot;snoRNA fragments&quot;,
    stringr::str_detect(ref_chr, stringr::regex(&quot;snRNA|spliceosomal|\\b7SK\\b|nuclear&quot;, ignore_case = TRUE)) ~ &quot;snRNA fragments&quot;,
    
    # small regulatory
    stringr::str_detect(ref_chr, stringr::regex(&quot;piRNA&quot;, ignore_case = TRUE)) ~ &quot;piRNA&quot;,
    stringr::str_detect(ref_chr, stringr::regex(&quot;miRNA|microRNA|\\bmiR\\b|Sme-|sme-lin|sme-let|Sme-Bantam&quot;, ignore_case = TRUE)) ~ &quot;miRNA&quot;,
    
    # lnc
    stringr::str_detect(ref_chr, stringr::regex(&quot;long_non-coding|\\blnc\\b&quot;, ignore_case = TRUE)) ~ &quot;lncRNA fragments&quot;,
    
    TRUE ~ &quot;other fragments&quot;
  )
}

#  sample are ELAC13S, WT25S, GFP33S, etc.
sample_to_group &lt;- function(sample_id) {
  #  ELAC13S -&gt; ELAC3S
  stringr::str_replace(sample_id, &quot;^(ELAC|WT|GFP|PARN)\\d(3S|5S)$&quot;, &quot;\\1\\2&quot;)
}

list_basenames &lt;- function(dir_path) {
  list.files(dir_path, full.names = FALSE, all.files = FALSE)
}

common_basenames &lt;- function(dirs) {
  bn &lt;- purrr::map(dirs, list_basenames)
  Reduce(intersect, bn)
}

# ----------------------------
# 3) Per-sample processing
# ----------------------------
process_one_sample &lt;- function(basename_file, cfg) {
  # Read each source
  dt_rc   &lt;- read_map_tbl(file.path(cfg$dir_rnacentral, basename_file))
  dt_trna &lt;- read_map_tbl(file.path(cfg$dir_trna_map, basename_file))
  dt_rrna &lt;- read_map_tbl(file.path(cfg$dir_rrna_map, basename_file))
  dt_tx   &lt;- read_map_tbl(file.path(cfg$dir_transcript, basename_file))
  
  # Annotate tRNA/rRNA sources 
  dt_trna[, RNA_type := &quot;tRNA fragments&quot;]
  dt_rrna[, RNA_type := &quot;rRNA fragments&quot;]
  
  # Annotate RNAcentral
  dt_rc[, RNA_type := rna_type_from_ref(ref)]
  
  # Priority logic 
  # 1) keep tRNA mappings first (remove those reads from RNAcentral set)
  dt_rc2 &lt;- dt_rc[!(read %in% dt_trna$read)]
  dt_all &lt;- data.table::rbindlist(list(dt_rc2, dt_trna), use.names = TRUE, fill = TRUE)
  
  # 2) add rRNA mappings only for reads not already present
  dt_rrna2 &lt;- dt_rrna[!(read %in% dt_all$read)]
  dt_all &lt;- data.table::rbindlist(list(dt_all, dt_rrna2), use.names = TRUE, fill = TRUE)
  
  # 3) add transcriptome mappings (mRNA fragments) only for remaining reads
  dt_tx2 &lt;- dt_tx[!(read %in% dt_all$read)]
  dt_tx2[, RNA_type := &quot;mRNA fragments&quot;]
  dt_all &lt;- data.table::rbindlist(list(dt_all, dt_tx2), use.names = TRUE, fill = TRUE)
  
  # Compute mismatch features
  cig &lt;- cigar_nonmatch_ops(dt_all$cigar)
  dt_all[, cigar_match    := cig$match]
  dt_all[, cigar_nonmatch := cig$nonmatch]
  dt_all[, xm_mm          := parse_xm(XM)]
  dt_all[, all_mm         := xm_mm + cigar_nonmatch]
  
  # Compute oriented sequence 
  dt_all[, orig_seq := ifelse(strand == 0, seq, revcomp_chr(seq))]
  
  # Apply filters 
  dt_all &lt;- dt_all[strand == cfg$keep_strand &amp; all_mm &lt;= cfg$max_total_mm]
  
  dt_all[, .(
    read, strand, ref, position, cigar, seq, orig_seq,
    RNA_type, XM, MD, cigar_match, cigar_nonmatch, xm_mm, all_mm
  )]
}

# ----------------------------
# 4) Consensus annotation per unique sequence
# ----------------------------
#   - build unique (orig_seq, pos_ref) pairs from all samples,
#   - classify each pos_ref,
#   - if a sequence maps to multiple types, prefer:
#       (1) tRNA fragments
#       (2) entries containing &quot;Schmidtea&quot;
#       (3) &quot;other fragments&quot; (only if no tRNA)
#       else &quot;multiple_hits&quot;
build_consensus_annotation &lt;- function(dt_all_samples) {
  dt &lt;- data.table::as.data.table(dt_all_samples)
  
  # pos_ref includes coordinate + ref 
  dt[, pos_ref := paste(position, ref, sep = &quot;_&quot;)]
  
  # Unique mapping candidates
  uniq &lt;- unique(dt[, .(orig_seq, pos_ref)])
  
  # Classify based on pos_ref content 
  uniq[, RNA_type := rna_type_from_ref(pos_ref)]
  
  # Determine if any sequence has multiple RNA types
  uniq[, correct_annotation := {
    # All candidates for this orig_seq
    pos_all &lt;- pos_ref
    type_all &lt;- RNA_type
    
    # Preference 1: any tRNA hit
    if (any(type_all == &quot;tRNA fragments&quot;)) {
      pos_all[which(type_all == &quot;tRNA fragments&quot;)[1]]
    } else if (any(stringr::str_detect(pos_all, stringr::regex(&quot;Schmidtea&quot;, ignore_case = TRUE)))) {
      pos_all[which(stringr::str_detect(pos_all, stringr::regex(&quot;Schmidtea&quot;, ignore_case = TRUE)))[1]]
    } else if (any(type_all == &quot;other fragments&quot;)) {
      pos_all[which(type_all == &quot;other fragments&quot;)[1]]
    } else {
      &quot;multiple_hits&quot;
    }
  }, by = orig_seq]
  
  uniq[, correct_RNA_type := rna_type_from_ref(correct_annotation)]
  
  # One row per orig_seq
  out &lt;- unique(uniq[, .(orig_seq, correct_annotation, correct_RNA_type)])
  out
}

# ----------------------------
# 5) Genome-only add-in 
# ----------------------------
read_genome_only &lt;- function(basename_file, cfg) {
  dt_g &lt;- read_map_tbl(file.path(cfg$dir_genome, basename_file))
  dt_g[, RNA_type := &quot;genome&quot;]
  
  cig &lt;- cigar_nonmatch_ops(dt_g$cigar)
  dt_g[, cigar_match    := cig$match]
  dt_g[, cigar_nonmatch := cig$nonmatch]
  dt_g[, xm_mm          := parse_xm(XM)]
  dt_g[, all_mm         := xm_mm + cigar_nonmatch]
  dt_g[, orig_seq       := ifelse(strand == 0, seq, revcomp_chr(seq))]
  
  dt_g &lt;- dt_g[strand == cfg$keep_strand &amp; all_mm &lt;= cfg$max_total_mm]
  
  dt_g[, .(
    read, strand, ref, position, cigar, seq, orig_seq,
    RNA_type, XM, MD, cigar_match, cigar_nonmatch, xm_mm, all_mm
  )]
}

# ----------------------------
# 6) Count matrix + CPM filtering
# ----------------------------
make_count_matrix &lt;- function(sample_tables) {
  # Build (seq_anno, sample, n) long table and cast wide.
  dt_long &lt;- data.table::rbindlist(
    lapply(names(sample_tables), function(sid) {
      dt &lt;- data.table::as.data.table(sample_tables[[sid]])
      dt[, seq_anno := paste(orig_seq, correct_annotation, sep = &quot; &quot;)]
      dt[, .(n = .N), by = .(seq_anno)][, sample := sid][]
    }),
    use.names = TRUE, fill = TRUE
  )
  
  dt_wide &lt;- data.table::dcast(dt_long, seq_anno ~ sample, value.var = &quot;n&quot;, fill = 0)
  
  # Convert to numeric matrix for edgeR::cpm
  mat &lt;- as.matrix(dt_wide[, -1])
  storage.mode(mat) &lt;- &quot;numeric&quot;
  rownames(mat) &lt;- dt_wide$seq_anno
  
  mat
}

cpm_filter &lt;- function(count_mat, cpm_threshold = 10, min_samples = 2L) {
  cpm &lt;- edgeR::cpm(count_mat)
  keep &lt;- rowSums(cpm &gt; cpm_threshold) &gt;= min_samples
  list(cpm = cpm, keep = keep)
}

# ==============================================================================
# 7) Run the pipeline
# ==============================================================================
dirs_needed &lt;- c(cfg$dir_rnacentral, cfg$dir_trna_map, cfg$dir_rrna_map, cfg$dir_transcript)
basenames &lt;- common_basenames(dirs_needed)

if (length(basenames) == 0) {
  stop(&quot;No common basenames found across the required directories.&quot;)
}

# --- A) Build per-sample tables (no genome)
sample_tbls &lt;- purrr::set_names(vector(&quot;list&quot;, length(basenames)), basenames)
for (bn in basenames) {
  message(&quot;Processing (no genome): &quot;, bn)
  sample_tbls[[bn]] &lt;- process_one_sample(bn, cfg)
}

# Create a stable sample_id from basename 
sample_ids &lt;- stringr::str_replace(basenames, &quot;\\.[^.]*$&quot;, &quot;&quot;)
names(sample_tbls) &lt;- sample_ids

# Add group labels like ELAC3S / WT5S
for (sid in names(sample_tbls)) {
  dt &lt;- data.table::as.data.table(sample_tbls[[sid]])
  dt[, set := sample_to_group(sid)]
  sample_tbls[[sid]] &lt;- dt
}

# --- B) Build consensus annotation map from all samples
dt_all &lt;- data.table::rbindlist(sample_tbls, use.names = TRUE, fill = TRUE)
anno_map &lt;- build_consensus_annotation(dt_all)

# Save annotation map
saveRDS(anno_map, file.path(cfg$out_dir, &quot;consensus_annotation_map.rds&quot;))
data.table::fwrite(anno_map, file.path(cfg$out_dir, &quot;consensus_annotation_map.csv&quot;))

# --- C) Attach consensus annotation to each sample table
sample_tbls_anno &lt;- lapply(sample_tbls, function(dt) {
  dt &lt;- data.table::as.data.table(dt)
  dt2 &lt;- merge(dt, anno_map, by = &quot;orig_seq&quot;, all.x = TRUE)
  
  # If something is NA ...
  dt2[is.na(correct_annotation), correct_annotation := paste(position, ref, sep = &quot;_&quot;)]
  dt2[is.na(correct_RNA_type),   correct_RNA_type   := rna_type_from_ref(correct_annotation)]
  
  dt2
})

saveRDS(sample_tbls_anno, file.path(cfg$out_dir, &quot;sample_tables_no_genome_annotated.rds&quot;))

# --- Add genome-only reads (heavy)

basenames_g &lt;- common_basenames(c(cfg$dir_genome, cfg$dir_rnacentral))
basenames_g &lt;- intersect(basenames_g, basenames)  # keep aligned set

genome_tbls &lt;- purrr::set_names(vector(&quot;list&quot;, length(basenames_g)), basenames_g)
for (bn in basenames_g) {
  message(&quot;Processing (genome): &quot;, bn)
  genome_tbls[[bn]] &lt;- read_genome_only(bn, cfg)
}
names(genome_tbls) &lt;- stringr::str_replace(basenames_g, &quot;\\.[^.]*$&quot;, &quot;&quot;)

# Append genome reads not already assigned in no-genome set (by read ID)
sample_tbls_with_genome &lt;- lapply(names(sample_tbls_anno), function(sid) {
  dt_no &lt;- data.table::as.data.table(sample_tbls_anno[[sid]])
  
  if (!sid %in% names(genome_tbls)) return(dt_no)
  
  dt_g &lt;- data.table::as.data.table(genome_tbls[[sid]])
  dt_g &lt;- dt_g[!(read %in% dt_no$read)]
  dt_g[, set := sample_to_group(sid)]
  dt_g[, correct_annotation := ref]
  dt_g[, correct_RNA_type := &quot;genome&quot;]
  
  data.table::rbindlist(list(dt_no, dt_g), use.names = TRUE, fill = TRUE)
})
names(sample_tbls_with_genome) &lt;- names(sample_tbls_anno)

saveRDS(sample_tbls_with_genome, file.path(cfg$out_dir, &quot;sample_tables_with_genome_annotated.rds&quot;))

# --- E) Build count matrix (features are &quot;orig_seq + correct_annotation&quot;)
count_mat &lt;- make_count_matrix(sample_tbls_with_genome)
saveRDS(count_mat, file.path(cfg$out_dir, &quot;count_matrix.rds&quot;))

# --- F) CPM + filtering
flt &lt;- cpm_filter(count_mat, cfg$cpm_threshold, cfg$cpm_min_samples)
saveRDS(flt$cpm,  file.path(cfg$out_dir, &quot;cpm_matrix.rds&quot;))
saveRDS(flt$keep, file.path(cfg$out_dir, &quot;cpm_keep_mask.rds&quot;))

# Save filtered matrices (optional)
count_mat_keep &lt;- count_mat[flt$keep, , drop = FALSE]
cpm_keep &lt;- flt$cpm[flt$keep, , drop = FALSE]
saveRDS(count_mat_keep, file.path(cfg$out_dir, &quot;count_matrix_cpm_filtered.rds&quot;))
saveRDS(cpm_keep,       file.path(cfg$out_dir, &quot;cpm_matrix_filtered.rds&quot;))

# --- G) Minimal QC plots 
# 1) Composition per &quot;set&quot; (ELAC3S/GFP3S/WT3S/...)
plot_composition &lt;- function(sample_tables, out_png) {
  dt &lt;- data.table::rbindlist(sample_tables, use.names = TRUE, fill = TRUE)
  dt_sum &lt;- dt[, .N, by = .(set, correct_RNA_type)]
  dt_sum[, perc := 100 * N / sum(N), by = set]
  
  p &lt;- ggplot2::ggplot(
    dt_sum,
    ggplot2::aes(x = &quot;&quot;, y = perc, fill = correct_RNA_type)
  ) +
    ggplot2::geom_col(color = &quot;white&quot;) +
    ggplot2::coord_polar(theta = &quot;y&quot;) +
    ggplot2::facet_wrap(~set, nrow = 2) +
    ggplot2::theme_void() +
    ggplot2::theme(
      legend.title = ggplot2::element_blank()
    )
  
  ggplot2::ggsave(out_png, p, width = 12, height = 6, dpi = 300)
}

plot_composition(
  sample_tbls_with_genome,
  file.path(cfg$out_dir, &quot;rna_type_composition_by_set.png&quot;)
)

message(&quot;Done. Outputs written to: &quot;, cfg$out_dir)</code></pre>
</div>
<div id="script_3.r" class="section level3">
<h3>script_3.R</h3>
<ul>
<li><a href="scripts/script_3.R" target="_blank" rel="noopener">Open</a>
- <a href="scripts/script_3.R" download>Download</a></li>
</ul>
<pre class="r"><code># Purpose
#   Evaluate integration quality on a chosen embedding (usually PCA):
#     - iLISI: local mixing by batch/condition (higher = better mixing)
#     - cLISI-derived purity: local purity by cell type (higher = better purity)
#     - kBET: average rejection rate of local batch-mixing tests (lower = better mixing)


# ----------------------------
# 0) Package checks
# ----------------------------
check_pkg &lt;- function(pkg) {
  if (!requireNamespace(pkg, quietly = TRUE)) {
    stop(&quot;Missing package: &quot;, pkg, &quot; (install it first).&quot;, call. = FALSE)
  }
}
check_pkg(&quot;Seurat&quot;)
check_pkg(&quot;lisi&quot;)   # immunogenomics/LISI (R package name: lisi)
check_pkg(&quot;kBET&quot;)
check_pkg(&quot;ggplot2&quot;)
check_pkg(&quot;dplyr&quot;)

# ----------------------------
# 1) Core metric function
# ----------------------------
score_embedding &lt;- function(obj,
                            condition_col   = &quot;condition&quot;,
                            celltype_col    = &quot;final_population&quot;,
                            reduction       = &quot;pca&quot;,
                            dims            = 1:30,
                            lisi_perplexity = 30,   # effective neighborhood size in LISI (not kNN k)
                            kbet_k0         = 15,   # neighborhood size for kBET
                            kbet_max_cells  = 5000, # subsample for speed (stratified by condition)
                            seed            = 1) {
  
  md &lt;- obj@meta.data
  stopifnot(all(c(condition_col, celltype_col) %in% colnames(md)))
  stopifnot(reduction %in% names(obj@reductions))
  
  emb_all &lt;- Seurat::Embeddings(obj, reduction = reduction)
  stopifnot(max(dims) &lt;= ncol(emb_all))
  emb &lt;- emb_all[, dims, drop = FALSE]
  
  # Keep only complete cases for the two labels
  keep &lt;- stats::complete.cases(md[, c(condition_col, celltype_col), drop = FALSE])
  emb  &lt;- emb[keep, , drop = FALSE]
  md   &lt;- md[keep, , drop = FALSE]
  
  # Force factors (required for correct level counting)
  batch    &lt;- factor(md[[condition_col]])
  celltype &lt;- factor(md[[celltype_col]])
  
  B &lt;- nlevels(batch)
  C &lt;- nlevels(celltype)
  
  # ---- LISI (per-cell) ----
  # compute_lisi returns a data.frame with one column per label in label_colnames
  lisi_vals &lt;- lisi::compute_lisi(
    X              = emb,
    meta_data      = md[, c(condition_col, celltype_col), drop = FALSE],
    label_colnames = c(condition_col, celltype_col),
    perplexity     = lisi_perplexity
  )
  
  iLISI &lt;- lisi_vals[[condition_col]]
  cLISI &lt;- lisi_vals[[celltype_col]]
  
  # Normalize iLISI to 0..1 where 0 = no mixing, 1 = maximal mixing given B batches
  iLISI_norm &lt;- (iLISI - 1) / max(1, B - 1)
  
  # Convert cLISI to a &quot;purity&quot; score in 0..1 where 1 = perfectly pure neighborhoods
  # (cLISI = 1 means only one cell type locally; cLISI = C means full mixing)
  cPUR_norm &lt;- (C - cLISI) / max(1, C - 1)
  
  stats_fun &lt;- function(x) {
    c(
      mean   = mean(x, na.rm = TRUE),
      median = stats::median(x, na.rm = TRUE),
      p10    = unname(stats::quantile(x, 0.10, na.rm = TRUE)),
      p90    = unname(stats::quantile(x, 0.90, na.rm = TRUE))
    )
  }
  
  # ---- kBET ----
  set.seed(seed)
  idx &lt;- seq_len(nrow(emb))
  if (length(idx) &gt; kbet_max_cells) {
    by_batch &lt;- split(idx, batch)
    sizes &lt;- vapply(by_batch, length, integer(1))
    
    # Allocate approximately proportionally (guarantee at least 1 per batch if possible)
    alloc &lt;- pmax(1L, floor(kbet_max_cells * sizes / sum(sizes)))
    # Trim if we overshot due to pmax(1)
    while (sum(alloc) &gt; kbet_max_cells) {
      j &lt;- which.max(alloc)
      if (alloc[j] &gt; 1L) alloc[j] &lt;- alloc[j] - 1L else break
    }
    
    idx &lt;- sort(unlist(Map(function(ix, m) sample(ix, size = min(m, length(ix))), by_batch, alloc), use.names = FALSE))
  }
  
  X_sub     &lt;- emb[idx, , drop = FALSE]
  batch_sub &lt;- factor(batch[idx])
  
  # Use k0 and turn off heuristic so kBET does not silently change neighborhood size
  kbet_res &lt;- tryCatch(
    kBET::kBET(
      df        = X_sub,
      batch     = batch_sub,
      k0        = kbet_k0,
      heuristic = FALSE,
      do.pca    = FALSE,
      plot      = FALSE,
      verbose   = FALSE
    ),
    error = function(e) e
  )
  
  kBET_mean_reject &lt;- NA_real_
  kBET_p025 &lt;- NA_real_
  kBET_p975 &lt;- NA_real_
  
  if (!inherits(kbet_res, &quot;error&quot;) &amp;&amp; is.list(kbet_res)) {
    if (!is.null(kbet_res$stats) &amp;&amp; &quot;kBET.observed&quot; %in% colnames(kbet_res$stats)) {
      obs &lt;- kbet_res$stats[, &quot;kBET.observed&quot;]
      kBET_mean_reject &lt;- mean(obs, na.rm = TRUE)
      kBET_p025 &lt;- unname(stats::quantile(obs, 0.025, na.rm = TRUE))
      kBET_p975 &lt;- unname(stats::quantile(obs, 0.975, na.rm = TRUE))
    } else if (!is.null(kbet_res$summary) &amp;&amp; &quot;kBET.observed&quot; %in% names(kbet_res$summary)) {
      # Fallback: single observed rate from the summary
      kBET_mean_reject &lt;- unname(kbet_res$summary[[&quot;kBET.observed&quot;]])
    }
  }
  
  list(
    n_cells          = nrow(emb),
    n_batches        = B,
    n_celltypes      = C,
    iLISI_norm_stats = stats_fun(iLISI_norm),
    cPUR_norm_stats  = stats_fun(cPUR_norm),
    kBET_mean_reject = kBET_mean_reject,
    kBET_p025        = kBET_p025,
    kBET_p975        = kBET_p975
  )
}

# ----------------------------
# 2) Helpers
# ----------------------------
read_result_rdata &lt;- function(path, object_name = NULL) {
  e &lt;- new.env(parent = emptyenv())
  objs &lt;- load(path, envir = e)
  
  if (!is.null(object_name)) {
    if (!object_name %in% objs) stop(&quot;Object &#39;&quot;, object_name, &quot;&#39; not found in: &quot;, path, call. = FALSE)
    return(e[[object_name]])
  }
  
  # Pick the first list that contains expected fields
  is_score &lt;- function(x) {
    is.list(x) &amp;&amp; all(c(&quot;iLISI_norm_stats&quot;, &quot;cPUR_norm_stats&quot;, &quot;kBET_mean_reject&quot;) %in% names(x))
  }
  hits &lt;- objs[vapply(objs, function(nm) is_score(e[[nm]]), logical(1))]
  if (length(hits) == 0) stop(&quot;No score-like object found in: &quot;, path, call. = FALSE)
  e[[hits[1]]]
}

# ----------------------------
# 3) Summarize and plot (three metrics)
# ----------------------------
summarize_scores &lt;- function(res_list) {
  # res_list: named list of score_embedding() outputs, names are approach labels
  dplyr::bind_rows(lapply(names(res_list), function(nm) {
    res &lt;- res_list[[nm]]
    data.frame(
      approach     = nm,
      n_cells      = res$n_cells,
      n_conditions = res$n_batches,
      n_celltypes  = res$n_celltypes,
      
      iLISI_med = unname(res$iLISI_norm_stats[&quot;median&quot;]),
      iLISI_p10 = unname(res$iLISI_norm_stats[&quot;p10&quot;]),
      iLISI_p90 = unname(res$iLISI_norm_stats[&quot;p90&quot;]),
      
      cPUR_med  = unname(res$cPUR_norm_stats[&quot;median&quot;]),
      cPUR_p10  = unname(res$cPUR_norm_stats[&quot;p10&quot;]),
      cPUR_p90  = unname(res$cPUR_norm_stats[&quot;p90&quot;]),
      
      kBET_mean = unname(res$kBET_mean_reject),
      kBET_p025 = unname(res$kBET_p025),
      kBET_p975 = unname(res$kBET_p975),
      
      stringsAsFactors = FALSE
    )
  }))
}

make_plot_df &lt;- function(df_sum) {
  dplyr::bind_rows(
    dplyr::transmute(
      df_sum,
      approach,
      metric = &quot;Condition mixing (iLISI, normalized)&quot;,
      center = iLISI_med, low = iLISI_p10, high = iLISI_p90
    ),
    dplyr::transmute(
      df_sum,
      approach,
      metric = &quot;Cell-type purity (cLISI-derived, normalized)&quot;,
      center = cPUR_med, low = cPUR_p10, high = cPUR_p90
    ),
    dplyr::transmute(
      df_sum,
      approach,
      metric = &quot;kBET rejection rate by condition&quot;,
      center = kBET_mean, low = kBET_p025, high = kBET_p975
    )
  )
}

plot_integration_metrics &lt;- function(df_plot, approach_levels = NULL) {
  if (!is.null(approach_levels)) {
    df_plot$approach &lt;- factor(df_plot$approach, levels = approach_levels)
  } else {
    df_plot$approach &lt;- factor(df_plot$approach, levels = rev(unique(df_plot$approach)))
  }
  
  ggplot2::ggplot(df_plot, ggplot2::aes(x = approach, y = center)) +
    ggplot2::geom_pointrange(
      ggplot2::aes(ymin = low, ymax = high),
      color = &quot;grey60&quot;,
      na.rm = TRUE
    ) +
    ggplot2::geom_point(color = &quot;black&quot;, size = 2, na.rm = TRUE) +
    ggplot2::coord_flip() +
    ggplot2::facet_wrap(~ metric, scales = &quot;fixed&quot;) +
    ggplot2::theme_classic() +
    ggplot2::labs(x = NULL, y = NULL)
}


# res1 &lt;- score_embedding(INTEGR_WEG0_PJ, condition_col = &quot;condition&quot;, celltype_col = &quot;CellType&quot;)
# res2 &lt;- score_embedding(integrated_seurat_obj, condition_col = &quot;condition&quot;, celltype_col = &quot;possibly_final_anno&quot;)
# res3 &lt;- score_embedding(result_obj, condition_col = &quot;condition&quot;, celltype_col = &quot;final_population&quot;)
# saveRDS(res1, &quot;res1.rds&quot;); saveRDS(res2, &quot;res2.rds&quot;); saveRDS(res3, &quot;res3.rds&quot;)

# res_paths &lt;- c(
#   &quot;WT-only integrated (Harmony)&quot;          = &quot;G:/PhD_final/integration_presentation/res1.RData&quot;,
#   &quot;All samples integrated (Harmony)&quot;      = &quot;G:/PhD_final/integration_presentation/res2.RData&quot;,
#   &quot;All samples merged (no integration)&quot;   = &quot;G:/PhD_final/integration_presentation/res3.RData&quot;
# )
# res_list &lt;- lapply(res_paths, read_result_rdata)
# 
# df_sum  &lt;- summarize_scores(res_list)
# df_plot &lt;- make_plot_df(df_sum)
# 
# p &lt;- plot_integration_metrics(df_plot, approach_levels = rev(names(res_paths)))
# 
# print(df_sum)
# print(p)</code></pre>
</div>
<div id="script_4.r" class="section level3">
<h3>script_4.R</h3>
<ul>
<li><a href="scripts/script_4.R" target="_blank" rel="noopener">Open</a>
- <a href="scripts/script_4.R" download>Download</a></li>
</ul>
<pre class="r"><code># Auto-annotation pipeline 

suppressPackageStartupMessages({
  library(Seurat)
  library(Matrix)
  library(dplyr)
  library(tidyr)
  library(stringr)
  library(purrr)
  library(openxlsx)
  library(igraph)
})
suppressPackageStartupMessages(library(future))
plan(sequential)

if (.Platform$OS.type == &quot;windows&quot; &amp;&amp; exists(&quot;memory.limit&quot;)) {
  try(suppressWarnings(memory.limit(size = 56000)), silent = TRUE)
}

# ---------------------------
# Config (tuned defaults)
# ---------------------------
cfg &lt;- list(
  paths = list(
    seurat_rdata   = &quot;D:/scRNA-seq/AZ_final_obj/seurat_obj_new.RData&quot;,
    matrix_rds     = NULL,
    markers_xlsx   = &quot;G:/PhD_final/cell_markers_curated_new_new.xlsx&quot;,
    anno_rdata     = &quot;E:/Stringtie_anno/SM_anno/final/final_final/pfam_swiss_ncbi_merged_only_genes_dedup.RData&quot;,
    out_xlsx       = sprintf(
      &quot;G:/PhD_final/auto_annotation_%s.xlsx&quot;,
      format(Sys.time(), &quot;%Y%m%d_%H%M&quot;)
    )
  ),
  ckpt_dir        = &quot;G:/PhD_final/sncRNA/.auto_annot_ckpts&quot;,
  use_qs          = TRUE,
  qs_preset       = &quot;balanced&quot;,
  
  base_assay      = &quot;SCT&quot;,
  pca_name        = &quot;pca.auto&quot;,
  umap_name       = &quot;umap.auto&quot;,
  max_pcs         = 60L,
  variance_cut    = 0.90,
  knee_smooth     = 5L,
  
  target_n_clusters = 60L,
  k_grid            = c(5L, 8L, 10L, 15L, 20L),
  res_grid          = c(seq(0.4, 2.0, by = 0.2), 1.8, 2.0),
  res_init          = 0.6,
  res_max           = 10,
  grid_max_steps    = 20,
  
  tiny_frac_cut     = 0.015,
  agree_cut         = 0.75,
  
  sub_npcs          = 30L,
  seed              = 42L,
  sub_k_grid        = c(10L, 15L, 20L, 25L),
  sub_res_grid      = seq(0.5, 3.5, by = 0.25),
  sub_min_cells_for_split = 30L,
  sub_max_children  = 6L,
  sub_min_child_n    = 10L,
  sub_min_child_prop = 0.005,
  
  annot_features_max    = 1500L,
  annot_skip_deg        = TRUE,
  deg_subsample_per_ident = 2000L,
  
  enable_ucell     = TRUE,
  ucell_min_genes  = 3L,
  ucell_cells_per_cluster = 1000L,
  ucell_max_signatures   = 300L,
  ucell_ncores     = 1L,
  
  write_round1_degs = TRUE
)
set.seed(cfg$seed)

# Optional packages
has_ucell     &lt;- requireNamespace(&quot;UCell&quot;, quietly = TRUE)
has_fgsea     &lt;- requireNamespace(&quot;fgsea&quot;, quietly = TRUE)
has_cellmanam &lt;- requireNamespace(&quot;CellMaNam&quot;, quietly = TRUE)
has_qs        &lt;- requireNamespace(&quot;qs&quot;, quietly = TRUE)
has_digest    &lt;- requireNamespace(&quot;digest&quot;, quietly = TRUE)

# ---------------------------
# Helpers
# ---------------------------
`%||%` &lt;- function(a, b) if (!is.null(a)) a else b
trim &lt;- function(x)
  gsub(&quot;^\\s+|\\s+$&quot;, &quot;&quot;, x)
canon_cluster &lt;- function(v) {
  v &lt;- as.character(v)
  v &lt;- trimws(v)
  v &lt;- sub(&quot;^X([0-9]+)$&quot;, &quot;g\\1&quot;, v)
  v &lt;- sub(&quot;^([0-9]+)$&quot;, &quot;g\\1&quot;, v)
  v
}
sanitize_sheet &lt;- function(x) {
  x &lt;- gsub(&quot;[\\*\\?/\\\\\\[\\]:]&quot;, &quot;_&quot;, x)
  x &lt;- substr(x, 1, 31)
  make.unique(x)
}
pick_layer_arg &lt;- function() {
  if (&quot;layer&quot; %in% names(formals(Seurat::FindAllMarkers)))
    &quot;layer&quot;
  else
    &quot;slot&quot;
}
apply_mapping &lt;- function(keys, map_named) {
  out &lt;- rep(NA_character_, length(keys))
  m &lt;- match(keys, names(map_named))
  hit &lt;- !is.na(m)
  out[hit] &lt;- unname(map_named[m[hit]])
  out
}
as_chr_collapse &lt;- function(x) {
  if (is.null(x)) return(&quot;&quot;)
  if (is.list(x)) x &lt;- unlist(x, recursive = TRUE, use.names = FALSE)
  x &lt;- unique(na.omit(as.character(x)))
  if (!length(x)) &quot;&quot; else paste(x, collapse = &quot;; &quot;)
}


# IO/ckpt ------------------------------------------------------------
CKPT_DIR &lt;- cfg$ckpt_dir
.dir_ok &lt;- function() {
  dir.create(CKPT_DIR, showWarnings = FALSE, recursive = TRUE)
  TRUE
}
ckpt_path_qs  &lt;- function(stage)
  file.path(CKPT_DIR, paste0(&quot;auto_annot_ckpt_&quot;, stage, &quot;.qs&quot;))
ckpt_path_rds &lt;- function(stage)
  file.path(CKPT_DIR, paste0(&quot;auto_annot_ckpt_&quot;, stage, &quot;.rds&quot;))
ckpt_has  &lt;- function(stage)
  file.exists(ckpt_path_qs(stage)) ||
  file.exists(ckpt_path_rds(stage))
ckpt_save &lt;- function(stage, value) {
  .dir_ok()
  if (has_qs &amp;&amp;
      isTRUE(cfg$use_qs))
    qs::qsave(value, ckpt_path_qs(stage), preset = cfg$qs_preset)
  else
    saveRDS(value, ckpt_path_rds(stage))
}
ckpt_load &lt;- function(stage) {
  if (file.exists(ckpt_path_qs(stage)))
    return(qs::qread(ckpt_path_qs(stage)))
  readRDS(ckpt_path_rds(stage))
}
wb_load_or_new &lt;- function(path) if (file.exists(path)) openxlsx::loadWorkbook(path) else openxlsx::createWorkbook()
wb_save &lt;- function(wb, path)
  openxlsx::saveWorkbook(wb, path, overwrite = TRUE)
ckpt_update &lt;- function(stage, st, ...) {
  up &lt;- list(...)
  for (nm in names(up))
    st[[nm]] &lt;- up[[nm]]
  ckpt_save(stage, st)
}

# Memory diet ------------------------------------------------------------
diet_for_checkpoint &lt;- function(obj,
                                keep_assay  = cfg$base_assay,
                                keep_reduc  = c(cfg$pca_name, cfg$umap_name, paste0(cfg$umap_name, &quot;.v2&quot;)),
                                keep_graphs = character(),
                                drop_counts = TRUE,
                                drop_scale  = TRUE) {
  DefaultAssay(obj) &lt;- keep_assay
  obj@assays     &lt;- obj@assays[intersect(names(obj@assays), keep_assay)]
  obj@reductions &lt;- obj@reductions[intersect(names(obj@reductions), keep_reduc)]
  obj@graphs     &lt;- obj@graphs[intersect(names(obj@graphs), keep_graphs)]
  
  v &lt;- tryCatch(
    utils::packageVersion(&quot;SeuratObject&quot;),
    error = function(e)
      package_version(&quot;4.0.0&quot;)
  )
  if (v &gt;= package_version(&quot;5.0.0&quot;)) {
    Seurat::DietSeurat(
      obj,
      assays = names(obj@assays),
      dimreducs = names(obj@reductions),
      graphs = names(obj@graphs),
      layers = setNames(list(&quot;data&quot;), names(obj@assays))
    )
  } else {
    Seurat::DietSeurat(
      obj,
      assays = names(obj@assays),
      counts = !drop_counts,
      data = TRUE,
      scale.data = !drop_scale,
      dimreducs = names(obj@reductions),
      graphs = names(obj@graphs),
      features = NULL
    )
  }
}

# Stats helpers ----------------------------------------------------------
.named_or_fail &lt;- function(x, expect_names, method_name) {
  if (!length(x))
    return(x)
  if (is.null(names(x)) || any(is.na(names(x)) | names(x) == &quot;&quot;)) {
    if (!missing(expect_names) &amp;&amp; length(x) == length(expect_names)) {
      names(x) &lt;- as.character(expect_names)
    } else {
      stop(
        sprintf(
          &quot;Annotation method produced an unnamed vector; method=%s len=%d&quot;,
          method_name,
          length(x)
        )
      )
    }
  }
  names(x) &lt;- canon_cluster(names(x))
  x
}
.run_annot_method &lt;- function(label,
                              fun,
                              expect_clusters,
                              ckpt_stage_tag = &quot;annot&quot;) {
  message(sprintf(&quot;[annot] %s: running...&quot;, label))
  v &lt;- tryCatch(
    fun(),
    error = function(e) {
      message(sprintf(&quot;[annot] %s: ERROR -&gt; %s&quot;, label, conditionMessage(e)))
      return(setNames(character(0), character(0)))
    }
  )
  v &lt;- .named_or_fail(v, expect_clusters, label)
  if (length(v))
    v &lt;- v[names(v) %in% as.character(expect_clusters)]
  tag &lt;- paste0(ckpt_stage_tag, &quot;_&quot;, label)
  try(ckpt_save(
    tag,
    list(
      method = label,
      result = v,
      expect_clusters = as.character(expect_clusters),
      saved_at = Sys.time()
    )
  ), silent = TRUE)
  message(sprintf(&quot;[annot] %s: %d label(s).&quot;, label, length(v)))
  v
}

choose_pcs_by_knee &lt;- function(stdev,
                               max_pcs = 50L,
                               variance_cut = 0.90,
                               smooth_k = 5L,
                               min_pcs = 25L) {
  stdev &lt;- stdev[is.finite(stdev) &amp; stdev &gt; 0]
  stdev &lt;- stdev[seq_len(min(length(stdev), max_pcs))]
  if (!length(stdev))
    return(min_pcs)
  
  var_ratio &lt;- stdev^2 / sum(stdev^2)
  cumvar &lt;- cumsum(var_ratio)
  ceil &lt;- which(cumvar &gt;= variance_cut)[1]
  if (is.na(ceil))
    ceil &lt;- length(var_ratio)
  
  y &lt;- var_ratio
  if (length(y) &gt;= (smooth_k * 2 + 1)) {
    y &lt;- stats::filter(y, rep(1 / (smooth_k * 2 + 1), smooth_k * 2 + 1), sides = 2)
    y[is.na(y)] &lt;- var_ratio[is.na(y)]
  }
  d2 &lt;- diff(y, differences = 2)
  knee &lt;- which.min(d2) + 1L
  
  pcs &lt;- max(min_pcs, min(max(10L, knee), ceil))
  pcs &lt;- min(pcs, length(stdev))
  pcs
}

avg_by_group_sparse &lt;- function(X, groups) {
  stopifnot(inherits(X, &quot;dgCMatrix&quot;))
  groups &lt;- droplevels(factor(groups))
  G &lt;- Matrix::sparse.model.matrix(~ groups - 1)
  sums &lt;- X %*% G
  n_per &lt;- Matrix::colSums(G)
  Dinv &lt;- Matrix::Diagonal(x = as.numeric(1 / n_per))
  avg &lt;- sums %*% Dinv
  colnames(avg) &lt;- levels(groups)
  avg
}
get_graph_modularity &lt;- function(obj, graph.name, membership) {
  S &lt;- obj@graphs[[graph.name]]
  if (is.null(S))
    return(NA_real_)
  if (!methods::is(S, &quot;dgCMatrix&quot;))
    S &lt;- as(S, &quot;dgCMatrix&quot;)
  S &lt;- Matrix::drop0((S + Matrix::t(S)) / 2)
  Matrix::diag(S) &lt;- 0
  trip &lt;- as.data.frame(Matrix::summary(S))
  trip &lt;- trip[trip$i &lt; trip$j &amp;
                 trip$x &gt; 0, c(&quot;i&quot;, &quot;j&quot;, &quot;x&quot;), drop = FALSE]
  if (!nrow(trip))
    return(NA_real_)
  vnames &lt;- colnames(S)
  if (is.null(vnames))
    vnames &lt;- seq_len(ncol(S))
  g &lt;- igraph::graph_from_data_frame(
    data.frame(
      from = vnames[trip$i],
      to = vnames[trip$j],
      weight = trip$x
    ),
    directed = FALSE,
    vertices = data.frame(name = vnames)
  )
  mvec &lt;- membership
  if (!is.null(names(mvec)))
    mvec &lt;- mvec[V(g)$name]
  else
    names(mvec) &lt;- V(g)$name
  memb &lt;- as.integer(factor(mvec))
  igraph::modularity(g, membership = memb, weights = igraph::E(g)$weight)
}
score_solution &lt;- function(obj,
                           graph.name,
                           idents,
                           target_n,
                           tiny_cut) {
  memb &lt;- as.character(idents)
  nclu &lt;- length(unique(memb))
  n    &lt;- length(memb)
  tab  &lt;- sort(table(memb), decreasing = TRUE)
  tiny_frac &lt;- if (length(tab))
    sum(tab &lt; (tiny_cut * n)) / length(tab)
  else
    1
  mod &lt;- suppressWarnings(get_graph_modularity(obj, graph.name, memb))
  if (!is.finite(mod) || mod &lt; 1e-6) {
    return(data.frame(
      n_clusters = nclu,
      modularity = mod,
      tiny_frac = tiny_frac,
      score = -Inf
    ))
  }
  if (is.na(target_n))
    close &lt;- 0
  else {
    close &lt;- 1 - (abs(nclu - target_n) / max(target_n, nclu))
    close &lt;- max(0, min(close, 1))
  }
  tiny_pen &lt;- pmin(0.4, tiny_frac * 0.8)
  score &lt;- 0.70 * close + 0.25 * mod - 0.05 * tiny_pen
  data.frame(
    n_clusters = nclu,
    modularity = mod,
    tiny_frac = tiny_frac,
    score = score
  )
}

# Marker prep ------------------------------------------------------------
prepare_marker_ref &lt;- function(cell_markers_df,
                               gene_col = &quot;Markers_positive_SMESG&quot;,
                               general_col = &quot;Cell_population_general&quot;,
                               detailed_col = &quot;Cell_population_detailed&quot;,
                               neg_col = NULL,
                               weight_col = NULL) {
  gene_col &lt;- match.arg(gene_col)
  df &lt;- as.data.frame(cell_markers_df, stringsAsFactors = FALSE)
  norm &lt;- function(v)
    trim(as.character(v))
  gene     &lt;- norm(df[[gene_col]])
  general  &lt;- norm(df[[general_col]])
  detailed &lt;- norm(df[[detailed_col]])
  neg_vec &lt;- if (!is.null(neg_col) &amp;&amp;
                 neg_col %in% names(df))
    as.logical(df[[neg_col]])
  else
    FALSE
  weight_vec &lt;- if (!is.null(weight_col) &amp;&amp;
                    weight_col %in% names(df))
    suppressWarnings(as.numeric(df[[weight_col]]))
  else
    NA_real_
  general[general %in% c(&quot;Protonephridia&quot;, &quot;Protonephridia &quot;)] &lt;- &quot;Protonephridia&quot;
  detailed[detailed %in% c(&quot;Protonephridial tubule precursor &quot;,
                           &quot;Protonephridia tubule precursor&quot;)] &lt;- &quot;Protonephridial tubule precursor&quot;
  pos &lt;- tibble::tibble(
    gene = gene,
    general = general,
    detailed = detailed,
    neg = neg_vec,
    weight = weight_vec
  ) %&gt;%
    dplyr::filter(gene != &quot;&quot; &amp;
                    general != &quot;&quot; &amp;
                    detailed != &quot;&quot;) %&gt;% dplyr::distinct()
  ref_general  &lt;- pos %&gt;% dplyr::transmute(gene, final_cluster = general, weight, neg)
  ref_detailed &lt;- pos %&gt;% dplyr::transmute(gene,
                                           final_cluster = detailed,
                                           parent_general = general,
                                           weight,
                                           neg)
  list(general = ref_general, detailed = ref_detailed)
}
.bg_genes &lt;- function(obj)
  rownames(Seurat::GetAssayData(obj, assay = cfg$base_assay, layer = &quot;data&quot;))

# DEG robust + cache ------------------------------------------------------
compute_degs_robust &lt;- function(obj, group_col, features_whitelist = NULL) {
  DefaultAssay(obj) &lt;- cfg$base_assay
  stopifnot(group_col %in% colnames(obj@meta.data))
  pick &lt;- function(df, cands, default) {
    for (nm in cands)
      if (nm %in% names(df))
        return(df[[nm]])
    if (is.function(default))
      return(default())
    rep(default, nrow(df))
  }
  if (is.null(features_whitelist)) {
    bg   &lt;- rownames(Seurat::GetAssayData(obj, assay = cfg$base_assay, layer = &quot;data&quot;))
    hvgs &lt;- tryCatch(
      VariableFeatures(obj),
      error = function(e)
        character(0)
    )
    if (!length(hvgs)) {
      obj &lt;- FindVariableFeatures(
        obj,
        assay = cfg$base_assay,
        nfeatures = 3000,
        verbose = FALSE
      )
      hvgs &lt;- VariableFeatures(obj)
    }
    misc_markers &lt;- tryCatch(
      unique(unlist(obj@misc$marker_genes)),
      error = function(e)
        character(0)
    )
    features_whitelist &lt;- unique(intersect(union(hvgs, misc_markers), bg))
    if (!length(features_whitelist))
      features_whitelist &lt;- hvgs[hvgs %in% bg]
    if (!length(features_whitelist))
      features_whitelist &lt;- bg
  }
  layer_or_slot &lt;- pick_layer_arg()
  old_id &lt;- Idents(obj)
  on.exit(Idents(obj) &lt;- old_id, add = TRUE)
  Idents(obj) &lt;- obj[[group_col]][, 1]
  lv &lt;- levels(Idents(obj))
  if (!length(lv)) {
    message(&quot;compute_degs_robust: no levels in &#39;&quot;, group_col, &quot;&#39;.&quot;)
    return(
      tibble::tibble(
        cluster = character(),
        gene = character(),
        avg_log2FC = double(),
        p_val_adj = double()
      )
    )
  }
  pieces &lt;- lapply(lv, function(cl) {
    args &lt;- list(
      object = obj,
      ident.1 = cl,
      only.pos = TRUE,
      min.pct = 0.20,
      logfc.threshold = 0.25,
      test.use = &quot;wilcox&quot;,
      verbose = FALSE,
      random.seed = cfg$seed,
      features = features_whitelist
    )
    if (!is.null(cfg$deg_subsample_per_ident))
      args$max.cells.per.ident &lt;- cfg$deg_subsample_per_ident
    if (layer_or_slot == &quot;layer&quot;)
      args$layer &lt;- &quot;data&quot;
    else
      args$slot &lt;- &quot;data&quot;
    fm &lt;- tryCatch(
      do.call(Seurat::FindMarkers, args),
      error = function(e)
        NULL
    )
    if (is.null(fm) || !nrow(fm))
      return(NULL)
    tibble::tibble(
      cluster    = canon_cluster(cl),
      gene       = rownames(fm),
      avg_log2FC = suppressWarnings(pick(
        fm, c(&quot;avg_log2FC&quot;, &quot;avg_logFC&quot;, &quot;log2FC&quot;), NA_real_
      )),
      p_val_adj  = suppressWarnings(pick(
        fm,
        c(&quot;p_val_adj&quot;, &quot;p_val.adj&quot;, &quot;p_val_adj_fdr&quot;, &quot;p_val&quot;),
        1
      ))
    ) %&gt;% dplyr::filter(is.finite(avg_log2FC),
                        is.finite(p_val_adj),
                        p_val_adj &lt; 0.05,
                        avg_log2FC &gt; 0)
  })
  res &lt;- dplyr::bind_rows(pieces)
  if (!nrow(res)) {
    message(&quot;compute_degs_robust: no DEGs passed filters.&quot;)
    return(
      tibble::tibble(
        cluster = character(),
        gene = character(),
        avg_log2FC = double(),
        p_val_adj = double()
      )
    )
  }
  res
}
.safe_hash &lt;- function(x) {
  x &lt;- paste(x, collapse = &quot;|&quot;)
  if (has_digest)
    digest::digest(x, algo = &quot;xxhash64&quot;)
  else
    sprintf(&quot;h%08x&quot;, abs(as.integer(sum(utf8ToInt(
      x
    ))) %% 2^31))
}
.deg_ckpt_tag &lt;- function(obj, group_col, features = NULL) {
  memb &lt;- canon_cluster(as.character(obj[[group_col]][, 1]))
  sz   &lt;- sort(as.integer(table(memb)), decreasing = TRUE)
  features &lt;- sort(unique(as.character(features %||% character(0))))
  feat_stub &lt;- features[seq_len(min(200L, length(features)))]
  .safe_hash(c(
    sprintf(&quot;n=%d&quot;, length(memb)),
    sprintf(&quot;k=%d&quot;, length(sz)),
    paste0(&quot;sz:&quot;, paste(sz, collapse = &quot;,&quot;)),
    sprintf(&quot;f=%d&quot;, length(features)),
    paste0(&quot;feat:&quot;, paste(feat_stub, collapse = &quot;,&quot;))
  ))
}
.deg_ckpt_file &lt;- function(prefix, tag)
  file.path(CKPT_DIR, sprintf(&quot;deg_%s_%s.rds&quot;, prefix, tag))
deg_ckpt_save &lt;- function(prefix,
                          obj,
                          group_col,
                          degs,
                          features = NULL,
                          extra = list()) {
  .dir_ok()
  tag &lt;- .deg_ckpt_tag(obj, group_col, features)
  saveRDS(c(
    list(
      saved_at = Sys.time(),
      prefix = prefix,
      group_col = group_col,
      tag = tag,
      features = features,
      degs = degs
    ),
    extra
  ), .deg_ckpt_file(prefix, tag))
}
deg_ckpt_load &lt;- function(prefix, obj, group_col, features = NULL) {
  tag &lt;- .deg_ckpt_tag(obj, group_col, features)
  f &lt;- .deg_ckpt_file(prefix, tag)
  if (!file.exists(f))
    return(NULL)
  x &lt;- readRDS(f)
  if (!is.list(x) || is.null(x$degs))
    return(NULL)
  x$degs
}

# Neighbors/Clustering ----------------------------------------------------
run_neighbors_if_needed &lt;- function(obj, dims, k, reduction = cfg$pca_name) {
  gname &lt;- paste0(cfg$base_assay, &quot;_snn_k&quot;, k)
  if (is.null(obj@graphs[[gname]])) {
    obj &lt;- FindNeighbors(
      obj,
      reduction = reduction,
      dims = 1:dims,
      k.param = k,
      graph.name = gname,
      verbose = FALSE
    )
  }
  obj
}
safe_findclusters &lt;- function(obj, graph.name, resolution, seed = cfg$seed) {
  ok &lt;- FALSE
  res &lt;- NULL
  for (alg in c(4, 3, 1)) {
    res &lt;- try(FindClusters(
      obj,
      graph.name = graph.name,
      resolution = resolution,
      algorithm = alg,
      random.seed = seed,
      verbose = FALSE
    ),
    silent = TRUE)
    if (!inherits(res, &quot;try-error&quot;)) {
      ok &lt;- TRUE
      break
    }
  }
  if (!ok)
    stop(&quot;FindClusters failed for graph=&quot;,
         graph.name,
         &quot; res=&quot;,
         resolution)
  res
}

# Knee-based resolution picker -------------------------------------------
pick_res_by_knee &lt;- function(res_vals, nclu_vals, target_n = NA_integer_) {
  stopifnot(length(res_vals) == length(nclu_vals), length(res_vals) &gt; 0)
  o &lt;- order(res_vals)
  x &lt;- as.numeric(res_vals[o])
  y &lt;- as.numeric(nclu_vals[o])
  y &lt;- cummax(y)
  dy  &lt;- c(NA_real_, diff(y))
  d2  &lt;- c(NA_real_, diff(dy))
  elbow_ix &lt;- suppressWarnings(which.max(replace(-d2, is.na(d2), -Inf)))
  if (length(elbow_ix) == 0 ||
      is.infinite(elbow_ix) || is.na(elbow_ix) || elbow_ix &lt; 1) {
    if (is.na(target_n))
      return(x[ceiling(length(x) / 2)])
    return(x[which.min(abs(y - target_n))])
  }
  x[elbow_ix]
}

# Grid search with stability &amp; memory care ---------------------------
grid_search_clusters &lt;- function(obj,
                                 dims,
                                 target_n = cfg$target_n_clusters,
                                 k_grid = c(5L, 8L, 10L, 15L, 20L),
                                 res_init = 0.6,
                                 res_max  = 10,
                                 max_steps = 20) {
  attempts &lt;- list()
  best &lt;- NULL
  best_membership &lt;- NULL
  best_k &lt;- NULL
  best_r &lt;- NULL
  
  for (k in k_grid) {
    obj_k &lt;- run_neighbors_if_needed(obj, dims, k)
    gname &lt;- paste0(cfg$base_assay, &quot;_snn_k&quot;, k)
    
    eval_r &lt;- function(r) {
      x &lt;- safe_findclusters(
        obj_k,
        graph.name = gname,
        resolution = r,
        seed = cfg$seed
      )
      memb &lt;- as.character(Idents(x))
      names(memb) &lt;- colnames(x)
      rec  &lt;- score_solution(x, gname, memb, target_n, cfg$tiny_frac_cut)
      rec$k &lt;- k
      rec$resolution &lt;- r
      list(rec = rec,
           memb = memb,
           obj = x)
    }
    
    r_lo &lt;- res_init
    e_lo &lt;- eval_r(r_lo)
    n_lo &lt;- e_lo$rec$n_clusters
    attempts[[length(attempts) + 1]] &lt;- e_lo$rec
    
    if (is.na(target_n)) {
      for (r in seq(res_init, min(res_max, res_init + 4), by = 0.4)) {
        e &lt;- eval_r(r)
        attempts[[length(attempts) + 1]] &lt;- e$rec
        if (is.null(best) ||
            e$rec$score &gt; best$score) {
          best &lt;- e$rec
          best_membership &lt;- e$memb
          best_k &lt;- k
          best_r &lt;- r
        }
      }
      next
    }
    
    r_hi &lt;- r_lo
    e_hi &lt;- e_lo
    n_hi &lt;- n_lo
    step &lt;- 0
    while (n_hi &lt; target_n &amp;&amp; r_hi &lt; res_max &amp;&amp; step &lt; max_steps) {
      r_hi &lt;- r_hi * 1.5
      if (r_hi &lt;= r_lo)
        r_hi &lt;- r_lo + 0.2
      e_hi &lt;- eval_r(r_hi)
      attempts[[length(attempts) + 1]] &lt;- e_hi$rec
      n_hi &lt;- e_hi$rec$n_clusters
      step &lt;- step + 1
    }
    
    cand_list &lt;- list(e_lo, e_hi)
    if (n_hi &lt; target_n) {
      e_closest &lt;- cand_list[[which.min(abs(c(n_lo, n_hi) - target_n))]]
      if (is.null(best) || e_closest$rec$score &gt; best$score) {
        best &lt;- e_closest$rec
        best_membership &lt;- e_closest$memb
        best_k &lt;- k
        best_r &lt;- e_closest$rec$resolution
      }
      next
    }
    
    l_r &lt;- r_lo
    l_e &lt;- e_lo
    l_n &lt;- n_lo
    h_r &lt;- r_hi
    h_e &lt;- e_hi
    h_n &lt;- n_hi
    
    it &lt;- 0
    while (it &lt; max_steps &amp;&amp; (abs(h_r - l_r) &gt; 0.05)) {
      it &lt;- it + 1
      m_r &lt;- (l_r + h_r) / 2
      m_e &lt;- eval_r(m_r)
      attempts[[length(attempts) + 1]] &lt;- m_e$rec
      m_n &lt;- m_e$rec$n_clusters
      if (m_n &lt; target_n) {
        l_r &lt;- m_r
        l_e &lt;- m_e
        l_n &lt;- m_n
      } else {
        h_r &lt;- m_r
        h_e &lt;- m_e
        h_n &lt;- m_n
      }
    }
    
    final_e &lt;- if (abs(l_n - target_n) &lt;= abs(h_n - target_n))
      l_e
    else
      h_e
    if (is.null(best) || final_e$rec$score &gt; best$score) {
      best &lt;- final_e$rec
      best_membership &lt;- final_e$memb
      best_k &lt;- k
      best_r &lt;- final_e$rec$resolution
    }
    gc(FALSE)
  }
  
  stopifnot(!is.null(best))
  cl_fac &lt;- factor(best_membership, levels = unique(best_membership))
  names(cl_fac) &lt;- names(best_membership)
  Idents(obj) &lt;- cl_fac[colnames(obj)]
  obj$seurat_clusters &lt;- Idents(obj)
  
  keep_graph &lt;- paste0(cfg$base_assay, &quot;_snn_k&quot;, best_k)
  obj@graphs &lt;- obj@graphs[intersect(names(obj@graphs), keep_graph)]
  
  diag &lt;- dplyr::bind_rows(attempts)
  obj@misc$grid_diag &lt;- diag
  
  list(obj = obj,
       stats = best,
       keep_graph = keep_graph)
}

# Annotation methods ------------------------------------------------------
annotate_avgexp_matrix &lt;- function(avg_mat,
                                   marker_ref,
                                   curated_genes,
                                   top_n = 10) {
  stopifnot(is.matrix(avg_mat) || inherits(avg_mat, &quot;Matrix&quot;))
  feats &lt;- intersect(curated_genes, rownames(avg_mat))
  if (!length(feats))
    return(setNames(character(0), character(0)))
  Z &lt;- t(scale(t(as.matrix(avg_mat[feats, , drop = FALSE]))))
  Z[is.na(Z)] &lt;- 0
  res &lt;- vapply(seq_len(ncol(Z)), function(i) {
    top &lt;- head(names(sort(Z[, i], decreasing = TRUE)), top_n)
    tab &lt;- dplyr::filter(marker_ref, gene %in% top) %&gt;% dplyr::count(final_cluster, sort = TRUE)
    if (nrow(tab) == 0)
      &quot;Unknown&quot;
    else
      tab$final_cluster[1]
  }, FUN.VALUE = character(1))
  names(res) &lt;- colnames(Z)
  res
}
annotate_hypergeom &lt;- function(seurat_clusters_DEG,
                               marker_ref,
                               bg_genes) {
  bg_genes &lt;- unique(bg_genes)
  if (!nrow(seurat_clusters_DEG))
    return(setNames(character(0), character(0)))
  clusters &lt;- unique(seurat_clusters_DEG$cluster)
  res &lt;- sapply(clusters, function(cl) {
    cl_genes &lt;- intersect(unique(seurat_clusters_DEG$gene[seurat_clusters_DEG$cluster == cl]), bg_genes)
    total &lt;- length(bg_genes)
    df &lt;- do.call(rbind, lapply(unique(marker_ref$final_cluster), function(ct) {
      ct_genes &lt;- intersect(unique(marker_ref$gene[marker_ref$final_cluster == ct]), bg_genes)
      overlap &lt;- length(intersect(cl_genes, ct_genes))
      m &lt;- length(ct_genes)
      n &lt;- total - m
      k &lt;- length(cl_genes)
      pval &lt;- stats::phyper(overlap - 1, m, n, k, lower.tail = FALSE)
      data.frame(cell_type = ct, pval = pval)
    }))
    df$p_adj &lt;- p.adjust(df$pval, method = &quot;BH&quot;)
    df$cell_type[which.min(df$p_adj)]
  })
  names(res) &lt;- clusters
  res
}
annotate_majority &lt;- function(seurat_clusters_DEG, marker_ref) {
  if (!nrow(seurat_clusters_DEG))
    return(setNames(character(0), character(0)))
  df &lt;- dplyr::inner_join(seurat_clusters_DEG,
                          marker_ref,
                          by = &quot;gene&quot;,
                          relationship = &quot;many-to-many&quot;) %&gt;%
    dplyr::group_by(cluster, final_cluster) %&gt;% dplyr::summarise(n = dplyr::n(), .groups =
                                                                   &quot;drop&quot;) %&gt;%
    dplyr::group_by(cluster) %&gt;% dplyr::slice_max(n, n = 1, with_ties =
                                                    FALSE)
  setNames(df$final_cluster, df$cluster)
}
annotate_logfc &lt;- function(seurat_clusters_DEG,
                           marker_ref,
                           gene_specificity = NULL,
                           use_padj_weight = TRUE,
                           neg_penalty = 0.2) {
  if (!nrow(seurat_clusters_DEG))
    return(setNames(character(0), character(0)))
  df &lt;- dplyr::inner_join(seurat_clusters_DEG,
                          marker_ref,
                          by = &quot;gene&quot;,
                          relationship = &quot;many-to-many&quot;)
  if (use_padj_weight &amp;&amp;
      &quot;p_val_adj&quot; %in% names(seurat_clusters_DEG)) {
    df &lt;- dplyr::mutate(df, w = pmax(0, -log10(pmin(
      p_val_adj, 1e-300
    ))))
  } else
    df$w &lt;- 1
  if (!is.null(gene_specificity))
    df$spec &lt;- pmax(0.2, gene_specificity[match(df$gene, names(gene_specificity))])
  else
    df$spec &lt;- 1
  if (&quot;neg&quot; %in% names(df) &amp;&amp;
      any(!is.na(df$neg)))
    df$neg_w &lt;- ifelse(isTRUE(df$neg), -neg_penalty, 0)
  else
    df$neg_w &lt;- 0
  df &lt;- df %&gt;%
    dplyr::group_by(cluster, final_cluster) %&gt;%
    dplyr::summarise(
      score = stats::weighted.mean(pmax(0, avg_log2FC) * spec + neg_w, w, na.rm =
                                     TRUE),
      .groups = &quot;drop&quot;
    ) %&gt;%
    dplyr::group_by(cluster) %&gt;% dplyr::slice_max(score, n = 1, with_ties =
                                                    FALSE)
  setNames(df$final_cluster, df$cluster)
}
annotate_cellmanam &lt;- function(seurat_obj,
                               seurat_clusters_DEG,
                               marker_ref,
                               top_n = 2,
                               p_val = 0.01,
                               level = 1) {
  if (!isTRUE(has_cellmanam))
    return(setNames(character(0), character(0)))
  if (is.null(seurat_clusters_DEG) ||
      !nrow(seurat_clusters_DEG))
    return(setNames(character(0), character(0)))
  DefaultAssay(seurat_obj) &lt;- cfg$base_assay
  occ &lt;- tryCatch(
    CellMaNam::calc_occurrence(
      markers_data  = marker_ref,
      features_col  = &quot;gene&quot;,
      cell_column   = &quot;final_cluster&quot;
    ),
    error = function(e)
      NULL
  )
  if (is.null(occ) ||
      !nrow(occ))
    return(setNames(character(0), character(0)))
  occ2 &lt;- tryCatch(
    CellMaNam::select_top_occ(occ, top_n = top_n),
    error = function(e)
      NULL
  )
  if (is.null(occ2) ||
      !nrow(occ2))
    return(setNames(character(0), character(0)))
  ann_tbl &lt;- tryCatch(
    CellMaNam::get_annotation(
      cell_markers = seurat_clusters_DEG %&gt;% dplyr::select(cell_annotation = cluster, markers = gene),
      markers_occ  = occ2,
      max_genes    = nrow(
        Seurat::GetAssayData(seurat_obj, assay = cfg$base_assay, layer = &quot;data&quot;)
      )
    ),
    error = function(e)
      NULL
  )
  if (is.null(ann_tbl) ||
      !nrow(ann_tbl))
    return(setNames(character(0), character(0)))
  cell_types &lt;- tryCatch(
    CellMaNam::cell_typing(
      annotation_data = ann_tbl,
      hierarchy_data = NULL,
      p_val = p_val,
      level = level,
      hierarchy = FALSE
    ),
    error = function(e)
      NULL
  )
  if (is.null(cell_types) ||
      !nrow(cell_types))
    return(setNames(character(0), character(0)))
  need &lt;- c(&quot;annotation&quot;, &quot;full_names&quot;, &quot;completed&quot;)
  if (!all(need %in% names(cell_types)))
    return(setNames(character(0), character(0)))
  df &lt;- cell_types %&gt;% dplyr::group_by(annotation) %&gt;% dplyr::filter(completed == max(completed, na.rm =
                                                                                        TRUE)) %&gt;% dplyr::ungroup() %&gt;%
    dplyr::select(cluster = annotation, annotation = full_names)
  if (!nrow(df))
    return(setNames(character(0), character(0)))
  res &lt;- df$annotation
  names(res) &lt;- canon_cluster(df$cluster)
  res
}
cluster_expressed_bg &lt;- function(seurat_obj, cluster_idents, min_cells = 5) {
  sct &lt;- Seurat::GetAssayData(seurat_obj, assay = cfg$base_assay, layer = &quot;data&quot;)
  g &lt;- seurat_obj[[cluster_idents]][, 1] %&gt;% canon_cluster()
  if (is.null(names(g)))
    names(g) &lt;- colnames(seurat_obj)
  lapply(split(names(g), g), function(cells) {
    if (!length(cells))
      return(character(0))
    keep &lt;- Matrix::rowSums(sct[, cells, drop = FALSE] &gt; 0) &gt;= min_cells
    rownames(sct)[keep]
  })
}
annotate_hypergeomX &lt;- function(seurat_obj,
                                seurat_clusters_DEG,
                                marker_ref,
                                cluster_idents,
                                min_cells_bg = 5) {
  if (!nrow(seurat_clusters_DEG))
    return(setNames(character(0), character(0)))
  seurat_clusters_DEG$cluster &lt;- canon_cluster(as.character(seurat_clusters_DEG$cluster))
  clusters &lt;- unique(seurat_clusters_DEG$cluster)
  bg_by_cluster &lt;- cluster_expressed_bg(seurat_obj, cluster_idents, min_cells =
                                          min_cells_bg)
  vals &lt;- sapply(clusters, function(cl) {
    bg_genes &lt;- unique(bg_by_cluster[[cl]])
    if (!length(bg_genes))
      return(&quot;Unknown&quot;)
    cl_genes &lt;- intersect(unique(seurat_clusters_DEG$gene[seurat_clusters_DEG$cluster == cl]), bg_genes)
    if (!length(cl_genes))
      return(&quot;Unknown&quot;)
    df &lt;- do.call(rbind, lapply(unique(marker_ref$final_cluster), function(ct) {
      ct_genes &lt;- intersect(unique(marker_ref$gene[marker_ref$final_cluster == ct]), bg_genes)
      overlap &lt;- length(intersect(cl_genes, ct_genes))
      m &lt;- length(ct_genes)
      n &lt;- length(bg_genes) - m
      k &lt;- length(cl_genes)
      pval &lt;- stats::phyper(overlap - 1, m, n, k, lower.tail = FALSE)
      data.frame(cell_type = ct, pval = pval)
    }))
    if (!nrow(df))
      return(&quot;Unknown&quot;)
    df$p_adj &lt;- p.adjust(df$pval, method = &quot;BH&quot;)
    as.character(df$cell_type[which.min(df$p_adj)])
  }, USE.NAMES = FALSE)
  names(vals) &lt;- clusters
  vals
}
annotate_fgsea &lt;- function(seurat_clusters_DEG,
                           marker_ref,
                           minSize = 3,
                           maxSize = 500) {
  if (!has_fgsea ||
      !nrow(seurat_clusters_DEG))
    return(setNames(character(0), character(0)))
  genesets &lt;- split(marker_ref$gene, marker_ref$final_cluster)
  res &lt;- lapply(split(seurat_clusters_DEG, seurat_clusters_DEG$cluster), function(df_cl) {
    lfc &lt;- df_cl$avg_log2FC
    names(lfc) &lt;- df_cl$gene
    if (!length(lfc))
      return(&quot;Unknown&quot;)
    lfc &lt;- sort(tapply(lfc, names(lfc), max), decreasing = TRUE)
    gs &lt;- lapply(genesets, function(v)
      intersect(v, names(lfc)))
    len &lt;- sapply(gs, length)
    gs &lt;- gs[len &gt;= minSize &amp; len &lt;= maxSize]
    if (!length(gs))
      return(&quot;Unknown&quot;)
    gsr &lt;- suppressWarnings(fgsea::fgsea(
      pathways = gs,
      stats = lfc,
      nperm = 2000
    ))
    if (!nrow(gsr))
      return(&quot;Unknown&quot;)
    as.character(gsr$pathway[order(gsr$padj, -abs(gsr$NES))][1])
  })
  labs &lt;- unlist(res)
  names(labs) &lt;- names(res)
  labs
}

# ---- UCell lean ----
fast_ucell_labels_lean &lt;- function(seurat_obj,
                                   marker_ref,
                                   cluster_idents,
                                   min_genes   = cfg$ucell_min_genes,
                                   cells_per_cluster = cfg$ucell_cells_per_cluster,
                                   max_signatures    = cfg$ucell_max_signatures,
                                   ncores = cfg$ucell_ncores) {
  if (!has_ucell || !isTRUE(cfg$enable_ucell)) {
    message(&quot;[annot][ucell] UCell unavailable or disabled; skipping.&quot;)
    return(list(
      obj = seurat_obj,
      labels = setNames(character(0), character(0))
    ))
  }
  if (!cluster_idents %in% colnames(seurat_obj@meta.data)) {
    message(&quot;[annot][ucell] Cluster key &#39;&quot;,
            cluster_idents,
            &quot;&#39; not found; skipping.&quot;)
    return(list(
      obj = seurat_obj,
      labels = setNames(character(0), character(0))
    ))
  }
  
  DefaultAssay(seurat_obj) &lt;- cfg$base_assay
  bg &lt;- rownames(Seurat::GetAssayData(seurat_obj, assay = cfg$base_assay, layer = &quot;data&quot;))
  if (!length(bg)) {
    message(&quot;[annot][ucell] No background genes in assay; skipping.&quot;)
    return(list(
      obj = seurat_obj,
      labels = setNames(character(0), character(0))
    ))
  }
  
  sigs &lt;- split(marker_ref$gene, marker_ref$final_cluster)
  sigs &lt;- lapply(sigs, function(v)
    intersect(unique(v), bg))
  sigs &lt;- sigs[sapply(sigs, length) &gt;= min_genes]
  if (!length(sigs)) {
    message(
      &quot;[annot][ucell] No usable signatures after filtering (min_genes=&quot;,
      min_genes,
      &quot;); skipping.&quot;
    )
    return(list(
      obj = seurat_obj,
      labels = setNames(character(0), character(0))
    ))
  }
  sig_len  &lt;- sort(sapply(sigs, length), decreasing = TRUE)
  keep_sig &lt;- names(sig_len)[seq_len(min(length(sig_len), max_signatures))]
  sigs     &lt;- sigs[keep_sig]
  
  grp &lt;- seurat_obj[[cluster_idents]][, 1] |&gt; as.character() |&gt; canon_cluster()
  if (length(grp) != ncol(seurat_obj)) {
    message(&quot;[annot][ucell] length(grp) != ncol(object); skipping.&quot;)
    return(list(
      obj = seurat_obj,
      labels = setNames(character(0), character(0))
    ))
  }
  cells_by &lt;- split(colnames(seurat_obj), grp)
  subs &lt;- unlist(lapply(cells_by, function(v)
    if (length(v) &lt;= cells_per_cluster)
      v
    else
      sample(v, cells_per_cluster)), use.names = FALSE)
  if (!length(subs)) {
    message(&quot;[annot][ucell] Subsampling kept 0 cells; skipping.&quot;)
    return(list(
      obj = seurat_obj,
      labels = setNames(character(0), character(0))
    ))
  }
  
  sub &lt;- subset(seurat_obj, cells = subs)
  pre_cols &lt;- colnames(sub@meta.data)
  message(
    &quot;[annot][ucell] Running UCell on &quot;,
    length(subs),
    &quot; cells across &quot;,
    length(sigs),
    &quot; signatures...&quot;
  )
  sub &lt;- UCell::AddModuleScore_UCell(sub,
                                     features = sigs,
                                     name = &quot;U&quot;,
                                     ncores = ncores)
  
  post_cols &lt;- setdiff(colnames(sub@meta.data), pre_cols)
  if (!length(post_cols))
    post_cols &lt;- grep(&quot;^U[._-]&quot;, colnames(sub@meta.data), value = TRUE)
  if (!length(post_cols)) {
    message(&quot;[annot][ucell] No UCell score columns were created; skipping.&quot;)
    return(list(
      obj = seurat_obj,
      labels = setNames(character(0), character(0))
    ))
  }
  
  clean_uc &lt;- function(x) {
    x &lt;- gsub(&quot;^U[._-]*&quot;, &quot;&quot;, x, perl = TRUE)
    x &lt;- gsub(&quot;(?:[._-]*(?:UCell|U))?$&quot;, &quot;&quot;, x, perl = TRUE)
    trim(x)
  }
  col2label &lt;- setNames(clean_uc(post_cols), post_cols)
  
  sub_grp &lt;- sub[[cluster_idents]][, 1] |&gt; as.character() |&gt; canon_cluster()
  df &lt;- data.frame(cluster = sub_grp, sub@meta.data[, post_cols, drop = FALSE], check.names = FALSE)
  lab &lt;- tapply(seq_len(nrow(df)), df$cluster, function(ix) {
    med &lt;- suppressWarnings(apply(df[ix, post_cols, drop = FALSE], 2, stats::median, na.rm = TRUE))
    best_col &lt;- names(which.max(med))
    col2label[[best_col]]
  })
  
  labs &lt;- unlist(lab)
  labs &lt;- setNames(as.character(labs), names(lab))
  list(obj = seurat_obj, labels = labs)
}

# Two-pass annotation orchestrator ---------------------------------------
annotate_all_methods &lt;- function(obj,
                                 marker_ref,
                                 cluster_key_name = &quot;cluster_key&quot;,
                                 prefix = &quot;annot_detailed&quot;,
                                 limit_clusters = NULL,
                                 deg_prefix = &quot;deg&quot;,
                                 degs_precomputed = NULL) {
  stopifnot(inherits(obj, &quot;Seurat&quot;))
  if (is.null(marker_ref) ||
      !nrow(marker_ref) ||
      !all(c(&quot;gene&quot;, &quot;final_cluster&quot;) %in% names(marker_ref))) {
    stop(&quot;[annot] marker_ref must be a data.frame with columns: gene, final_cluster&quot;)
  }
  obj &lt;- ensure_cluster_key(obj, cluster_key_name)
  
  old_id &lt;- Idents(obj)
  on.exit(try(Idents(obj) &lt;- old_id, silent = TRUE)
          , add = TRUE)
  Idents(obj) &lt;- obj[[cluster_key_name]][, 1]
  clv &lt;- Idents(obj)
  
  DefaultAssay(obj) &lt;- cfg$base_assay
  X_full &lt;- Seurat::GetAssayData(obj, assay = cfg$base_assay, layer = &quot;data&quot;)
  if (!inherits(X_full, &quot;dgCMatrix&quot;))
    X_full &lt;- methods::as(X_full, &quot;dgCMatrix&quot;)
  bg &lt;- rownames(X_full)
  
  curated_genes &lt;- unique(as.character(marker_ref$gene))
  feats_cur &lt;- intersect(curated_genes, bg)
  if (!length(feats_cur))
    stop(&quot;[annot] No curated markers found in assay background.&quot;)
  if (isTRUE(cfg$annot_features_max) &amp;&amp;
      length(feats_cur) &gt; cfg$annot_features_max)
    feats_cur &lt;- feats_cur[seq_len(cfg$annot_features_max)]
  
  obj_lean &lt;- Seurat::DietSeurat(
    obj,
    assays = cfg$base_assay,
    counts = TRUE,
    data = TRUE,
    scale.data = FALSE,
    dimreducs = character(),
    graphs = character(),
    features = feats_cur
  )
  DefaultAssay(obj_lean) &lt;- cfg$base_assay
  Idents(obj_lean) &lt;- obj_lean[[cluster_key_name]][, 1]
  
  if (!is.null(limit_clusters)) {
    limit_clusters &lt;- canon_cluster(as.character(limit_clusters))
    grp_all &lt;- as.character(Idents(obj_lean))
    keep_cells &lt;- colnames(obj_lean)[grp_all %in% limit_clusters]
    if (!length(keep_cells)) {
      message(&quot;[annot] limit_clusters matched 0 cells; returning empty table.&quot;)
      tab_empty &lt;- tibble::tibble(cluster = character(0))
      if (!prefix %in% colnames(obj@meta.data))
        obj[[prefix]] &lt;- NA_character_
      if (!&quot;final_consensus&quot; %in% colnames(obj@meta.data))
        obj$final_consensus &lt;- NA_character_
      try(ckpt_save(&quot;annot_table_last&quot;,
                    list(table = tab_empty, saved_at = Sys.time())), silent = TRUE)
      return(list(
        obj = obj,
        table = tab_empty,
        degs = tibble::tibble()
      ))
    }
    obj_lean &lt;- subset(obj_lean, cells = keep_cells)
  }
  
  clusters &lt;- Idents(obj_lean)
  lv &lt;- levels(clusters)
  expected_clusters &lt;- lv
  
  tab_placeholder &lt;- tibble::tibble(cluster = canon_cluster(as.character(expected_clusters)))
  try(ckpt_save(&quot;annot_table_last&quot;,
                list(table = tab_placeholder, saved_at = Sys.time())), silent = TRUE)
  
  message(&quot;[annot] DEGs: preparing ...&quot;)
  degs &lt;- degs_precomputed
  if (is.null(degs)) {
    if (isTRUE(cfg$annot_skip_deg)) {
      cached &lt;- try(deg_ckpt_load(
        prefix = deg_prefix,
        obj = obj,
        group_col = cluster_key_name,
        features = feats_cur
      ),
      silent = TRUE)
      if (!inherits(cached, &quot;try-error&quot;) &amp;&amp;
          !is.null(cached))
        degs &lt;- cached
    } else {
      layer_or_slot &lt;- pick_layer_arg()
      pieces &lt;- lapply(expected_clusters, function(cl) {
        args &lt;- list(
          object = obj_lean,
          ident.1 = cl,
          only.pos = TRUE,
          min.pct = 0.20,
          logfc.threshold = 0.25,
          test.use = &quot;wilcox&quot;,
          verbose = FALSE,
          features = feats_cur,
          random.seed = cfg$seed
        )
        if (!is.null(cfg$deg_subsample_per_ident))
          args$max.cells.per.ident &lt;- cfg$deg_subsample_per_ident
        if (layer_or_slot == &quot;layer&quot;)
          args$layer &lt;- &quot;data&quot;
        else
          args$slot &lt;- &quot;data&quot;
        fm &lt;- tryCatch(
          do.call(Seurat::FindMarkers, args),
          error = function(e)
            NULL
        )
        if (is.null(fm) || !nrow(fm))
          return(NULL)
        tibble::tibble(
          cluster    = canon_cluster(as.character(cl)),
          gene       = rownames(fm),
          avg_log2FC = suppressWarnings(
            if (&quot;avg_log2FC&quot; %in% names(fm))
              fm$avg_log2FC
            else if (&quot;avg_logFC&quot; %in% names(fm))
              fm$avg_logFC
            else if (&quot;log2FC&quot; %in% names(fm))
              fm$log2FC
            else
              NA_real_
          ),
          p_val_adj  = suppressWarnings(
            if (&quot;p_val_adj&quot;  %in% names(fm))
              fm$p_val_adj
            else if (&quot;p_val.adj&quot; %in% names(fm))
              fm$p_val.adj
            else if (&quot;p_val&quot; %in% names(fm))
              fm$p_val
            else
              1
          )
        )
      })
      degs &lt;- dplyr::bind_rows(pieces)
      if (!is.null(degs) &amp;&amp; nrow(degs)) {
        degs &lt;- dplyr::filter(
          degs,
          is.finite(avg_log2FC),
          is.finite(p_val_adj),
          p_val_adj &lt; 0.05,
          avg_log2FC &gt; 0
        )
        try(deg_ckpt_save(
          prefix = deg_prefix,
          obj = obj,
          group_col = cluster_key_name,
          degs = degs,
          features = feats_cur
        ),
        silent = TRUE)
      }
    }
  }
  message(sprintf(
    &quot;[annot] DEGs: %s&quot;,
    ifelse(
      is.null(degs) ||
        !nrow(degs),
      &quot;none (empty table)&quot;,
      sprintf(&quot;n=%d&quot;, nrow(degs))
    )
  ))
  
  X &lt;- Seurat::GetAssayData(obj_lean, assay = cfg$base_assay, layer = &quot;data&quot;)
  stopifnot(inherits(X, &quot;dgCMatrix&quot;))
  avg_gc   &lt;- avg_by_group_sparse(X, clusters)
  avg_gc_m &lt;- as.matrix(avg_gc)
  
  obj_lean@misc$annot_feats   &lt;- feats_cur
  obj_lean@misc$annot_avg_exp &lt;- avg_gc_m
  obj_lean@misc$annot_degs    &lt;- degs
  assign(&quot;.annot_obj_lean&quot;, obj_lean, envir = .GlobalEnv)
  
  out &lt;- list()
  curated_genes &lt;- unique(as.character(marker_ref$gene))
  out$avg_exp   &lt;- .run_annot_method(&quot;avg_exp&quot;, function()
    annotate_avgexp_matrix(avg_gc_m, marker_ref, curated_genes = curated_genes), expect_clusters = expected_clusters)
  out$hypergeom &lt;- .run_annot_method(&quot;hypergeom&quot;, function()
    annotate_hypergeom(degs %||% tibble::tibble(), marker_ref, rownames(X)), expect_clusters = expected_clusters)
  out$majority  &lt;- .run_annot_method(&quot;majority&quot;, function()
    annotate_majority(degs %||% tibble::tibble(), marker_ref), expect_clusters = expected_clusters)
  out$logfc     &lt;- .run_annot_method(&quot;logfc&quot;, function()
    annotate_logfc(degs %||% tibble::tibble(), marker_ref, use_padj_weight = TRUE), expect_clusters = expected_clusters)
  out$cellmanam &lt;- .run_annot_method(&quot;cellmanam&quot;, function()
    annotate_cellmanam(obj, degs %||% tibble::tibble(), marker_ref), expect_clusters = expected_clusters)
  out$hypergeomX &lt;- .run_annot_method(&quot;hypergeomX&quot;, function()
    annotate_hypergeomX(
      obj,
      degs %||% tibble::tibble(),
      marker_ref,
      cluster_idents = cluster_key_name,
      min_cells_bg = 5
    ), expect_clusters = expected_clusters)
  out$gsea      &lt;- .run_annot_method(&quot;gsea&quot;, function()
    annotate_fgsea(degs %||% tibble::tibble(), marker_ref), expect_clusters = expected_clusters)
  
  uc &lt;- fast_ucell_labels_lean(obj, marker_ref, cluster_idents = cluster_key_name)
  obj &lt;- uc$obj
  out$ucell     &lt;- .run_annot_method(&quot;ucell&quot;, function()
    uc$labels, expect_clusters = expected_clusters)
  
  build_tbl &lt;- function(named_vec, nm) {
    if (!length(named_vec))
      return(NULL)
    tibble::tibble(cluster = names(named_vec), !!nm := unname(named_vec))
  }
  dfs &lt;- purrr::compact(lapply(names(out), function(nm)
    build_tbl(out[[nm]], nm)))
  tab &lt;- if (length(dfs))
    Reduce(function(x, y)
      dplyr::full_join(x, y, by = &quot;cluster&quot;), dfs)
  else
    tibble::tibble(cluster = character(0))
  if (!nrow(tab))
    tab &lt;- tibble::tibble(cluster = canon_cluster(as.character(expected_clusters)))
  tab$cluster &lt;- canon_cluster(tab$cluster)
  if (!is.null(limit_clusters))
    tab &lt;- dplyr::filter(tab, cluster %in% expected_clusters)
  
  methods &lt;- intersect(
    c(
      &quot;avg_exp&quot;,
      &quot;hypergeom&quot;,
      &quot;majority&quot;,
      &quot;logfc&quot;,
      &quot;cellmanam&quot;,
      &quot;hypergeomX&quot;,
      &quot;gsea&quot;,
      &quot;ucell&quot;
    ),
    names(tab)
  )
  weights &lt;- c(
    avg_exp = 1,
    hypergeom = 1,
    majority = 1,
    logfc = 1,
    cellmanam = 1,
    hypergeomX = 1,
    gsea = 1,
    ucell = 1
  )
  weights &lt;- weights[methods]
  wvote &lt;- function(row) {
    # methods + weights already defined above
    vals &lt;- as.list(row[methods])
    labs &lt;- vapply(vals, function(x) as.character(x[[1]]), &quot;&quot;, USE.NAMES = FALSE)
    keep &lt;- !is.na(labs) &amp; labs != &quot;Unknown&quot;
    if (!any(keep)) return(NA_character_)
    # align weights to the methods that actually voted
    ms   &lt;- methods[keep]
    labs &lt;- labs[keep]
    # sum method weights per label
    sc &lt;- tapply(weights[ms], labs, sum, simplify = TRUE)
    names(which.max(sc))
  }
  
  if (nrow(tab) &amp;&amp;
      length(methods))
    tab$final_consensus &lt;- apply(tab[, methods, drop = FALSE], 1, wvote)
  else
    tab$final_consensus &lt;- NA_character_
  
  if (nrow(tab) &amp;&amp; length(methods)) {
    tab$agree &lt;- apply(tab[, methods, drop = FALSE], 1, function(x) {
      v &lt;- x[!is.na(x) &amp; x != &quot;Unknown&quot;]
      if (!length(v))
        return(0)
      max(table(v)) / length(v)
    })
  } else
    tab$agree &lt;- numeric(nrow(tab))
  
  grp &lt;- obj[[cluster_key_name]][, 1] %&gt;% as.character() %&gt;% canon_cluster()
  names(grp) &lt;- colnames(obj)
  init_meta &lt;- function(n)
    rep(NA_character_, n)
  # existing block writes: annot_detailed_avg_exp, ..., annot_detailed_ucell
  for (m in methods) {
    colname &lt;- paste0(prefix, &quot;_&quot;, m)
    if (!colname %in% colnames(obj@meta.data))
      obj[[colname]] &lt;- init_meta(ncol(obj))
    cmap &lt;- setNames(tab[[m]], tab$cluster)
    obj[[colname]] &lt;- apply_mapping(grp, cmap)
  }
  # also write UNPREFIXED aliases by request (result_obj$avg_exp, etc.)
  for (m in methods) {
    cmap &lt;- setNames(tab[[m]], tab$cluster)
    obj[[m]] &lt;- apply_mapping(grp, cmap)
  }
  
  if (!prefix %in% colnames(obj@meta.data))
    obj[[prefix]] &lt;- init_meta(ncol(obj))
  if (nrow(tab))
    obj[[prefix]] &lt;- apply_mapping(grp, setNames(tab$final_consensus, tab$cluster))
  if (!&quot;final_consensus&quot; %in% colnames(obj@meta.data))
    obj$final_consensus &lt;- init_meta(ncol(obj))
  if (nrow(tab))
    obj$final_consensus &lt;- apply_mapping(grp, setNames(tab$final_consensus, tab$cluster))
  
  tab &lt;- dplyr::arrange(tab, cluster)
  try(ckpt_save(&quot;annot_table_last&quot;, list(table = tab, saved_at = Sys.time())), silent = TRUE)
  
  res &lt;- list(
    obj = obj,
    table = tab,
    degs = degs %||% tibble::tibble()
  )
  class(res) &lt;- c(&quot;annot_res&quot;, &quot;list&quot;)
  return(res)
}

print_annotation_summary &lt;- function(tab, n = NULL) {
  if (is.null(tab) ||
      !nrow(tab)) {
    message(&quot;[annot][summary] Empty annotation table.&quot;)
    return(invisible(NULL))
  }
  cols &lt;- intersect(
    c(
      &quot;cluster&quot;,
      &quot;avg_exp&quot;,
      &quot;hypergeom&quot;,
      &quot;majority&quot;,
      &quot;logfc&quot;,
      &quot;cellmanam&quot;,
      &quot;hypergeomX&quot;,
      &quot;gsea&quot;,
      &quot;ucell&quot;,
      &quot;final_consensus&quot;,
      &quot;agree&quot;
    ),
    colnames(tab)
  )
  show &lt;- tab[, cols, drop = FALSE] %&gt;% dplyr::arrange(cluster)
  if (!is.null(n))
    show &lt;- utils::head(show, n)
  print(show, row.names = FALSE)
  invisible(show)
}

write_results_xlsx &lt;- function(wb, sheet_prefix, annot_tab, degs, anno_df) {
  addWorksheet(wb, paste0(sheet_prefix, &quot;_annot&quot;))
  writeData(wb, paste0(sheet_prefix, &quot;_annot&quot;), annot_tab)
  if (is.null(degs) ||
      !is.data.frame(degs) || !nrow(degs))
    return(invisible(NULL))
  if (!&quot;cluster&quot; %in% names(degs))
    stop(&quot;DEG table lacks &#39;cluster&#39; column.&quot;)
  by_cluster &lt;- split(degs, as.character(degs$cluster))
  adf_ok &lt;- is.data.frame(anno_df) &amp;&amp; nrow(anno_df) &gt; 0
  if (adf_ok) {
    adf &lt;- anno_df
    if (!&quot;gene&quot; %in% names(adf)) {
      alt &lt;- intersect(names(adf),
                       c(
                         &quot;Gene&quot;,
                         &quot;GeneID&quot;,
                         &quot;gene_id&quot;,
                         &quot;Gene_name&quot;,
                         &quot;GeneID_version&quot;
                       ))
      if (length(alt))
        names(adf)[match(alt[1], names(adf))] &lt;- &quot;gene&quot;
    }
    if (!&quot;all_anno&quot; %in% names(adf)) {
      alt &lt;- intersect(
        c(
          &quot;Annotation&quot;,
          &quot;Uniprot_protein_name&quot;,
          &quot;PFAM_domain_name&quot;,
          &quot;NCBI_ID&quot;
        ),
        names(adf)
      )
      adf$all_anno &lt;- if (length(alt))
        do.call(paste, c(adf[alt], sep = &quot;; &quot;))
      else
        NA_character_
    }
    adf$gene &lt;- trim(as.character(adf$gene))
    adf &lt;- unique(adf[, c(&quot;gene&quot;, &quot;all_anno&quot;)])
    adf$gene_nov &lt;- sub(&quot;\\.[0-9]+$&quot;, &quot;&quot;, adf$gene)
    adf_slim &lt;- unique(adf[, c(&quot;gene&quot;, &quot;gene_nov&quot;, &quot;all_anno&quot;)])
  }
  
  norm_chr &lt;- function(x)
    trim(as.character(x))
  for (nm in names(by_cluster)) {
    df &lt;- by_cluster[[nm]]
    df &lt;- as.data.frame(df, stringsAsFactors = FALSE)
    if (!&quot;gene&quot; %in% names(df))
      df$gene &lt;- rownames(df)
    df$gene &lt;- norm_chr(df$gene)
    if (adf_ok) {
      # 1) First join  be safe as well
      df1 &lt;- dplyr::left_join(
        df,
        adf_slim[, c(&quot;gene&quot;,&quot;all_anno&quot;), drop = FALSE],
        by = &quot;gene&quot;
      )
      df1$all_anno &lt;- vapply(df1$all_anno, as_chr_collapse, &quot;&quot;, USE.NAMES = FALSE)
      # 2) Only if any annotations are missing
      need &lt;- is.na(df1$all_anno) | df1$all_anno == &quot;&quot;
      if (any(need)) {
        df1$gene_nov &lt;- sub(&quot;\\.[0-9]+$&quot;, &quot;&quot;, df1$gene)
        stopifnot(is.data.frame(df1[need, c(&quot;gene_nov&quot;), drop = FALSE]))
        
        lk &lt;- dplyr::left_join(
          df1[need, c(&quot;gene_nov&quot;), drop = FALSE],                             # &lt;- drop = FALSE
          unique(adf_slim[, c(&quot;gene_nov&quot;,&quot;all_anno&quot;), drop = FALSE]),         # &lt;- drop = FALSE
          by = &quot;gene_nov&quot;
        )
        
        df1$all_anno[need] &lt;- lk$all_anno
        df1$gene_nov &lt;- NULL
        df1$all_anno &lt;- vapply(df1$all_anno, as_chr_collapse, &quot;&quot;, USE.NAMES = FALSE)
      }
      df &lt;- df1
      
      
    }
    sht &lt;- sanitize_sheet(paste0(sheet_prefix, &quot;_&quot;, nm))
    addWorksheet(wb, sht)
    writeData(wb, sht, df)
  }
}

# ---------------------------
# Cluster keys &amp; subclustering
# ---------------------------

ensure_cluster_key &lt;- function(obj, key = &quot;cluster_key&quot;) {
  if (!(key %in% colnames(obj@meta.data))) {
    # build it from Idents if possible
    if (length(Idents(obj))) {
      obj[[key]] &lt;- canon_cluster(as.character(Idents(obj)))
    } else {
      stop(&quot;&#39;&quot;,
           key,
           &quot;&#39; not found in Seurat object meta.data and Idents() is empty.&quot;)
    }
  } else {
    obj[[key]] &lt;- canon_cluster(as.character(obj[[key]][, 1]))
  }
  obj
}

.pretty_sizes &lt;- function(tab_named)
  paste(sprintf(&quot;%d:%d&quot;, seq_along(tab_named), as.integer(tab_named)), collapse = &quot;, &quot;)
.min_allowed &lt;- function(n, abs_min, prop_min, tiny_prop) {
  list(
    min_allowed   = max(abs_min, ceiling(prop_min  * n)),
    tiny_allowed  = max(abs_min, ceiling(tiny_prop * n)),
    abs_min       = abs_min,
    prop_min_calc = ceiling(prop_min  * n),
    tiny_min_calc = ceiling(tiny_prop * n)
  )
}
# --- replace the centroid merge helper with this hardened version ---
.merge_labels_by_centroid &lt;- function(emb, lab, tiny_levels) {
  if (!length(tiny_levels))
    return(lab)
  lab &lt;- as.character(lab)
  lab[is.na(lab)] &lt;- &quot;NA&quot;                    # guard NAs
  tab &lt;- table(lab)
  big_levels &lt;- setdiff(names(tab), tiny_levels)
  if (!length(big_levels))
    return(lab)
  
  emb &lt;- as.matrix(emb)
  stopifnot(nrow(emb) == length(lab))
  
  # centroids per level
  lab_f &lt;- factor(lab)                # ensure factor
  cent  &lt;- rowsum(emb, lab_f) / as.numeric(table(lab_f))
  cent &lt;- as.matrix(cent)
  
  for (sm in tiny_levels) {
    # if tiny level vanished, skip
    if (!sm %in% rownames(cent) || !length(big_levels))
      next
    d &lt;- sapply(big_levels, function(b) {
      v &lt;- cent[sm, , drop = FALSE] - cent[b, , drop = FALSE]
      sum(v^2)
    })
    to &lt;- names(which.min(d))
    lab[lab == sm] &lt;- to
  }
  lab
}



# ---- CORE: robust subclustering for ONE parent  (FIXED) ---------------------
# ---- CORE: robust subclustering for ONE parent (never throws) ----
subcluster_one &lt;- function(obj_in,
                           parent_key,
                           cluster_key_name = &quot;cluster_key&quot;,
                           new_key_name     = &quot;cluster_key_v2&quot;,
                           res_grid         = cfg$subclust_res,
                           npcs             = cfg$subclust_npcs,
                           k                = cfg$subclust_k,
                           min_abs          = cfg$min_child_abs,
                           min_prop         = cfg$min_child_prop,
                           tiny_prop        = cfg$subclust_tiny_prop,
                           collapse_tiny    = TRUE) {
  # --- helpers ---
  has_valid_graph &lt;- function(o, gnm) {
    G &lt;- o@graphs[[gnm]]
    if (is.null(G))
      return(FALSE)
    if (!methods::is(G, &quot;dgCMatrix&quot;))
      G &lt;- methods::as(G, &quot;dgCMatrix&quot;)
    Matrix::nnzero(G) &gt; 0
  }
  pick_snn &lt;- function(o) {
    cands &lt;- names(o@graphs)
    if (!length(cands))
      return(NULL)
    snn &lt;- cands[grepl(&quot;_snn&quot;, cands, fixed = TRUE)]
    if (!length(snn))
      snn &lt;- cands[1]
    snn[1]
  }
  
  # --- find parent cells from PARENT labels only ---
  base_lab &lt;- obj_in[[cluster_key_name]][, 1] |&gt; as.character() |&gt; canon_cluster()
  p_regex &lt;- paste0(&quot;^&quot;, parent_key, &quot;(\\.|$)&quot;)
  cells_parent &lt;- colnames(obj_in)[grepl(p_regex, base_lab, perl = TRUE)]
  parent_n &lt;- length(cells_parent)
  if (!parent_n) {
    message(&quot;[subclust] (&quot;, parent_key, &quot;) no cells; skip.&quot;)
    return(obj_in)
  }
  
  # small parents: skip early
  if (parent_n &lt; (cfg$sub_min_cells_for_split %||% 30L)) {
    message(&quot;[subclust] (keep &quot;,
            parent_key,
            &quot;) too few cells (n=&quot;,
            parent_n,
            &quot;); skip.&quot;)
    return(obj_in)
  }
  
  thr &lt;- .min_allowed(parent_n, min_abs, min_prop, tiny_prop)
  
  # subset
  DefaultAssay(obj_in) &lt;- cfg$base_assay
  sub &lt;- tryCatch(
    subset(obj_in, cells = cells_parent),
    error = function(e)
      NULL
  )
  if (is.null(sub) || ncol(sub) &lt; 3L) {
    message(&quot;[subclust] (keep &quot;, parent_key, &quot;) subset invalid; skip.&quot;)
    return(obj_in)
  }
  
  # HVG + drop zero-variance
  if (length(VariableFeatures(sub)) &lt; 200) {
    sub &lt;- FindVariableFeatures(
      sub,
      selection.method = &quot;vst&quot;,
      nfeatures = min(2000, nrow(sub)),
      verbose = FALSE
    )
  }
  feats &lt;- intersect(VariableFeatures(sub), rownames(sub))
  if (!length(feats)) {
    message(&quot;[subclust] (keep &quot;, parent_key, &quot;) no HVGs; skip.&quot;)
    return(obj_in)
  }
  
  Xsub &lt;- tryCatch(
    Seurat::GetAssayData(obj_in, assay = cfg$base_assay, layer = &quot;data&quot;)[feats, cells_parent, drop = FALSE],
    error = function(e)
      NULL
  )
  if (is.null(Xsub)) {
    message(&quot;[subclust] (keep &quot;, parent_key, &quot;) no data layer; skip.&quot;)
    return(obj_in)
  }
  
  mu  &lt;- Matrix::rowMeans(Xsub)
  mu2 &lt;- Matrix::rowMeans(Xsub^2)
  vrs &lt;- as.numeric(mu2 - mu^2)
  feats &lt;- feats[vrs &gt; 0]
  if (!length(feats)) {
    message(&quot;[subclust] (keep &quot;, parent_key, &quot;) no variable signal; skip.&quot;)
    return(obj_in)
  }
  
  # scaling
  sub &lt;- tryCatch(
    ScaleData(sub, features = feats, verbose = FALSE),
    error = function(e)
      NULL
  )
  if (is.null(sub)) {
    message(&quot;[subclust] (keep &quot;, parent_key, &quot;) ScaleData failed; skip.&quot;)
    return(obj_in)
  }
  
  # PCA (exact SVD, bounded PCs)
  use_pcs_max &lt;- max(2L, min(length(feats), parent_n - 2L))
  Xsc &lt;- tryCatch(
    Seurat::GetAssayData(sub, assay = cfg$base_assay, layer = &quot;scale.data&quot;)[feats, , drop = FALSE],
    error = function(e)
      NULL
  )
  if (is.null(Xsc) || nrow(Xsc) &lt; 2L || ncol(Xsc) &lt; 3L) {
    message(&quot;[subclust] (keep &quot;,
            parent_key,
            &quot;) scaled matrix too small; skip.&quot;)
    return(obj_in)
  }
  rank_est &lt;- tryCatch(
    as.integer(Matrix::rankMatrix(t(Xsc))),
    error = function(e)
      NA_integer_
  )
  if (is.finite(rank_est))
    use_pcs_max &lt;- max(2L, min(use_pcs_max, rank_est - 1L))
  use_pcs &lt;- min(npcs, 50L, use_pcs_max)
  
  sub &lt;- tryCatch(
    RunPCA(
      sub,
      features = rownames(Xsc),
      npcs = use_pcs,
      approx = FALSE,
      verbose = FALSE
    ),
    error = function(e)
      NULL
  )
  if (is.null(sub) || is.null(sub@reductions$pca)) {
    message(&quot;[subclust] (keep &quot;, parent_key, &quot;) PCA failed; skip.&quot;)
    return(obj_in)
  }
  
  emb &lt;- tryCatch(
    Embeddings(sub, &quot;pca&quot;),
    error = function(e)
      NULL
  )
  if (is.null(emb) || ncol(emb) &lt; 2L) {
    message(&quot;[subclust] (keep &quot;,
            parent_key,
            &quot;) PCA embeddings too small; skip.&quot;)
    return(obj_in)
  }
  emb &lt;- as.matrix(emb)
  storage.mode(emb) &lt;- &quot;double&quot;
  avail &lt;- min(ncol(emb), use_pcs)
  
  # Neighbors with safe k
  k_eff &lt;- max(5L, min(k, parent_n - 2L, max(10L, floor(parent_n * 0.25))))
  gname &lt;- paste0(cfg$base_assay, &quot;_snn_sub_k&quot;, k_eff)
  sub &lt;- tryCatch(
    FindNeighbors(
      sub,
      dims = 1:avail,
      k.param = k_eff,
      graph.name = gname,
      verbose = FALSE
    ),
    error = function(e)
      NULL
  )
  if (is.null(sub)) {
    message(&quot;[subclust] (keep &quot;,
            parent_key,
            &quot;) FindNeighbors failed; skip.&quot;)
    return(obj_in)
  }
  
  # verify graph
  g_pick &lt;- if (has_valid_graph(sub, gname))
    gname
  else
    pick_snn(sub)
  if (is.null(g_pick) || !has_valid_graph(sub, g_pick)) {
    message(&quot;[subclust] (keep &quot;,
            parent_key,
            &quot;) SNN graph empty/invalid; skip.&quot;)
    return(obj_in)
  }
  
  # scan resolutions, try multiple algorithms via safe_findclusters()
  found_multi &lt;- FALSE
  last_ok &lt;- NULL
  for (res in res_grid) {
    sub_try &lt;- try(safe_findclusters(
      sub,
      graph.name = g_pick,
      resolution = res,
      seed = cfg$seed
    ),
    silent = TRUE)
    if (!inherits(sub_try, &quot;try-error&quot;)) {
      cl &lt;- as.character(Idents(sub_try))
      if (length(unique(cl)) &gt; 1L) {
        sub &lt;- sub_try
        found_multi &lt;- TRUE
        break
      }
      last_ok &lt;- sub_try
    }
  }
  # if never &gt;1, keep latest valid object and skip
  if (!found_multi) {
    message(&quot;[subclust] (keep &quot;,
            parent_key,
            &quot;) only one child at all resolutions; skip.&quot;)
    return(obj_in)
  }
  
  # children sizes (pre-merge)
  cl &lt;- as.character(Idents(sub))
  tab &lt;- sort(table(cl), decreasing = TRUE)
  message(
    &quot;[subclust] (&quot;,
    parent_key,
    &quot;) parent_n=&quot;,
    parent_n,
    &quot; | children: &quot;,
    paste(sprintf(&quot;%d:%d&quot;, seq_along(tab), tab), collapse = &quot;, &quot;),
    &quot; | min_allowed=&quot;,
    thr$min_allowed,
    &quot; [abs=&quot;,
    thr$abs_min,
    &quot;, prop=&quot;,
    min_prop,
    &quot;&quot;,
    thr$prop_min_calc,
    &quot;, tiny=&quot;,
    tiny_prop,
    &quot;&quot;,
    thr$tiny_min_calc,
    &quot;]&quot;
  )
  
  # collapse tiny by centroid
  if (collapse_tiny &amp;&amp; any(tab &lt; thr$tiny_min_calc)) {
    tiny_lvls &lt;- names(tab)[tab &lt; thr$tiny_min_calc]
    cl &lt;- .merge_labels_by_centroid(emb[, 1:avail, drop = FALSE], cl, tiny_lvls)
    Idents(sub) &lt;- factor(cl)
    tab &lt;- sort(table(cl), decreasing = TRUE)
    if (length(tab) &lt;= 1L) {
      message(&quot;[subclust] (keep &quot;,
              parent_key,
              &quot;) tiny merge  single child; skip.&quot;)
      return(obj_in)
    }
  }
  
  # enforce min size
  if (any(tab &lt; thr$min_allowed)) {
    small_lvls &lt;- names(tab)[tab &lt; thr$min_allowed]
    cl &lt;- .merge_labels_by_centroid(emb[, 1:avail, drop = FALSE], cl, small_lvls)
    Idents(sub) &lt;- factor(cl)
    tab &lt;- sort(table(cl), decreasing = TRUE)
    if (length(tab) &lt;= 1L) {
      message(&quot;[subclust] (keep &quot;,
              parent_key,
              &quot;) size merge  single child; skip.&quot;)
      return(obj_in)
    }
  }
  
  # final relabel gX.N
  ord &lt;- names(tab)
  idx_map &lt;- setNames(seq_along(ord), ord)
  child_nums   &lt;- unname(idx_map[as.character(Idents(sub))])
  child_labels &lt;- paste0(parent_key, &quot;.&quot;, child_nums)
  names(child_labels) &lt;- Cells(sub)
  
  # ensure v2 column exists as character
  if (!(new_key_name %in% colnames(obj_in@meta.data))) {
    obj_in@meta.data[[new_key_name]] &lt;- as.character(obj_in[[cluster_key_name]][, 1])
  } else if (!is.character(obj_in@meta.data[[new_key_name]])) {
    obj_in@meta.data[[new_key_name]] &lt;- as.character(obj_in@meta.data[[new_key_name]])
  }
  
  stopifnot(all(cells_parent %in% rownames(obj_in@meta.data)))
  # write values in the exact order of &#39;cells_parent&#39;
  vals &lt;- unname(child_labels[match(cells_parent, names(child_labels))])
  if (anyNA(vals)) {
    # if any NA slipped in, abort cleanly
    message(&quot;[subclust] (keep &quot;,
            parent_key,
            &quot;) child label mismatch; skip.&quot;)
    return(obj_in)
  }
  obj_in@meta.data[cells_parent, new_key_name] &lt;- vals
  obj_in@meta.data[[new_key_name]] &lt;- factor(obj_in@meta.data[[new_key_name]])
  
  message(&quot;[subclust] (&quot;,
          parent_key,
          &quot;) accepted split  &quot;,
          paste(sprintf(&quot;%d:%d&quot;, seq_along(tab), tab), collapse = &quot;, &quot;))
  obj_in
}




# --- STAGE: subclust driver -----------------------------------------------
auto_subcluster_suspicious &lt;- function(obj_in,
                                       annot_table,
                                       cluster_key_name = &quot;cluster_key&quot;,
                                       agree_cut = cfg$agree_cut) {
  stopifnot(inherits(obj_in, &quot;Seurat&quot;))
  obj_in &lt;- ensure_cluster_key(obj_in, cluster_key_name)
  if (!all(c(&quot;cluster&quot;, &quot;agree&quot;) %in% colnames(annot_table))) {
    message(&quot;[subclust] Annotation table lacks &#39;cluster&#39; and/or &#39;agree&#39;; skipping.&quot;)
    return(list(
      obj = obj_in,
      changed = FALSE,
      parents = character(0)
    ))
  }
  susp &lt;- annot_table %&gt;% dplyr::filter(agree &lt;= agree_cut) %&gt;% dplyr::arrange(agree) %&gt;% dplyr::pull(cluster) %&gt;% unique()
  nk_name &lt;- paste0(cluster_key_name, &quot;_v2&quot;)
  if (!length(susp)) {
    message(&quot;[subclust] No suspicious clusters (agree  &quot;,
            agree_cut,
            &quot;); nothing to split.&quot;)
    return(list(
      obj = obj_in,
      changed = FALSE,
      parents = character(0)
    ))
  }
  message(
    &quot;[subclust] Will subcluster &quot;,
    length(susp),
    &quot; parent(s): &quot;,
    paste(utils::head(susp, 10), collapse = &quot;, &quot;),
    if (length(susp) &gt; 10)
      &quot; ...&quot;
    else
      &quot;&quot;
  )
  obj_work &lt;- obj_in
  accepted &lt;- character(0)
  for (p in susp) {
    obj_try &lt;- try(subcluster_one(
      obj_in = obj_work,
      parent_key = p,
      cluster_key_name = cluster_key_name,
      new_key_name = nk_name,
      collapse_tiny = TRUE
    ),
    silent = TRUE)
    if (inherits(obj_try, &quot;try-error&quot;)) {
      msg &lt;- tryCatch(
        conditionMessage(attr(obj_try, &quot;condition&quot;)),
        error = function(e)
          &quot;unknown error&quot;
      )
      message(&quot;[subclust] (keep &quot;, p, &quot;) error: &quot;, msg)
      next
    }
    if (nk_name %in% colnames(obj_try@meta.data)) {
      lab_now &lt;- as.character(obj_try[[nk_name]][, 1])
      if (any(startsWith(lab_now, paste0(p, &quot;.&quot;)), na.rm = TRUE)) {
        accepted &lt;- c(accepted, p)
        obj_work &lt;- obj_try
      } else {
        message(&quot;[subclust] (keep &quot;, p, &quot;) no new children written; skip.&quot;)
      }
    }
  }
  list(
    obj = obj_work,
    changed = length(accepted) &gt; 0,
    parents = unique(accepted),
    new_key = nk_name
  )
}

needs_rerun_subclust &lt;- function() {
  if (!ckpt_has(&quot;subclust&quot;))
    return(TRUE)
  st &lt;- ckpt_load(&quot;subclust&quot;)
  if (!isTRUE(st$changed))
    return(FALSE)
  nk &lt;- st$new_key %||% &quot;cluster_key_v2&quot;
  obj2 &lt;- st$obj
  is.null(obj2) || !(nk %in% colnames(obj2@meta.data))
}

# --- timing helpers ---
.stage_time_log_add &lt;- function(stage,
                                t0,
                                t1,
                                ok = TRUE,
                                note = NULL) {
  rec &lt;- data.frame(
    stage = stage,
    start = as.character(t0),
    end   = as.character(t1),
    elapsed_sec = as.numeric(difftime(t1, t0, units = &quot;secs&quot;)),
    ok = ok,
    note = if (is.null(note))
      &quot;&quot;
    else
      as.character(note),
    stringsAsFactors = FALSE
  )
  if (ckpt_has(&quot;timings&quot;)) {
    log &lt;- ckpt_load(&quot;timings&quot;)
    log &lt;- rbind(log, rec)
  } else
    log &lt;- rec
  ckpt_save(&quot;timings&quot;, log)
  invisible(rec)
}
save_timings_to_xlsx &lt;- function(wb, sheet_name = &quot;timings&quot;) {
  if (!ckpt_has(&quot;timings&quot;))
    return(invisible(NULL))
  log &lt;- ckpt_load(&quot;timings&quot;)
  if (sheet_name %in% names(wb))
    removeWorksheet(wb, sheet_name)
  addWorksheet(wb, sheet_name)
  writeData(wb, sheet_name, log)
  invisible(log)
}

# --- CONFIG KNOBS defaults (keep) ---
cfg$subclust_res        &lt;- cfg$subclust_res        %||% c(0.2, 0.4, 0.6, 0.8, 1.0, 1.5, 2.0)
cfg$subclust_npcs       &lt;- cfg$subclust_npcs       %||% 30L
cfg$subclust_k          &lt;- cfg$subclust_k          %||% 30L
cfg$agree_cut           &lt;- cfg$agree_cut           %||% 0.6
cfg$min_child_abs       &lt;- cfg$min_child_abs       %||% 10L
cfg$min_child_prop      &lt;- cfg$min_child_prop      %||% 0.005
cfg$subclust_tiny_prop  &lt;- cfg$subclust_tiny_prop  %||% 0.015

# ---------------------------
# STAGES
# ---------------------------
stage_load &lt;- function() {
  message(&quot;Stage load...&quot;)
  stopifnot(file.exists(cfg$paths$markers_xlsx))
  cell_markers &lt;- openxlsx::read.xlsx(cfg$paths$markers_xlsx, sheet = 1)
  refs &lt;- prepare_marker_ref(cell_markers, gene_col = &quot;Markers_positive_SMESG&quot;)
  marker_ref_general  &lt;- refs$general
  marker_ref_detailed &lt;- refs$detailed
  marker_ref          &lt;- marker_ref_detailed
  
  anno_df &lt;- NULL
  if (!is.null(cfg$paths$anno_rdata) &amp;&amp;
      file.exists(cfg$paths$anno_rdata)) {
    load(cfg$paths$anno_rdata)
    nn &lt;- ls()
    hit &lt;- nn[sapply(nn, function(x)
      is.data.frame(get(x)) &amp;&amp; &quot;gene&quot; %in% names(get(x)))]
    if (length(hit)) {
      anno_df &lt;- get(hit[1])
      if (!&quot;all_anno&quot; %in% names(anno_df)) {
        alt &lt;- intersect(
          c(
            &quot;Annotation&quot;,
            &quot;Uniprot_protein_name&quot;,
            &quot;PFAM_domain_name&quot;,
            &quot;NCBI_ID&quot;
          ),
          names(anno_df)
        )
        anno_df$all_anno &lt;- if (length(alt))
          do.call(paste, c(anno_df[alt], sep = &quot;; &quot;))
        else
          NA_character_
      }
      anno_df &lt;- anno_df[, intersect(c(&quot;gene&quot;, &quot;all_anno&quot;), names(anno_df)), drop =
                           FALSE]
    }
  }
  if (!is.null(anno_df)) {
    # Ensure &#39;gene&#39; and &#39;all_anno&#39; exist and are plain character
    if (!&quot;gene&quot; %in% names(anno_df)) {
      alt &lt;- intersect(names(anno_df),
                       c(&quot;Gene&quot;, &quot;GeneID&quot;, &quot;gene_id&quot;, &quot;Gene_name&quot;, &quot;GeneID_version&quot;))
      if (length(alt)) names(anno_df)[match(alt[1], names(anno_df))] &lt;- &quot;gene&quot;
    }
    if (!&quot;all_anno&quot; %in% names(anno_df)) {
      alt &lt;- intersect(names(anno_df),
                       c(&quot;Annotation&quot;, &quot;Uniprot_protein_name&quot;, &quot;PFAM_domain_name&quot;, &quot;NCBI_ID&quot;))
      anno_df$all_anno &lt;- if (length(alt)) do.call(paste, c(anno_df[alt], sep=&quot;; &quot;)) else NA_character_
    }
    # &lt;- NEW: flatten possible list column to character
    if (is.list(anno_df$all_anno)) {
      anno_df$all_anno &lt;- vapply(anno_df$all_anno, as_chr_collapse, &quot;&quot;, USE.NAMES = FALSE)
    } else {
      anno_df$all_anno &lt;- as.character(anno_df$all_anno %||% &quot;&quot;)
    }
    anno_df$gene &lt;- trim(as.character(anno_df$gene))
    anno_df &lt;- unique(anno_df[, c(&quot;gene&quot;, &quot;all_anno&quot;)])
  }
  
  
  obj &lt;- NULL
  if (!is.null(cfg$paths$matrix_rds) &amp;&amp;
      file.exists(cfg$paths$matrix_rds)) {
    message(&quot;Loading from matrix_rds...&quot;)
    mat &lt;- readRDS(cfg$paths$matrix_rds)
    if (!inherits(mat, &quot;dgCMatrix&quot;))
      stop(&quot;matrix_rds must be dgCMatrix.&quot;)
    if (is.null(rownames(mat)))
      rownames(mat) &lt;- paste0(&quot;g&quot;, seq_len(nrow(mat)))
    if (is.null(colnames(mat)))
      colnames(mat) &lt;- paste0(&quot;c&quot;, seq_len(ncol(mat)))
    empty_counts &lt;- new(&quot;dgCMatrix&quot;,
                        Dim = dim(mat),
                        Dimnames = dimnames(mat))
    obj &lt;- CreateSeuratObject(
      counts = empty_counts,
      assay = cfg$base_assay,
      min.cells = 0,
      min.features = 0
    )
    if (&quot;SetAssayData&quot; %in% getNamespaceExports(&quot;SeuratObject&quot;)) {
      obj &lt;- SeuratObject::SetAssayData(
        obj,
        assay = cfg$base_assay,
        layer = &quot;data&quot;,
        new.data = mat
      )
      obj &lt;- SeuratObject::SetAssayData(
        obj,
        assay = cfg$base_assay,
        layer = &quot;counts&quot;,
        new.data = empty_counts
      )
    } else {
      obj[[cfg$base_assay]]@data   &lt;- mat
      obj[[cfg$base_assay]]@counts &lt;- empty_counts
    }
    DefaultAssay(obj) &lt;- cfg$base_assay
  } else {
    stopifnot(file.exists(cfg$paths$seurat_rdata))
    message(&quot;Loading from seurat_rdata...&quot;)
    load(cfg$paths$seurat_rdata)
    if (exists(&quot;integrated_seurat_obj_annotated_new&quot;))
      obj &lt;- integrated_seurat_obj_annotated_new
    else if (exists(&quot;integrated_seurat_obj&quot;))
      obj &lt;- integrated_seurat_obj
    else {
      nn &lt;- ls()
      cls &lt;- sapply(nn, function(x)
        class(get(x, inherits = FALSE))[1])
      cand &lt;- nn[grepl(&quot;Seurat&quot;, cls)]
      if (!length(cand))
        stop(&quot;No Seurat object found inside: &quot;, cfg$paths$seurat_rdata)
      obj &lt;- get(cand[1], inherits = FALSE)
    }
    DefaultAssay(obj) &lt;- cfg$base_assay
  }
  
  obj_small &lt;- diet_for_checkpoint(
    obj,
    keep_assay = cfg$base_assay,
    keep_reduc = character(),
    keep_graphs = character(),
    drop_counts = TRUE,
    drop_scale = TRUE
  )
  
  ckpt_save(
    &quot;load&quot;,
    list(
      obj = obj_small,
      marker_ref_general  = marker_ref_general,
      marker_ref_detailed = marker_ref_detailed,
      marker_ref          = marker_ref,
      anno_df = anno_df
    )
  )
  invisible(TRUE)
}

ensure_scaled &lt;- function(obj, assay, features, chunk = 4000L) {
  DefaultAssay(obj) &lt;- assay
  present &lt;- intersect(unique(features), rownames(Seurat::GetAssayData(
    obj, assay = assay, layer = &quot;data&quot;
  )))
  if (!length(present))
    return(obj)
  parts &lt;- split(present, ceiling(seq_along(present) / max(1L, chunk)))
  for (fs in parts)
    obj &lt;- ScaleData(
      object = obj,
      assay = assay,
      features = fs,
      do.center = TRUE,
      do.scale = TRUE,
      verbose = FALSE
    )
  obj
}

stage_pca &lt;- function() {
  message(&quot;Stage PCA...&quot;)
  st  &lt;- ckpt_load(&quot;load&quot;)
  obj &lt;- st$obj
  DefaultAssay(obj) &lt;- cfg$base_assay
  if (!length(VariableFeatures(obj)))
    obj &lt;- FindVariableFeatures(
      object = obj,
      assay = cfg$base_assay,
      selection.method = &quot;vst&quot;,
      nfeatures = 3000,
      verbose = FALSE
    )
  hvg &lt;- VariableFeatures(obj)
  if (!length(hvg))
    stop(&quot;No variable features.&quot;)
  obj &lt;- ensure_scaled(
    obj,
    assay = cfg$base_assay,
    features = hvg,
    chunk = 4000L
  )
  obj &lt;- RunPCA(
    object = obj,
    features = hvg,
    npcs = cfg$max_pcs,
    reduction.name = cfg$pca_name,
    reduction.key = &quot;PCu_&quot;,
    verbose = FALSE
  )
  stdev &lt;- obj@reductions[[cfg$pca_name]]@stdev
  if (is.null(stdev) || !length(stdev))
    stop(&quot;PCA failed.&quot;)
  dims &lt;- choose_pcs_by_knee(
    stdev,
    max_pcs = min(cfg$max_pcs, length(stdev)),
    variance_cut = cfg$variance_cut,
    smooth_k = cfg$knee_smooth,
    min_pcs = 25L
  )
  message(&quot;Chosen PCs: &quot;, dims)
  ckpt_save(
    &quot;pca&quot;,
    list(
      obj = obj,
      dims = dims,
      marker_ref_general  = st$marker_ref_general,
      marker_ref_detailed = st$marker_ref_detailed,
      marker_ref          = st$marker_ref,
      anno_df = st$anno_df
    )
  )
  invisible(TRUE)
}

stage_grid &lt;- function() {
  message(&quot;Stage grid...&quot;)
  st  &lt;- ckpt_load(&quot;pca&quot;)
  obj &lt;- st$obj
  dims &lt;- st$dims
  gs &lt;- grid_search_clusters(
    obj,
    dims,
    target_n = cfg$target_n_clusters,
    k_grid   = cfg$k_grid %||% c(5L, 8L, 10L, 15L, 20L),
    res_init = cfg$res_init %||% 0.6,
    res_max = cfg$res_max %||% 10,
    max_steps = cfg$grid_max_steps %||% 20
  )
  obj_best   &lt;- gs$obj
  best_stats &lt;- gs$stats
  keep_graph &lt;- gs$keep_graph
  message(
    sprintf(
      &quot;Best: k=%s res=%s clusters=%s modularity=%s&quot;,
      best_stats$k,
      best_stats$resolution,
      best_stats$n_clusters,
      round(best_stats$modularity, 3)
    )
  )
  obj_small &lt;- diet_for_checkpoint(obj_best,
                                   keep_reduc  = cfg$pca_name,
                                   keep_graphs = keep_graph)
  ckpt_save(
    &quot;grid&quot;,
    list(
      obj        = obj_small,
      dims = dims,
      best_stats = best_stats,
      keep_graph = keep_graph,
      marker_ref_general  = st$marker_ref_general,
      marker_ref_detailed = st$marker_ref_detailed,
      marker_ref          = st$marker_ref,
      anno_df    = st$anno_df
    )
  )
  invisible(TRUE)
}

stage_umap &lt;- function() {
  message(&quot;Stage UMAP...&quot;)
  st &lt;- ckpt_load(&quot;grid&quot;)
  obj &lt;- st$obj
  dims &lt;- st$dims
  obj &lt;- RunUMAP(
    obj,
    reduction = cfg$pca_name,
    dims = 1:dims,
    n.neighbors = 30,
    min.dist = 0.5,
    metric = &quot;cosine&quot;,
    reduction.name = cfg$umap_name,
    seed.use = cfg$seed,
    verbose = FALSE
  )
  obj$cluster_key &lt;- canon_cluster(as.character(Idents(obj)))
  obj_small &lt;- diet_for_checkpoint(
    obj,
    keep_reduc = c(cfg$pca_name, cfg$umap_name),
    keep_graphs = st$keep_graph
  )
  ckpt_update(&quot;umap&quot;, st, obj = obj_small)
  invisible(TRUE)
}

stage_deg &lt;- function() {
  message(&quot;Stage DEG...&quot;)
  st &lt;- ckpt_load(&quot;umap&quot;)
  obj &lt;- st$obj
  obj &lt;- ensure_cluster_key(obj, &quot;cluster_key&quot;)
  degs &lt;- compute_degs_robust(obj, group_col = &quot;cluster_key&quot;, features_whitelist = NULL)
  if (!nrow(degs))
    message(&quot;Stage DEG: no DEGs found.&quot;)
  ckpt_update(&quot;deg&quot;,
              st,
              obj = obj,
              degs = degs,
              group_col = &quot;cluster_key&quot;)
  try(deg_ckpt_save(
    prefix = &quot;deg&quot;,
    obj = obj,
    group_col = &quot;cluster_key&quot;,
    degs = degs,
    features = NULL
  ),
  silent = TRUE)
  obj_small &lt;- diet_for_checkpoint(
    obj,
    keep_reduc = c(cfg$pca_name, cfg$umap_name),
    keep_graphs = st$keep_graph
  )
  ckpt_update(&quot;umap&quot;, st, obj = obj_small)
  invisible(TRUE)
}

rehydrate_refs &lt;- function(st = NULL) {
  try_ck &lt;- function(tag)
    if (ckpt_has(tag))
      ckpt_load(tag)
  else
    NULL
  bins &lt;- list(st,
               try_ck(&quot;umap&quot;),
               try_ck(&quot;grid&quot;),
               try_ck(&quot;pca&quot;),
               try_ck(&quot;load&quot;))
  bins &lt;- bins[!vapply(bins, is.null, TRUE)]
  pick_df &lt;- function(x)
    is.data.frame(x) &amp;&amp;
    nrow(x) &gt; 0 &amp;&amp; all(c(&quot;gene&quot;, &quot;final_cluster&quot;) %in% names(x))
  pick_anno &lt;- function(x)
    is.data.frame(x) &amp;&amp; nrow(x) &gt; 0 &amp;&amp; &quot;gene&quot; %in% names(x)
  
  mr_gen &lt;- mr_det &lt;- mr &lt;- anno_df &lt;- NULL
  for (b in bins) {
    if (is.null(mr_gen) &amp;&amp;
        pick_df(b$marker_ref_general))
      mr_gen &lt;- b$marker_ref_general
    if (is.null(mr_det) &amp;&amp;
        pick_df(b$marker_ref_detailed))
      mr_det &lt;- b$marker_ref_detailed
    if (is.null(mr)     &amp;&amp;
        pick_df(b$marker_ref))
      mr     &lt;- b$marker_ref
    if (is.null(anno_df) &amp;&amp;
        pick_anno(b$anno_df))
      anno_df &lt;- b$anno_df
  }
  if (is.null(mr) || !pick_df(mr)) {
    stopifnot(file.exists(cfg$paths$markers_xlsx))
    cm  &lt;- openxlsx::read.xlsx(cfg$paths$markers_xlsx, sheet = 1)
    refs &lt;- prepare_marker_ref(cm, gene_col = &quot;Markers_positive_SMESG&quot;)
    mr_gen &lt;- refs$general
    mr_det &lt;- refs$detailed
    mr &lt;- mr_det
  }
  if (is.null(anno_df) &amp;&amp;
      !is.null(cfg$paths$anno_rdata) &amp;&amp;
      file.exists(cfg$paths$anno_rdata)) {
    load(cfg$paths$anno_rdata)
    nn &lt;- ls()
    hit &lt;- nn[sapply(nn, function(x)
      is.data.frame(get(x)) &amp;&amp; &quot;gene&quot; %in% names(get(x)))]
    if (length(hit)) {
      anno_df &lt;- get(hit[1])
      if (!&quot;all_anno&quot; %in% names(anno_df)) {
        alt &lt;- intersect(
          c(
            &quot;Annotation&quot;,
            &quot;Uniprot_protein_name&quot;,
            &quot;PFAM_domain_name&quot;,
            &quot;NCBI_ID&quot;
          ),
          names(anno_df)
        )
        anno_df$all_anno &lt;- if (length(alt))
          do.call(paste, c(anno_df[alt], sep = &quot;; &quot;))
        else
          NA_character_
      }
      anno_df &lt;- anno_df[, intersect(c(&quot;gene&quot;, &quot;all_anno&quot;), names(anno_df)), drop =
                           FALSE]
    }
  }
  list(
    marker_ref_general = mr_gen,
    marker_ref_detailed = mr_det,
    marker_ref = mr,
    anno_df = anno_df
  )
}

stage_annot1 &lt;- function() {
  message(&quot;Stage annot1...&quot;)
  st &lt;- ckpt_load(&quot;umap&quot;)
  refs &lt;- rehydrate_refs(st)
  st$marker_ref_general  &lt;- refs$marker_ref_general
  st$marker_ref_detailed &lt;- refs$marker_ref_detailed
  st$marker_ref          &lt;- refs$marker_ref
  st$anno_df             &lt;- refs$anno_df
  ckpt_update(
    &quot;umap&quot;,
    st,
    marker_ref_general = st$marker_ref_general,
    marker_ref_detailed = st$marker_ref_detailed,
    marker_ref = st$marker_ref,
    anno_df = st$anno_df
  )
  
  mr &lt;- st$marker_ref %||% st$marker_ref_detailed %||% st$marker_ref_general
  obj &lt;- st$obj
  
  degs_in &lt;- NULL
  if (ckpt_has(&quot;deg&quot;)) {
    d &lt;- ckpt_load(&quot;deg&quot;)
    if (is.list(d) &amp;&amp; !is.null(d$degs))
      degs_in &lt;- d$degs
  }
  if (is.null(degs_in)) {
    degs_in &lt;- try(deg_ckpt_load(
      prefix = &quot;deg&quot;,
      obj = obj,
      group_col = &quot;cluster_key&quot;,
      features = NULL
    ),
    silent = TRUE)
    if (inherits(degs_in, &quot;try-error&quot;))
      degs_in &lt;- NULL
  }
  mr &lt;- st$marker_ref %||% st$marker_ref_detailed %||% st$marker_ref_general
  
  ann1 &lt;- try(annotate_all_methods(
    obj,
    mr,
    cluster_key_name = &quot;cluster_key&quot;,
    prefix = &quot;annot_detailed&quot;,
    limit_clusters = NULL,
    deg_prefix = &quot;deg&quot;,
    degs_precomputed = degs_in
  ),
  silent = TRUE)
  
  good &lt;- is.list(ann1) &amp;&amp;
    !is.null(ann1$obj) &amp;&amp; !is.null(ann1$table)
  if (!good) {
    msg &lt;- if (inherits(ann1, &quot;try-error&quot;))
      as.character(attr(ann1, &quot;condition&quot;))
    else
      &quot;non-list return&quot;
    message(&quot;[annot1] annotate_all_methods failed: &quot;, msg)
    message(&quot;[annot1] Falling back to a minimal round1 table so the pipeline can proceed.&quot;)
    obj &lt;- ensure_cluster_key(obj, &quot;cluster_key&quot;)
    parents &lt;- sort(unique(canon_cluster(as.character(
      obj$cluster_key
    ))))
    tab1 &lt;- tibble::tibble(cluster = parents,
                           final_consensus = NA_character_,
                           agree = 0)
    try(ckpt_save(&quot;annot_table_last&quot;, list(table = tab1, saved_at = Sys.time())), silent = TRUE)
    wb &lt;- wb_load_or_new(cfg$paths$out_xlsx)
    write_results_xlsx(
      wb,
      sheet_prefix = &quot;round1&quot;,
      annot_tab = tab1,
      degs = if (isTRUE(cfg$write_round1_degs) &amp;&amp;
                 !is.null(degs_in) &amp;&amp; nrow(degs_in))
        degs_in
      else
        NULL,
      anno_df = st$anno_df
    )
    save_timings_to_xlsx(wb)
    wb_save(wb, cfg$paths$out_xlsx)
    obj_small &lt;- diet_for_checkpoint(
      obj,
      keep_reduc  = c(cfg$pca_name, cfg$umap_name),
      keep_graphs = st$keep_graph
    )
    ckpt_update(&quot;annot1&quot;, st, obj = obj_small, tab1 = tab1)
    return(invisible(TRUE))
  }
  
  obj  &lt;- ann1$obj
  tab1 &lt;- ann1$table %&gt;% dplyr::arrange(cluster)
  message(&quot;[annot][summary] Round1 (detailed) first 20 rows:&quot;)
  invisible(print_annotation_summary(tab1, n = 20))
  try(ckpt_save(&quot;annot1_table&quot;, list(tab = tab1, saved_at = Sys.time())), silent = TRUE)
  
  wb &lt;- wb_load_or_new(cfg$paths$out_xlsx)
  write_results_xlsx(
    wb,
    sheet_prefix = &quot;round1&quot;,
    annot_tab = tab1,
    degs = if (isTRUE(cfg$write_round1_degs))
      ann1$degs
    else
      NULL,
    anno_df = st$anno_df
  )
  save_timings_to_xlsx(wb)
  wb_save(wb, cfg$paths$out_xlsx)
  
  obj_small &lt;- diet_for_checkpoint(
    obj,
    keep_reduc  = c(cfg$pca_name, cfg$umap_name),
    keep_graphs = st$keep_graph
  )
  ckpt_update(&quot;annot1&quot;, st, obj = obj_small, tab1 = tab1)
  invisible(TRUE)
}

auto_split_large &lt;- function(obj,
                             key        = &quot;cluster_key_v2&quot;,
                             max_cells  = 1200L,
                             max_passes = 2L) {
  for (pass in seq_len(max_passes)) {
    lab &lt;- as.character(obj[[key]][,1])
    tt  &lt;- sort(table(lab), decreasing = TRUE)
    big &lt;- names(tt)[tt &gt; max_cells]
    if (!length(big)) {
      message(&quot;[autosplit] pass &quot;, pass, &quot;: nothing above &quot;, max_cells, &quot; cells.&quot;)
      break
    }
    message(&quot;[autosplit] pass &quot;, pass, &quot;: splitting &quot;, length(big), &quot; parents: &quot;,
            paste(head(big, 10), collapse=&quot;, &quot;), if (length(big)&gt;10) &quot; ...&quot; else &quot;&quot;)
    for (p in big) {
      obj &lt;- subcluster_one(
        obj_in = obj,
        parent_key = p,
        cluster_key_name = key,
        new_key_name     = key,   # in-place refinement of the same key
        collapse_tiny    = TRUE
      )
    }
  }
  obj$cluster_key_final &lt;- obj[[key]][,1]
  obj
}

stage_subclust &lt;- function() {
  message(&quot;Stage subcluster...&quot;)
  st &lt;- ckpt_load(&quot;annot1&quot;)
  if (is.null(st))
    stop(&quot;[subclust] Missing &#39;annot1&#39; checkpoint. Run annot1 first.&quot;)
  obj  &lt;- st$obj
  tab1 &lt;- st$tab1
  obj &lt;- ensure_cluster_key(obj, &quot;cluster_key&quot;)
  Idents(obj) &lt;- obj$cluster_key
  # if v2 exists but has no children (no dots), drop it to avoid confusion
  if (&quot;cluster_key_v2&quot; %in% colnames(obj@meta.data) &amp;&amp;
      !any(grepl(&quot;\\.&quot;, obj$cluster_key_v2))) {
    obj$cluster_key_v2 &lt;- NULL
  }
  
  
  susp &lt;- tryCatch(
    tab1 %&gt;% dplyr::filter(!is.na(agree) &amp;
                             agree &lt;= cfg$agree_cut) %&gt;% dplyr::pull(cluster) %&gt;% unique() %&gt;% as.character(),
    error = function(e)
      character(0)
  )
  if (!length(susp)) {
    message(&quot;[subclust] No parents below agree_cut (&quot;,
            cfg$agree_cut,
            &quot;). Nothing to split.&quot;)
    ckpt_save(&quot;subclust&quot;, c(st, list(obj = obj, changed = FALSE)))
    return(invisible(TRUE))
  }
  message(
    &quot;[subclust] Will subcluster &quot;,
    length(susp),
    &quot; parent(s): &quot;,
    paste(head(susp, 10), collapse = &quot;, &quot;),
    if (length(susp) &gt; 10)
      &quot; ...&quot;
    else
      &quot;&quot;
  )
  
  res &lt;- auto_subcluster_suspicious(
    obj,
    annot_table = tab1,
    cluster_key_name = &quot;cluster_key&quot;,
    agree_cut = cfg$agree_cut
  )
  obj &lt;- res$obj
  
  if (!isTRUE(res$changed)) {
    message(&quot;[subclust] No accepted splits (&quot;,
            length(res$parents),
            &quot; accepted).&quot;)
    ckpt_save(&quot;subclust&quot;, c(st, list(obj = obj, changed = FALSE)))
    return(invisible(TRUE))
  }
  
  gd &lt;- tryCatch(
    ckpt_load(&quot;grid&quot;),
    error = function(e)
      NULL
  )
  dims_umap &lt;- if (!is.null(gd) &amp;&amp; length(gd$dims))
    gd$dims
  else
    30L
  obj &lt;- RunUMAP(
    obj,
    reduction = cfg$pca_name,
    dims = 1:dims_umap,
    n.neighbors = 30,
    min.dist = 0.5,
    metric = &quot;cosine&quot;,
    reduction.name = paste0(cfg$umap_name, &quot;.v2&quot;),
    seed.use = cfg$seed,
    verbose = FALSE
  )
  
  #ckpt_save(&quot;subclust&quot;, c(st, list(obj = obj, parents = unique(res$parents), new_key = res$new_key, changed = TRUE)))
  st$obj     &lt;- obj
  st$parents &lt;- unique(res$parents)
  st$new_key &lt;- res$new_key
  st$changed &lt;- TRUE
  tot &lt;- ncol(st$obj)
  max_cells_auto &lt;- max(800L, round(0.0125 * tot))  #  ~1.25% of total cells, but at least 800
  st$obj &lt;- auto_split_large(st$obj, key = &quot;cluster_key_v2&quot;, max_cells = max_cells_auto, max_passes = 2L)
  ckpt_save(&quot;subclust&quot;, st)
  invisible(TRUE)
}




stage_annot2_and_final &lt;- function() {
  message(&quot;Stage annot2/final...&quot;)
  st1 &lt;- ckpt_load(&quot;annot1&quot;)
  stopifnot(!is.null(st1))
  obj  &lt;- st1$obj
  tab1 &lt;- st1$tab1
  
  # Use subclustered key if available/meaningful
  sc &lt;- tryCatch(
    ckpt_load(&quot;subclust&quot;),
    error = function(e)
      NULL
  )
  use_v2 &lt;- FALSE
  if (!is.null(sc) &amp;&amp; !is.null(sc$obj)) {
    if (&quot;cluster_key_v2&quot; %in% colnames(sc$obj@meta.data)) {
      v2 &lt;- as.character(sc$obj$cluster_key_v2)
      use_v2 &lt;- any(grepl(&quot;\\.&quot;, v2), na.rm = TRUE) ||
        (length(unique(na.omit(v2))) &gt; length(unique(as.character(
          sc$obj$cluster_key
        ))))
      if (use_v2)
        obj &lt;- sc$obj
    }
  }
  final_key &lt;- if (use_v2)
    &quot;cluster_key_v2&quot;
  else
    &quot;cluster_key&quot;
  message(
    if (use_v2)
      &quot;[annot2] Using subclustered key (cluster_key_v2).&quot;
    else
      &quot;[annot2] Using round1 key (cluster_key).&quot;
  )
  obj$cluster_key_final &lt;- obj[[final_key]][, 1]
  
  # Rehydrate marker refs / annotations
  refs &lt;- rehydrate_refs()
  mr   &lt;- refs$marker_ref %||% refs$marker_ref_detailed %||% refs$marker_ref_general
  
  # NEW: compute DEGs for the FINAL grouping and cache them (prefix &#39;deg_final&#39;)
  degs_final &lt;- compute_degs_robust(obj, group_col = &quot;cluster_key_final&quot;, features_whitelist = NULL)
  if (nrow(degs_final)) {
    try(deg_ckpt_save(
      prefix = &quot;deg_final&quot;,
      obj = obj,
      group_col = &quot;cluster_key_final&quot;,
      degs = degs_final,
      features = NULL
    ),
    silent = TRUE)
  } else {
    message(
      &quot;[annot2] WARNING: no DEGs passed filters for final key; DEG-based methods may return 0 labels.&quot;
    )
  }
  
  # Re-annotate using final key; feed the DEGs we just computed
  ann2 &lt;- annotate_all_methods(
    obj,
    mr,
    cluster_key_name = &quot;cluster_key_final&quot;,
    prefix           = &quot;annot_final&quot;,
    limit_clusters   = NULL,
    deg_prefix       = &quot;deg_final&quot;,
    degs_precomputed = if (nrow(degs_final))
      degs_final
    else
      NULL
  )
  obj  &lt;- ann2$obj
  tab2 &lt;- ann2$table %&gt;% dplyr::arrange(cluster)
  
  # Attach parent info from round-1 so its visible in Excel
  # Force data.frame/tibble types before joining (prevents class=&#39;character&#39; surprises)
  # ---- SAFER: attach parent info without dplyr joins ----
  # Ensure tab2 is a data.frame with a &#39;cluster&#39; column
  tab2 &lt;- ann2$table
  if (!is.data.frame(tab2))
    tab2 &lt;- as.data.frame(tab2, stringsAsFactors = FALSE)
  if (!&quot;cluster&quot; %in% names(tab2)) {
    if (!is.null(rownames(tab2))) {
      tab2$cluster &lt;- rownames(tab2)
    } else {
      stop(&quot;[annot2] &#39;tab2&#39; lacks a &#39;cluster&#39; column and rownames; cannot augment.&quot;)
    }
  }
  tab2$cluster &lt;- as.character(tab2$cluster)
  tab2 &lt;- tab2[order(tab2$cluster), , drop = FALSE]
  
  # Map each final label to its parent
  df_labels &lt;- data.frame(cluster = sort(unique(as.character(
    obj$cluster_key_final
  ))), stringsAsFactors = FALSE)
  df_labels$parent &lt;- sub(&quot;\\..*$&quot;, &quot;&quot;, df_labels$cluster)
  
  # Slim round1 table (parent consensus/agree)
  tab1_slim &lt;- as.data.frame(st1$tab1, stringsAsFactors = FALSE)
  tab1_slim &lt;- tab1_slim[, c(&quot;cluster&quot;, &quot;final_consensus&quot;, &quot;agree&quot;)]
  names(tab1_slim) &lt;- c(&quot;parent&quot;, &quot;parent_consensus&quot;, &quot;parent_agree&quot;)
  tab1_slim$parent &lt;- as.character(tab1_slim$parent)
  message(&quot;tab2 class: &quot;, paste(class(ann2$table), collapse = &quot;, &quot;))
  message(&quot;tab1 class: &quot;, paste(class(st1$tab1), collapse = &quot;, &quot;))
  
  # Base merges (keeps left order; no S3 generics involved)
  tab2_tmp &lt;- merge(tab2,
                    df_labels,
                    by = &quot;cluster&quot;,
                    all.x = TRUE,
                    sort = FALSE)
  tab2_aug &lt;- merge(tab2_tmp,
                    tab1_slim,
                    by = &quot;parent&quot;,
                    all.x = TRUE,
                    sort = FALSE)
  # --------------------------------------------------------
  
  # Write Excel: final_annot (augmented) + per-cluster DEG sheets
  wb &lt;- wb_load_or_new(cfg$paths$out_xlsx)
  write_results_xlsx(
    wb,
    sheet_prefix = &quot;final&quot;,
    annot_tab    = tab2_aug,
    degs         = ann2$degs,
    # will create final_&lt;cluster&gt; sheets now that DEGs exist
    anno_df      = refs$anno_df
  )
  save_timings_to_xlsx(wb)
  wb_save(wb, cfg$paths$out_xlsx)
  
  # Save checkpoint
  obj_small &lt;- diet_for_checkpoint(obj, keep_reduc = c(cfg$pca_name, cfg$umap_name, paste0(cfg$umap_name, &quot;.v2&quot;)))
  ckpt_save(
    &quot;annot2_and_final&quot;,
    list(
      obj          = obj_small,
      final_key    = &quot;cluster_key_final&quot;,
      final_labels = tab2_aug
    )
  )
  invisible(TRUE)
}


# Orchestrator ------------------------------------------------------------
auto_run &lt;- function(resume = TRUE,
                     stop_after = NULL) {
  stages &lt;- c(&quot;load&quot;,
              &quot;pca&quot;,
              &quot;grid&quot;,
              &quot;umap&quot;,
              &quot;deg&quot;,
              &quot;annot1&quot;,
              &quot;subclust&quot;,
              &quot;annot2_and_final&quot;)
  fns &lt;- list(
    load = stage_load,
    pca = stage_pca,
    grid = stage_grid,
    umap = stage_umap,
    deg = stage_deg,
    annot1 = stage_annot1,
    subclust = stage_subclust,
    annot2_and_final = stage_annot2_and_final
  )
  for (s in stages) {
    skip &lt;- resume &amp;&amp; ckpt_has(s)
    if (s == &quot;subclust&quot; &amp;&amp;
        resume &amp;&amp; ckpt_has(&quot;subclust&quot;) &amp;&amp; needs_rerun_subclust()) {
      message(&quot;[auto_run] subclust checkpoint is stale; re-running subclust.&quot;)
      skip &lt;- FALSE
    }
    if (skip) {
      message(&quot;Skipping stage &quot;, s, &quot; (found checkpoint).&quot;)
      next
    }
    message(&quot;&gt;&gt;&gt; Running stage &quot;, s)
    t0 &lt;- Sys.time()
    ok &lt;- TRUE
    note &lt;- NULL
    tryCatch({
      fns[[s]]()
    }, error = function(e) {
      ok &lt;- FALSE
      note &lt;- conditionMessage(e)
      stop(e)
    }, finally = {
      t1 &lt;- Sys.time()
      .stage_time_log_add(
        stage = s,
        t0 = t0,
        t1 = t1,
        ok = ok,
        note = note
      )
      message(sprintf(&quot;[timing] %s: %.1f sec&quot;, s, as.numeric(difftime(t1, t0, units =
                                                                        &quot;secs&quot;))))
    })
    if (!is.null(stop_after) &amp;&amp;
        identical(s, stop_after)) {
      message(&quot;Stop requested after stage: &quot;, s)
      break
    }
  }
  invisible(TRUE)
}

# ---------------------------
# RUN
# ---------------------------
CKPT_DIR  &lt;- cfg$ckpt_dir
ckpt_file &lt;- function(stage)
  file.path(CKPT_DIR, paste0(&quot;auto_annot_ckpt_&quot;, stage, &quot;.rds&quot;))

setwd(&quot;G:/PhD_final/sncRNA&quot;)

# Clear only late-stage checkpoints if needed
# unlink(ckpt_path_qs(&quot;annot1&quot;),          force = TRUE); unlink(ckpt_path_rds(&quot;annot1&quot;),          force = TRUE)
# unlink(ckpt_path_qs(&quot;subclust&quot;),        force = TRUE); unlink(ckpt_path_rds(&quot;subclust&quot;),        force = TRUE)
# unlink(ckpt_path_qs(&quot;annot2_and_final&quot;), force = TRUE)
# unlink(ckpt_path_rds(&quot;annot2_and_final&quot;), force = TRUE)
# unlink(ckpt_path_qs(&quot;final&quot;), force = TRUE)
# unlink(ckpt_path_rds(&quot;final&quot;), force = TRUE)

auto_run(resume = TRUE)

# Convenience diagnostics:
# diag &lt;- if (ckpt_has(&quot;grid&quot;))
#   ckpt_load(&quot;grid&quot;)$obj@misc$grid_diag
# else
#   NULL

# Convenience: pull final object (saved in annot2_and_final)
if (ckpt_has(&quot;annot2_and_final&quot;)) {
  result_obj &lt;- ckpt_load(&quot;annot2_and_final&quot;)$obj
  message(&quot;Final object available as `result_obj` (labels in &#39;$cluster_key_final&#39;).&quot;)
}
if (exists(&quot;.annot_obj_lean&quot;, envir = .GlobalEnv)) {
  obj_lean &lt;- get(&quot;.annot_obj_lean&quot;, envir = .GlobalEnv)
  X &lt;- Seurat::GetAssayData(obj_lean, assay = cfg$base_assay, layer = &quot;data&quot;)
  print(class(X))
  print(dim(X))
  print(object.size(X))
  str(obj_lean@misc$annot_avg_exp)
}
st &lt;- ckpt_load(&quot;annot1&quot;)
v &lt;- as.character(st$obj$cluster_key)   # st &lt;- ckpt_load(&quot;annot1&quot;)
names(v)
sc &lt;- ckpt_load(&quot;subclust&quot;)
table(names(sc))[&quot;obj&quot;]  # will be 2

#result_obj
#result_obj$final_consensus
# 1) Confirm final key has children
table(grepl(&quot;\\.&quot;, result_obj$cluster_key_final))
head(sort(unique(
  as.character(result_obj$cluster_key_final)
)))

# 2) Confirm per-method unprefixed columns exist
head(colnames(result_obj@meta.data)[colnames(result_obj@meta.data) %in%
                                      c(
                                        &quot;avg_exp&quot;,
                                        &quot;hypergeom&quot;,
                                        &quot;majority&quot;,
                                        &quot;logfc&quot;,
                                        &quot;cellmanam&quot;,
                                        &quot;hypergeomX&quot;,
                                        &quot;gsea&quot;,
                                        &quot;ucell&quot;,
                                        &quot;final_consensus&quot;,
                                        &quot;final_agree&quot;
                                      )])

# 3) Excel: look for a &#39;final_annot&#39; sheet and per-cluster &#39;final_&lt;cluster&gt;&#39; sheets (with DEGs)
table(grepl(&quot;\\.&quot;, result_obj$cluster_key_final))           # subclusters present
head(result_obj@meta.data$avg_exp)                           # unprefixed methods exist
&quot;final_annot&quot; %in% openxlsx::getSheetNames(cfg$paths$out_xlsx)
st &lt;- ckpt_load(&quot;annot1&quot;)
obj &lt;- st$obj
Idents(obj) &lt;- obj$cluster_key
obj2 &lt;- subcluster_one(
  obj_in = obj,
  parent_key = &quot;g60&quot;,
  cluster_key_name = &quot;cluster_key&quot;,
  new_key_name = &quot;cluster_key_v2&quot;
)
# Should not error; either split or skip cleanly:
table(startsWith(as.character(obj2$cluster_key_v2), &quot;g60.&quot;))
unique(result_obj$annot_final)
#result_obj$cluster_key_final
warnings()
head(result_obj$cluster_key_final)
unique(result_obj$cluster_key_final)
unique(result_obj$cluster_key_v2)
unique(result_obj$final_consensus)</code></pre>
</div>
<div id="script_5.r" class="section level3">
<h3>script_5.R</h3>
<ul>
<li><a href="scripts/script_5.R" target="_blank" rel="noopener">Open</a>
- <a href="scripts/script_5.R" download>Download</a></li>
</ul>
<pre class="r"><code>
# Marker statistics per cluster 
#   1) Computes average expression and % detected for a given gene set per cluster.
#   2) Builds a long, join-ready marker table from Seurat::DotPlot() data.
#   3) Builds a per-cluster marker summary (top markers passing a % threshold).
#   4) Optionally maps a curated per-cluster annotation file back to the Seurat object.

# ----------------------------
# 0) Minimal dependencies
# ----------------------------
stopifnot(requireNamespace(&quot;Seurat&quot;, quietly = TRUE))
stopifnot(requireNamespace(&quot;Matrix&quot;, quietly = TRUE))
stopifnot(requireNamespace(&quot;dplyr&quot;, quietly = TRUE))
stopifnot(requireNamespace(&quot;openxlsx&quot;, quietly = TRUE))

# ----------------------------
# 1) Small helpers
# ----------------------------

# Seurat v4/v5 compatibility: GetAssayData() uses slot (v4) or layer (v5).
.get_data &lt;- function(obj, assay, layer_or_slot = &quot;data&quot;) {
  # Seurat v5 uses `layer=`; v4 uses `slot=`.
  fmls &lt;- names(formals(Seurat::GetAssayData))
  if (&quot;layer&quot; %in% fmls) {
    return(Seurat::GetAssayData(obj, assay = assay, layer = layer_or_slot))
  }
  Seurat::GetAssayData(obj, assay = assay, slot = layer_or_slot)
}

# Remove leading &quot;g&quot; only when it precedes a Greek letter (to keep g1/g2 etc intact).
.strip_g_before_greek &lt;- function(x) {
  x &lt;- as.character(x)
  sub(&quot;^g(?=\\p{Greek})&quot;, &quot;&quot;, x, perl = TRUE)
}

# Safe column extraction from meta.data
.get_md &lt;- function(obj, col) {
  stopifnot(col %in% colnames(obj@meta.data))
  obj@meta.data[[col]]
}

# ----------------------------
# 2) Core computations
# ----------------------------

# Compute average expression + percent detected per group for gene list.
#
compute_avg_and_pct &lt;- function(obj,
                                genes,
                                group_col,
                                assay = Seurat::DefaultAssay(obj),
                                layer_or_slot = &quot;data&quot;,
                                fix_group_names = TRUE) {
  stopifnot(is.character(genes), length(genes) &gt; 0)
  stopifnot(group_col %in% colnames(obj@meta.data))

  genes_use &lt;- intersect(genes, rownames(obj))
  if (!length(genes_use)) stop(&quot;None of the provided genes are present in the object.&quot;, call. = FALSE)

  grp_raw &lt;- .get_md(obj, group_col)
  grp &lt;- as.character(grp_raw)
  if (fix_group_names) grp &lt;- .strip_g_before_greek(grp)

  # Drop NA groups 
  keep_cells &lt;- !is.na(grp)
  grp &lt;- grp[keep_cells]

  mat &lt;- .get_data(obj, assay = assay, layer_or_slot = layer_or_slot)
  mat &lt;- mat[genes_use, keep_cells, drop = FALSE]

  idx_by_grp &lt;- split(seq_along(grp), grp)

  avg_mat &lt;- do.call(cbind, lapply(idx_by_grp, function(ii) {
    Matrix::rowMeans(mat[, ii, drop = FALSE])
  }))

  pct_mat &lt;- do.call(cbind, lapply(idx_by_grp, function(ii) {
    Matrix::rowMeans(mat[, ii, drop = FALSE] &gt; 0)
  }))

  colnames(avg_mat) &lt;- names(idx_by_grp)
  colnames(pct_mat) &lt;- names(idx_by_grp)
  rownames(avg_mat) &lt;- rownames(mat)
  rownames(pct_mat) &lt;- rownames(mat)

  stopifnot(identical(colnames(avg_mat), colnames(pct_mat)))

  list(
    genes_use = genes_use,
    group_levels = colnames(avg_mat),
    avg_mat = avg_mat,
    pct_mat = pct_mat
  )
}

# For each gene: report top1/top2 groups and the delta between them.
rank_top_groups_per_gene &lt;- function(avg_mat, pct_mat) {
  stopifnot(all(dim(avg_mat) == dim(pct_mat)))

  genes &lt;- rownames(avg_mat)
  out &lt;- lapply(genes, function(g) {
    v &lt;- avg_mat[g, ]
    ord &lt;- order(v, decreasing = TRUE, na.last = TRUE)

    top1 &lt;- names(v)[ord[1]]
    top2 &lt;- if (length(ord) &gt;= 2) names(v)[ord[2]] else NA_character_

    data.frame(
      gene      = g,
      top1_pop  = top1,
      top1_avg  = unname(v[ord[1]]),
      top1_pct  = unname(pct_mat[g, top1]),
      top2_pop  = top2,
      top2_avg  = if (!is.na(top2)) unname(v[ord[2]]) else NA_real_,
      top2_pct  = if (!is.na(top2)) unname(pct_mat[g, top2]) else NA_real_,
      delta12   = if (!is.na(top2)) unname(v[ord[1]] - v[ord[2]]) else NA_real_,
      stringsAsFactors = FALSE
    )
  })

  dplyr::bind_rows(out) |&gt;
    dplyr::arrange(dplyr::desc(.data$delta12), dplyr::desc(.data$top1_avg))
}

# Build a long marker table for a marker reference XLSX using DotPlot() output.
build_marker_stats_table &lt;- function(obj,
                                     markers_xlsx,
                                     marker_gene_col = &quot;Markers_positive_SMESG&quot;,
                                     group_col = &quot;cluster_key_final&quot;,
                                     assay = &quot;SCT&quot;,
                                     layer_or_slot = &quot;data&quot;) {
  stopifnot(file.exists(markers_xlsx))
  stopifnot(group_col %in% colnames(obj@meta.data))

  # Read marker reference and keep only the relevant join columns.
  mk &lt;- openxlsx::read.xlsx(markers_xlsx)
  names(mk) &lt;- make.unique(names(mk))

  need_cols &lt;- c(
    marker_gene_col,
    &quot;Cell_population_general&quot;,
    &quot;Cell_population_detailed&quot;,
    &quot;Markers_positive_common.name&quot;
  )
  miss &lt;- setdiff(need_cols, names(mk))
  if (length(miss)) stop(&quot;Missing columns in marker XLSX: &quot;, paste(miss, collapse = &quot;, &quot;), call. = FALSE)

  mk_join &lt;- mk[, need_cols, drop = FALSE]
  mk_join[[marker_gene_col]] &lt;- trimws(gsub(&quot;\\t&quot;, &quot;&quot;, mk_join[[marker_gene_col]]))
  mk_join &lt;- unique(mk_join)

  # Restrict to markers present in the object (exact match; keep &quot;.1&quot; etc intact).
  feat_all &lt;- rownames(.get_data(obj, assay = assay, layer_or_slot = layer_or_slot))
  marker_raw &lt;- unique(mk_join[[marker_gene_col]])
  marker_raw &lt;- marker_raw[!is.na(marker_raw) &amp; marker_raw != &quot;&quot;]
  marker_present &lt;- marker_raw[marker_raw %in% feat_all]

  if (!length(marker_present)) stop(&quot;No marker genes from XLSX were found in the object (assay/layer mismatch?).&quot;, call. = FALSE)

  # Cluster size table
  n_cells_tbl &lt;- as.data.frame(table(obj[[group_col, drop = TRUE]]), stringsAsFactors = FALSE)
  colnames(n_cells_tbl) &lt;- c(group_col, &quot;n_cells&quot;)

  # DotPlot gives per-group mean and % detected (in the plotting data). 
  dp &lt;- Seurat::DotPlot(
    object   = obj,
    features = marker_present,
    group.by = group_col,
    assay    = assay
  )$data

  # Normalize column names across Seurat versions
  stats_tbl &lt;- dp |&gt;
    dplyr::transmute(
      !!group_col := .data$id,
      gene        = .data$features.plot,
      mean_expr   = .data$avg.exp,
      pct_expr    = .data$pct.exp
    ) |&gt;
    dplyr::left_join(n_cells_tbl, by = group_col) |&gt;
    dplyr::left_join(mk_join, by = setNames(marker_gene_col, &quot;gene&quot;)) |&gt;
    dplyr::arrange(.data[[group_col]], dplyr::desc(.data$pct_expr), dplyr::desc(.data$mean_expr))

  stats_tbl
}

# Summarize markers per cluster for quick manual review.
build_cluster_marker_summary &lt;- function(stats_tbl,
                                         group_col = &quot;cluster_key_final&quot;,
                                         thr = 20) {
  stopifnot(all(c(group_col, &quot;gene&quot;, &quot;pct_expr&quot;, &quot;mean_expr&quot;, &quot;n_cells&quot;) %in% colnames(stats_tbl)))

  stats_tbl |&gt;
    dplyr::mutate(
      Markers_positive_common.name = trimws(gsub(&quot;\\s+&quot;, &quot; &quot;, .data$Markers_positive_common.name))
    ) |&gt;
    dplyr::filter(
      !is.na(.data$Markers_positive_common.name),
      .data$Markers_positive_common.name != &quot;&quot;,
      .data$pct_expr &gt;= thr
    ) |&gt;
    dplyr::group_by(.data[[group_col]]) |&gt;
   
    dplyr::mutate(
      name_n_in_cluster = ave(.data$Markers_positive_common.name, .data$Markers_positive_common.name, FUN = length),
      marker_label = ifelse(
        .data$name_n_in_cluster &gt; 1,
        paste0(.data$Markers_positive_common.name, &quot; [&quot;, .data$gene, &quot;]&quot;),
        .data$Markers_positive_common.name
      )
    ) |&gt;
    dplyr::summarise(
      n_cells = dplyr::first(.data$n_cells),
      n_markers_passing = dplyr::n_distinct(.data$Markers_positive_common.name),
      markers_common = paste(
        .data$marker_label[order(-.data$pct_expr, .data$marker_label)],
        sprintf(&quot;(%.1f%%)&quot;, .data$pct_expr[order(-.data$pct_expr, .data$marker_label)]),
        sep = &quot; &quot;,
        collapse = &quot;; &quot;
      ),
      markers_SMESG = paste(sort(unique(.data$gene)), collapse = &quot;; &quot;),
      .groups = &quot;drop&quot;
    ) |&gt;
    dplyr::arrange(dplyr::desc(.data$n_markers_passing), .data[[group_col]])
}

# Compute mode + purity of an existing annotation per cluster.
mode_and_purity_by_cluster &lt;- function(obj, cluster_col, anno_col) {
  md &lt;- obj@meta.data |&gt;
    dplyr::select(dplyr::all_of(c(cluster_col, anno_col))) |&gt;
    dplyr::filter(!is.na(.data[[cluster_col]]), !is.na(.data[[anno_col]]))

  md |&gt;
    dplyr::count(.data[[cluster_col]], .data[[anno_col]], name = &quot;n_label&quot;) |&gt;
    dplyr::group_by(.data[[cluster_col]]) |&gt;
    dplyr::mutate(
      n_cluster = sum(.data$n_label),
      purity = .data$n_label / .data$n_cluster
    ) |&gt;
    dplyr::slice_max(order_by = .data$n_label, n = 1, with_ties = FALSE) |&gt;
    dplyr::ungroup() |&gt;
    dplyr::transmute(
      !!cluster_col := .data[[cluster_col]],
      anno_mode = .data[[anno_col]],
      anno_purity = round(100 * .data$purity, 1),
      n_cells_meta = .data$n_cluster
    )
}

# Map curated per-cluster annotations back onto cell
apply_curated_cluster_annotation &lt;- function(obj,
                                             curated_xlsx,
                                             cluster_col = &quot;cluster_key_final&quot;,
                                             out_col = &quot;final_population&quot;,
                                             fallback = &quot;Unknown&quot;) {
  stopifnot(file.exists(curated_xlsx))
  stopifnot(cluster_col %in% colnames(obj@meta.data))

  cur &lt;- openxlsx::read.xlsx(curated_xlsx)
  if (ncol(cur) &lt; 2) stop(&quot;Curated XLSX must have at least 2 columns: cluster and final_population.&quot;, call. = FALSE)

  # Standardize expected names: first col = cluster, second col = final_population.
  names(cur)[1:2] &lt;- c(&quot;cluster&quot;, &quot;final_population&quot;)
  cur &lt;- cur[!duplicated(cur$cluster) &amp; !is.na(cur$cluster), c(&quot;cluster&quot;, &quot;final_population&quot;), drop = FALSE]

  map &lt;- setNames(as.character(cur$final_population), as.character(cur$cluster))
  cl &lt;- as.character(obj[[cluster_col, drop = TRUE]])

  anno &lt;- unname(map[cl])
  anno[is.na(anno) | anno == &quot;&quot;] &lt;- fallback

  obj[[out_col]] &lt;- factor(anno, levels = unique(cur$final_population))
  obj
}



# Parameters
cluster_col &lt;- &quot;cluster_key_final&quot;      # cluster labels
assay_use   &lt;- &quot;SCT&quot;                    # or Seurat::DefaultAssay(result_obj)
layer_use   &lt;- &quot;data&quot;                   # &quot;data&quot; for log-normalized/SCT

# Marker XLSX workflow
markers_xlsx &lt;- &quot;G:/PhD_final/tables/cell_markers_curated_new_new_new_new.xlsx&quot;

# Output paths
out_stats_xlsx   &lt;- &quot;G:/PhD_final/tables/cluster_marker_metrics_by_cluster_key_final.xlsx&quot;
out_summary_xlsx &lt;- &quot;G:/PhD_final/tables/cluster_marker_summary2.xlsx&quot;

# Optional curated mapping
curated_xlsx &lt;- &quot;G:/PhD_final/tables/cluster_marker_summary_verified.xlsx&quot;
out_obj_rdata &lt;- &quot;G:/PhD_final/result_obj_new.RData&quot;

# --- Build marker statistics and write to XLSX ---
stats_tbl &lt;- build_marker_stats_table(
  obj = result_obj,
  markers_xlsx = markers_xlsx,
  marker_gene_col = &quot;Markers_positive_SMESG&quot;,
  group_col = cluster_col,
  assay = assay_use,
  layer_or_slot = layer_use
)
openxlsx::write.xlsx(stats_tbl, file = out_stats_xlsx, overwrite = TRUE)

# --- Summarize markers per cluster (for manual review) ---
cluster_marker_summary &lt;- build_cluster_marker_summary(stats_tbl, group_col = cluster_col, thr = 20)

anno_col_existing &lt;- &quot;final_population_fixed&quot;
if (anno_col_existing %in% colnames(result_obj@meta.data)) {
  old_anno &lt;- mode_and_purity_by_cluster(result_obj, cluster_col = cluster_col, anno_col = anno_col_existing)
  cluster_marker_summary &lt;- cluster_marker_summary |&gt;
    dplyr::left_join(old_anno, by = cluster_col) |&gt;
    dplyr::relocate(.data$anno_mode, .data$anno_purity, .after = dplyr::all_of(cluster_col))
}

openxlsx::write.xlsx(cluster_marker_summary, file = out_summary_xlsx, overwrite = TRUE)

# --- Apply curated annotation back to Seurat object ---
if (file.exists(curated_xlsx)) {
  result_obj &lt;- apply_curated_cluster_annotation(
    obj = result_obj,
    curated_xlsx = curated_xlsx,
    cluster_col = cluster_col,
    out_col = &quot;final_population&quot;,
    fallback = &quot;Unknown&quot;
  )

  # Basic cleanup 
  result_obj$final_population &lt;- factor(trimws(as.character(result_obj$final_population)))

  save(result_obj, file = out_obj_rdata)
}</code></pre>
</div>
<div id="script_7.sh" class="section level3">
<h3>script_7.sh</h3>
<ul>
<li><a href="scripts/script_7.sh" target="_blank" rel="noopener">Open</a>
- <a href="scripts/script_7.sh" download>Download</a></li>
</ul>
<pre class="bash"><code>#!/usr/bin/env bash
set -euo pipefail
#set -x
# ---------- SM paths ----------
BASEDIR=&quot;/mnt/d/scRNA-seq/small_RNA&quot;
DATADIR=&quot;${BASEDIR}/Data&quot;
REFDIR=&quot;${BASEDIR}/reference&quot;
REF_FASTA=&quot;${REFDIR}/SM_ncRNA_filtered.fa&quot;
BOWTIE_PREFIX=&quot;${REFDIR}/SM_ncRNA_filtered_bowtie2_index&quot;  
#GTF=&quot;${REFDIR}/final_anno_only_ncRNA.gtf&quot;                       
THREADS=8
ADAPTER=&quot;AGATCGGAAGAGCACACGTCTGAACTCCAGTCAC&quot;
MINLEN=14
# ----------------------------------------

# ---------- Conda env  ----------
source &quot;$(conda info --base)/etc/profile.d/conda.sh&quot;
conda activate srna_env

# ---------- Directory layout ----------
OUT=&quot;${BASEDIR}/GenXPro_our&quot;
RAWQC=&quot;${OUT}/qc/raw&quot;
TRIMQC=&quot;${OUT}/qc/trimmed&quot;
TRIM1=&quot;${OUT}/trimmed_adapter_q&quot;       # pass1
CLEAN=&quot;${OUT}/cleaned_poly&quot;            # pass2
EXTRACT=&quot;${OUT}/umi_extracted&quot;         # UMI after trimming
DEDUP=&quot;${OUT}/dedup_pre_align&quot;         # pre-align dedup
MAP=&quot;${OUT}/map_bowtie2&quot;
COUNT=&quot;${OUT}/counts&quot;
TPM=&quot;${OUT}/tpm&quot;
LOGS=&quot;${OUT}/logs&quot;
mkdir -p &quot;$OUT&quot; &quot;$RAWQC&quot; &quot;$TRIMQC&quot; &quot;$TRIM1&quot; &quot;$CLEAN&quot; &quot;$EXTRACT&quot; &quot;$DEDUP&quot; &quot;$MAP&quot; &quot;$COUNT&quot; &quot;$TPM&quot; &quot;$LOGS&quot;

# ---------- Helper: relaxed UMI extractor (8nt 5 UMI, optional 4nt 3 UMI) ----------
# Keeps reads lacking a recognizable 3 UMI by assigning UMI3=NNNN
set -x
echo &quot;UMI extraction (fast; parallel)&quot;
n_in=$(ls -1 &quot;${CLEAN}&quot;/*.clean.fastq.gz 2&gt;/dev/null | wc -l); [ &quot;$n_in&quot; -gt 0 ] || { echo &quot;No inputs in ${CLEAN}&quot;; exit 1; }

EXTRACT_PY=&quot;${OUT}/_umi_extract_relaxed.py&quot;
cat &gt; &quot;$EXTRACT_PY&quot; &lt;&lt; &#39;PY&#39;
import sys, gzip, os
from Bio.SeqIO.QualityIO import FastqGeneralIterator

inp, outp = sys.argv[1], sys.argv[2]
os.makedirs(os.path.dirname(outp), exist_ok=True)

def open_in(p):
    return gzip.open(p, &quot;rt&quot;) if p.endswith(&quot;.gz&quot;) else open(p, &quot;r&quot;)

with open_in(inp) as fh, gzip.open(outp, &quot;wb&quot;) as out:
    for h, s, q in FastqGeneralIterator(fh):
        if len(s) &lt; 9:
            continue
        umi5 = s[:8]; body = s[8:]
        if len(body) &gt;= 5:
            umi3 = body[-4:]; ins = body[:-4]; qins = q[8:-4]
        else:
            umi3 = &quot;NNNN&quot;; ins = body; qins = q[8:8+len(ins)]
        if not ins:
            continue
        out.write(f&quot;@{h.rstrip()} UMI:{umi5}-{umi3}\n{ins}\n+\n{qins}\n&quot;.encode())
PY




#echo &quot;UMI extraction (Biopython; 5&#39; UMI required, 3&#39; UMI optional)&quot;
#for fq in &quot;${CLEAN}&quot;/*.clean.fastq.gz; do
#  base=$(basename &quot;$fq&quot; .clean.fastq.gz)
#  python -u &quot;${EXTRACT_PY}&quot; &quot;$fq&quot; &quot;${EXTRACT}/${base}.umi.fastq.gz&quot; \
#    2&gt; &quot;${LOGS}/${base}.umi_extract.stderr&quot; || { echo &quot;UMI extract failed for $base&quot;; exit 1; }
#  ls -lh &quot;${EXTRACT}/${base}.umi.fastq.gz&quot; | cat
#  break
#done

for f in &quot;${EXTRACT}&quot;/*.umi.fastq.gz; do
  tmp=&quot;${f%.umi.fastq.gz}.umi.fixed.fastq.gz&quot;
  gzip -cd &quot;$f&quot; | awk &#39;NR%4==1{$0=&quot;@&quot;$0}1&#39; | gzip &gt; &quot;$tmp&quot; &amp;&amp; mv &quot;$tmp&quot; &quot;$f&quot;
done



# ---------- Helper: FASTQ dedup by exact (sequence + UMI pair) ----------
DEDUP_PY=&quot;${OUT}/_dedup_by_seq_umi.py&quot;
cat &gt; &quot;$DEDUP_PY&quot; &lt;&lt; &#39;PY&#39;
import sys, gzip, hashlib, os

inp, outp, logp = sys.argv[1], sys.argv[2], sys.argv[3]
os.makedirs(os.path.dirname(outp), exist_ok=True)

def opn_r(p): return gzip.open(p, &quot;rt&quot;) if p.endswith(&quot;.gz&quot;) else open(p, &quot;r&quot;)
def opn_w(p): return gzip.open(p, &quot;wb&quot;) if p.endswith(&quot;.gz&quot;) else open(p, &quot;wb&quot;)

def umi_from_header(h):
    # header starts with &#39;@&#39;; UMI stored like &quot;... UMI:NNNNNNNN-NNNN&quot;
    i = h.rfind(&quot;UMI:&quot;)
    return &quot;&quot; if i == -1 else h[i+4:].split()[0]

seen=set(); kept=dup=0
with opn_r(inp) as r, opn_w(outp) as w, open(logp,&quot;w&quot;) as lg:
    while True:
        h = r.readline()
        if not h: break
        s = r.readline().rstrip(&quot;\n&quot;)
        plus = r.readline()
        q = r.readline().rstrip(&quot;\n&quot;)

        if not h.startswith(&quot;@&quot;):    # guard against malformed records
            continue
        umi = umi_from_header(h.rstrip())
        key = hashlib.md5((s + &quot;|&quot; + umi).encode()).hexdigest()

        if key in seen:
            dup += 1
            continue
        seen.add(key); kept += 1

        w.write(h.encode())
        w.write((s + &quot;\n&quot;).encode())
        w.write(plus.encode())
        w.write((q + &quot;\n&quot;).encode())

    lg.write(f&quot;kept\t{kept}\nremoved_duplicates\t{dup}\n&quot;)
PY


# ---------- FastQC raw ----------
# fastqc -t $THREADS -o &quot;$RAWQC&quot; &quot;${DATADIR}&quot;/*.fastq.gz || true

# ---------- Cutadapt pass 1: adapter + quality (as in vendor report) ----------
# echo &quot;Cutadapt pass 1 (adapter+qtrim)&quot;
# for fq in &quot;${DATADIR}&quot;/*.fastq.gz; do
  # base=$(basename &quot;$fq&quot; .fastq.gz)
  # cutadapt -e 0.1 -O 3 -q 20 -m ${MINLEN} -n 8 \ #check!!!!!!!
           # -a &quot;${ADAPTER}&quot; \
           # -o &quot;${TRIM1}/${base}.trim1.fastq.gz&quot; &quot;$fq&quot; \
           # &gt; &quot;${TRIM1}/${base}.trim1.log&quot;
# done

# # ---------- Cutadapt pass 2: homopolymer cleaning ----------
# echo &quot;Cutadapt pass 2 (homopolymer cleaning)&quot;
# for fq in &quot;${TRIM1}&quot;/*.trim1.fastq.gz; do
  # base=$(basename &quot;$fq&quot; .trim1.fastq.gz)
  # cutadapt -a &#39;A{10};o=10&#39; -a &#39;T{10};o=10&#39; -a &#39;C{10};o=10&#39; -a &#39;G{10};o=10&#39; \ #check!!!!!!!
           # -n 3 -m ${MINLEN} \
           # -o &quot;${CLEAN}/${base}.clean.fastq.gz&quot; &quot;$fq&quot; \
           # &gt; &quot;${CLEAN}/${base}.clean.log&quot;
# done

# ---------- UMI extraction AFTER trimming (relaxed) ----------
echo &quot;UMI extraction (fast; 5&#39; UMI required, 3&#39; UMI optional)&quot;
# sanity: inputs present?
# n_in=$(ls -1 &quot;${CLEAN}&quot;/*.clean.fastq.gz 2&gt;/dev/null | wc -l)
# if [ &quot;$n_in&quot; -eq 0 ]; then
  # echo &quot;ERROR: No inputs in ${CLEAN}/*.clean.fastq.gz&quot; &gt;&amp;2; exit 1
# fi

# # parallel if available, else serial
# if command -v parallel &gt;/dev/null 2&gt;&amp;1; then
  # ls &quot;${CLEAN}&quot;/*.clean.fastq.gz \
  # | sed &#39;s#.*/##; s/.clean.fastq.gz$//&#39; \
  # | parallel -j ${THREADS} &#39;
      # python -u &quot;&#39;&quot;${EXTRACT_PY}&quot;&#39;&quot; \
        # &quot;&#39;&quot;${CLEAN}&quot;&#39;&quot;/{}.clean.fastq.gz \
        # &quot;&#39;&quot;${EXTRACT}&quot;&#39;&quot;/{}.umi.fastq.gz \
      # 2&gt; &quot;&#39;&quot;${LOGS}&quot;&#39;&quot;/{}.umi_extract.stderr
    # &#39;
# else
  # for fq in &quot;${CLEAN}&quot;/*.clean.fastq.gz; do
    # base=$(basename &quot;$fq&quot; .clean.fastq.gz)
    # python -u &quot;${EXTRACT_PY}&quot; &quot;$fq&quot; &quot;${EXTRACT}/${base}.umi.fastq.gz&quot; \
      # 2&gt; &quot;${LOGS}/${base}.umi_extract.stderr&quot;
  # done
# fi


# ---------- Deduplicate BEFORE mapping: exact (UMI pair + insert) ----------
echo &quot;Deduplicate (pre-align) by (UMI pair + insert sequence)&quot;
for fq in &quot;${EXTRACT}&quot;/*.umi.fastq.gz; do
  base=$(basename &quot;$fq&quot; .umi.fastq.gz)
  python &quot;${DEDUP_PY}&quot; &quot;$fq&quot; &quot;${DEDUP}/${base}.dedup.fastq.gz&quot; &quot;${DEDUP}/${base}.dedup.stats.txt&quot;
done

# ---------- Build Bowtie2 index if missing ----------
if [ ! -e &quot;${BOWTIE_PREFIX}.1.bt2&quot; ] &amp;&amp; [ ! -e &quot;${BOWTIE_PREFIX}.1.bt2l&quot; ]; then
  echo &quot;Building Bowtie2 index for ${REF_FASTA}&quot;
  bowtie2-build &quot;${REF_FASTA}&quot; &quot;${BOWTIE_PREFIX}&quot;
fi

# ---------- Map to ncRNA with Bowtie2 --sensitive --local ----------
echo &quot;Bowtie2 mapping (--sensitive --local) to ncRNA&quot;
mkdir -p &quot;${MAP}&quot;
for fq in &quot;${DEDUP}&quot;/*.dedup.fastq.gz; do
  base=$(basename &quot;$fq&quot; .dedup.fastq.gz)
  echo $base
  bowtie2 --threads ${THREADS} --sensitive --local \
          -x &quot;${BOWTIE_PREFIX}&quot; -U &quot;$fq&quot; \
    2&gt; &quot;${MAP}/${base}.bowtie2.log&quot; \
  | samtools view -b -F 4 - \
  | samtools sort -@4 -o &quot;${MAP}/${base}.sorted.bam&quot;
  samtools index &quot;${MAP}/${base}.sorted.bam&quot;
done

# ---------- GTF (autogenerate if absent) ----------
if [ ! -s &quot;${GTF}&quot; ]; then
  echo &quot;No GTF found at ${GTF}. Autogenerating from FASTA headers (single exon per record).&quot;
  GTF=&quot;${REFDIR}/autogen_ncRNA_from_fasta.gtf&quot;
  python - &quot;$REF_FASTA&quot; &quot;$GTF&quot; &lt;&lt; &#39;PYCODE&#39;
import sys, gzip
fa, gtf = sys.argv[1], sys.argv[2]
def op(p): return gzip.open(p,&#39;rt&#39;) if p.endswith(&#39;.gz&#39;) else open(p)
with op(fa) as fh, open(gtf,&#39;w&#39;) as out:
    name=None; seq=[]
    def flush(nm, seqlen):
        if not nm: return
        out.write(f&quot;{nm}\tgenxpro\ttranscript\t1\t{seqlen}\t.\t+\t.\ttranscript_id \&quot;{nm}\&quot;; gene_id \&quot;{nm}\&quot;;\n&quot;)
    for line in fh:
        if line.startswith(&#39;&gt;&#39;):
            if name is not None:
                flush(name, len(&#39;&#39;.join(seq)))
            name=line[1:].strip().split()[0]
            seq=[]
        else:
            seq.append(line.strip())
    if name is not None:
        flush(name, len(&#39;&#39;.join(seq)))
PYCODE
fi

# ---------- htseq-count ----------
echo &quot;htseq-count on BAMs&quot;
mkdir -p &quot;${COUNT}&quot;
GTF=&quot;${REFDIR}/autogen_ncRNA_from_fasta.gtf&quot;
for bam in &quot;${MAP}&quot;/*.sorted.bam; do
  base=$(basename &quot;$bam&quot; .sorted.bam)
  echo $base
  htseq-count -f bam -r pos -s no -a 0 -t transcript -i transcript_id \
    --nonunique=fraction \
    &quot;$bam&quot; &quot;$GTF&quot; &gt; &quot;${COUNT}/${base}.counts.txt&quot;
  #htseq-count \
  #  -f bam \
  #  -r pos \                # coordinate-sorted BAM
  #  -s no \                 # unstranded
  #  -a 0 \                  # no min AQual filter
  #  -t transcript \         # your GTF uses &#39;transcript&#39;
  #  -i transcript_id \      # attribute you wrote
  #  &quot;$bam&quot; &quot;$GTF&quot; &gt; &quot;${COUNT}/${base}.counts.txt&quot;
done



featureCounts -T ${THREADS} -s 0 -t transcript -g transcript_id -M --fraction \
  -a &quot;${REFDIR}/autogen_ncRNA_from_fasta.gtf&quot; \
  -o &quot;${COUNT}/featureCounts.transcript.txt&quot; \
  ${MAP}/*.sorted.bam

# ---------- Merge counts and compute TPM ----------
echo &quot;Merge counts and compute TPM&quot;
samtools faidx &quot;${REF_FASTA}&quot;
mkdir -p &quot;${TPM}&quot;
cut -f1,2 &quot;${REF_FASTA}.fai&quot; &gt; &quot;${TPM}/lengths.tsv&quot;

python - &quot;${COUNT}&quot; &quot;${TPM}/lengths.tsv&quot; &quot;${TPM}&quot; &lt;&lt; &#39;PYCODE&#39;
import sys, os, glob, csv
from collections import defaultdict
count_dir, len_path, out_dir = sys.argv[1], sys.argv[2], sys.argv[3]
lengths = {}
with open(len_path) as f:
    for line in f:
        tid, ln = line.rstrip().split(&#39;\t&#39;)[:2]
        lengths[tid] = float(ln)
samples=[]; counts=defaultdict(dict)
for fn in sorted(glob.glob(os.path.join(count_dir, &quot;*.counts.txt&quot;))):
    s=os.path.basename(fn).replace(&quot;.counts.txt&quot;,&quot;&quot;); samples.append(s)
    with open(fn) as fh:
        for row in fh:
            if row.startswith(&quot;__&quot;): continue
            tid,c=row.rstrip().split(&#39;\t&#39;); counts[tid][s]=float(c)
all_ids=list(counts.keys())
with open(os.path.join(out_dir,&quot;counts_matrix.tsv&quot;),&quot;w&quot;,newline=&quot;&quot;) as out:
    w=csv.writer(out,delimiter=&#39;\t&#39;); w.writerow([&quot;transcript_id&quot;]+samples)
    for tid in all_ids: w.writerow([tid]+[int(counts[tid].get(s,0)) for s in samples])
def tpm_for_sample(s):
    rpk={}; 
    for tid in all_ids:
        ln=lengths.get(tid,0.0); c=counts[tid].get(s,0.0)
        rpk[tid]=0.0 if ln&lt;=0 else c/(ln/1000.0)
    denom=sum(rpk.values()) or 1.0
    return {tid:(v/denom)*1e6 for tid,v in rpk.items()}
per={s:tpm_for_sample(s) for s in samples}
with open(os.path.join(out_dir,&quot;tpm_matrix.tsv&quot;),&quot;w&quot;,newline=&quot;&quot;) as out:
    w=csv.writer(out,delimiter=&#39;\t&#39;); w.writerow([&quot;transcript_id&quot;]+samples)
    for tid in all_ids: w.writerow([tid]+[f&quot;{per[s][tid]:.6f}&quot; for s in samples])
PYCODE

# ---------- MultiQC ----------
multiqc &quot;${OUT}&quot; -o &quot;${OUT}/multiqc&quot;

echo &quot;Done.&quot;
echo &quot;Outputs:&quot;
echo &quot;  - Trimmed:       ${TRIM1}&quot;
echo &quot;  - Cleaned:       ${CLEAN}&quot;
echo &quot;  - UMI-extracted: ${EXTRACT}&quot;
echo &quot;  - Deduped:       ${DEDUP}&quot;
echo &quot;  - BAMs:          ${MAP}&quot;
echo &quot;  - Counts:        ${COUNT}&quot;
echo &quot;  - TPM:           ${TPM}&quot;</code></pre>
</div>
<div id="script_8.r" class="section level3">
<h3>script_8.R</h3>
<ul>
<li><a href="scripts/script_8.R" target="_blank" rel="noopener">Open</a>
- <a href="scripts/script_8.R" download>Download</a></li>
</ul>
<pre class="r"><code>###############################################################################
# small RNA activity / enrichment in scRNA-seq (no Wilcoxon; no UCell)
#
# Core idea
# 1) Build sRNAtarget gene sets by seed scanning against UTR ( CDS).
# 2) Score each cell by a control-matched module score for the target set.
#    - This reduces cell type baseline bias that often makes one population dominate.
# 3) Summarize per (celltype  timepoint  genotype) and test genotype effects
#    using a permutation test (directional, based on bulk sRNA change).
#
# Notes / constraints
# - You have 1 library per (condition  timepoint), so genotype p-values are
#   exploratory (cells are not true biological replicates). Treat as prioritization.
###############################################################################

options(stringsAsFactors = FALSE)
set.seed(1)

suppressPackageStartupMessages({
  library(Seurat)
  library(Matrix)
  library(Biostrings)
  library(data.table)
  library(stringr)
  library(&quot;xlsx&quot;)
  library(ggplot2)
})
# ---------------------- sRNA sequence extraction -----------------------------
extract_seq_from_id &lt;- function(id) {
  # pull a plausible nucleotide string; supports N and U
  s &lt;- stringr::str_extract(id, &quot;[ACGTUNacgtun]{15,100}&quot;)
  if (is.na(s)) return(NA_character_)
  s &lt;- toupper(s)
  s &lt;- chartr(&quot;U&quot;, &quot;T&quot;, s)
  s
}
# ------------------------------- load data -----------------------------------
load(&quot;G:/PhD_final/result_obj_new.RData&quot;)                  # result_obj: Seurat obj
#load(&quot;G:/PhD_final/tRNA_miRNA_selected_raw_counts.RData&quot;)  # tRNA_miRNA_selected_raw_counts
load(&quot;G:/PhD_final/all_stringtie_selected.RData&quot;)          # all_stringtie_selected
load(&quot;D:/scRNA-seq/tRF_motif/cds_tx_seq.RData&quot;)            # cds_tx_seq
load(&quot;D:/scRNA-seq/tRF_motif/tx2gene.RData&quot;)               # tx2gene
load(&quot;D:/scRNA-seq/tRF_motif/utr_tx_seq.RData&quot;)            # utr_tx_seq
load(&quot;D:/scRNA-seq/AZ_final_obj/filtered_DEG_abr_new.RData&quot;)# filtered_DE (optional)
load(&quot;G:/PhD_final/final_bulk_DGE.RData&quot;)                  # final_test_DGE (optional)
#load(&quot;G:/PhD_final/tables/bulk_dir_tbl_LFC057.RData&quot;)      # bulk_dir_tbl (sRNA DE)

#all RNA type accumulation
not_rRNA=read.xlsx(&quot;D:/Elac2/final_results/tables/DGE_other_than_rRF_snRNA_filtered_new.xlsx&quot;,sheetIndex=1)
unique(not_rRNA$RNA_type)
bulk_dir_tbl &lt;- not_rRNA
bulk_dir_tbl &lt;- bulk_dir_tbl[bulk_dir_tbl$set==&quot;Elac_vs_WT_dpa3&quot; &amp; bulk_dir_tbl$RNA_type %in% c(&quot;miRNAs&quot;,&quot;piRNAs&quot;,&quot;tRFs&quot;),]
bulk_dir_tbl &lt;- bulk_dir_tbl[,c(&quot;snRNA_type&quot;,&quot;Sequence&quot;,&quot;log2FoldChange&quot;)]
colnames(bulk_dir_tbl) &lt;- c(&quot;snRNA_type&quot;,&quot;Sequence&quot;,&quot;bulk_log2FC_3dpa&quot;)
bulk_dir_tbl$Sequence &lt;- chartr(&quot;U&quot;, &quot;T&quot;, bulk_dir_tbl$Sequence)
bulk_dir_tbl$sRNA &lt;- paste(bulk_dir_tbl$Sequence,bulk_dir_tbl$snRNA_type,sep=&quot; &quot;)

# ----------------------------- user parameters --------------------------------
OUT_DIR &lt;- &quot;G:/PhD_final/tables/srna_activity_sc&quot;
if (!dir.exists(OUT_DIR)) dir.create(OUT_DIR, recursive = TRUE)

# Seurat parsing
ASSAY_USE &lt;- &quot;RNA&quot;              # or &quot;SCT&quot; if you want SCT residual-like data
SLOT_USE  &lt;- &quot;data&quot;             # &quot;data&quot; = log-normalized; &quot;counts&quot; only if you know what you&#39;re doing
MIN_CELLS_PER_GROUP &lt;- 20       # per (celltype,timepoint,genotype)

# Which genotypes to compare
GENO_KEEP &lt;- c(&quot;WT&quot;, &quot;ELAC&quot;, &quot;GFP&quot;)    # you can include &quot;GFP&quot; if needed

# Timepoints to analyze (NULL = all detected)
#TIMEPOINTS_TO_USE &lt;- c(0, 16, 24, 72)
TIMEPOINTS_TO_USE &lt;- 72
# Target scanning
USE_CDS_IN_SCAN &lt;- TRUE
CDS_WEIGHT_MULT &lt;- 0.5          # downweight CDS sites vs UTR
MIN_GENE_SCORE  &lt;- 3            # minimum weighted site score to keep a gene
TOP_N_GENES     &lt;- 500          # cap target set size (keeps scoring stable)

# Module score (control-matched)
N_BINS_EXPR     &lt;- 24           # expression bins for control matching
CTRL_PER_TARGET &lt;- 20           # controls sampled per target gene
MIN_TARGETS_FOR_SCORE &lt;- 15

# Permutation test (run only on top strata per sRNA to keep runtime sane)
DO_PERMUTATION  &lt;- TRUE
N_PERM          &lt;- 2000
TEST_TOP_STRATA &lt;- 15           # per (sRNA,model): compute perm p only for top |delta| strata

# If bulk_dir_tbl has expected_target_change (DOWN_in_ELAC/UP_in_ELAC) use it; else derive from bulk_log2FC_3dpa
# expected_target_change = &quot;DOWN_in_ELAC&quot; means sRNA is UP in ELAC (targets expected DOWN) =&gt; activity expected HIGHER in ELAC.

TARGET_MODELS &lt;- c(&quot;miRNA_canonical&quot;, &quot;piRNA_extended&quot;, &quot;off1_7mer&quot;, &quot;off2_7mer&quot;, &quot;off3_7mer&quot;)

# Cache (target scanning is expensive)
TARGET_CACHE_RDS &lt;- file.path(OUT_DIR, &quot;targets_cache_corr.rds&quot;)

# ----------------------------- sanity checks ---------------------------------
stopifnot(exists(&quot;result_obj&quot;))
seu &lt;- result_obj
Seurat::DefaultAssay(seu) &lt;- ASSAY_USE

stopifnot(exists(&quot;bulk_dir_tbl&quot;))
bulk_dir_tbl &lt;- as.data.table(bulk_dir_tbl)
stopifnot(&quot;sRNA&quot; %in% names(bulk_dir_tbl))

if (!inherits(utr_tx_seq, &quot;DNAStringSet&quot;)) utr_tx_seq &lt;- Biostrings::DNAStringSet(utr_tx_seq)
if (!inherits(cds_tx_seq, &quot;DNAStringSet&quot;)) cds_tx_seq &lt;- Biostrings::DNAStringSet(cds_tx_seq)

# tx2gene can be a named vector or a 2-col df
as_tx2gene_named &lt;- function(tx2gene_obj) {
  if (is.vector(tx2gene_obj) &amp;&amp; !is.null(names(tx2gene_obj))) return(tx2gene_obj)
  if (is.data.frame(tx2gene_obj)) {
    cn &lt;- tolower(colnames(tx2gene_obj))
    tx_col   &lt;- colnames(tx2gene_obj)[match(TRUE, cn %in% c(&quot;tx&quot;,&quot;transcript&quot;,&quot;transcript_id&quot;,&quot;tx_id&quot;))]
    gene_col &lt;- colnames(tx2gene_obj)[match(TRUE, cn %in% c(&quot;gene&quot;,&quot;gene_id&quot;,&quot;geneid&quot;))]
    if (is.na(tx_col) || is.na(gene_col)) stop(&quot;tx2gene needs transcript and gene columns.&quot;)
    v &lt;- as.character(tx2gene_obj[[gene_col]])
    names(v) &lt;- as.character(tx2gene_obj[[tx_col]])
    return(v)
  }
  stop(&quot;Unrecognized tx2gene format.&quot;)
}
tx2gene_map &lt;- as_tx2gene_named(tx2gene)

# ------------------------- metadata column discovery --------------------------
pick_col &lt;- function(df, candidates) {
  hit &lt;- candidates[candidates %in% colnames(df)]
  if (length(hit) &gt; 0) return(hit[[1]])
  NA_character_
}

meta &lt;- seu@meta.data

CELLTYPE_COL &lt;- pick_col(meta, c(&quot;final_population&quot;,&quot;celltype_use&quot;,&quot;celltype&quot;,&quot;CellType&quot;,&quot;seurat_clusters&quot;))
COND_COL     &lt;- pick_col(meta, c(&quot;condition_correct&quot;,&quot;sc_condition_full&quot;,&quot;condition&quot;,&quot;orig.ident&quot;))

unique(meta$final_population)
if (is.na(CELLTYPE_COL) || is.na(COND_COL)) {
  stop(&quot;Could not find metadata columns for celltype and condition. Update CELLTYPE_COL / COND_COL candidates.&quot;)
}

# Parse strings like &quot;WT13S&quot;, &quot;ELAC24S&quot;, &quot;GFP0S&quot; -&gt; genotype + timepoint
parse_condition &lt;- function(x) {
  x &lt;- as.character(x)
  base &lt;- stringr::str_extract(x, &quot;^[A-Za-z]+&quot;)
  tp   &lt;- suppressWarnings(as.integer(stringr::str_extract(x, &quot;[0-9]+&quot;)))
  data.table(genotype = base, timepoint = tp, condition_full = x)
}

parsed &lt;- parse_condition(meta[[COND_COL]])
seu$genotype &lt;- parsed$genotype
seu$timepoint &lt;- parsed$timepoint
seu$celltype_use &lt;- as.character(meta[[CELLTYPE_COL]])

# keep timepoints
tp_present &lt;- sort(unique(seu$timepoint[!is.na(seu$timepoint)]))
TP_USE &lt;- if (is.null(TIMEPOINTS_TO_USE)) tp_present else intersect(tp_present, TIMEPOINTS_TO_USE)
if (length(TP_USE) == 0) stop(&quot;No requested timepoints found in Seurat metadata.&quot;)

# subset
cells_keep &lt;- which(seu$genotype %in% GENO_KEEP &amp; seu$timepoint %in% TP_USE &amp; !is.na(seu$celltype_use))
seu_use &lt;- subset(seu, cells = rownames(seu@meta.data)[cells_keep])

# group filter: require MIN_CELLS_PER_GROUP per (celltype,timepoint,genotype)
md &lt;- as.data.table(seu_use@meta.data, keep.rownames = &quot;cell&quot;)
gcnt &lt;- md[, .N, by=.(celltype_use, timepoint, genotype)]
good_groups &lt;- gcnt[N &gt;= MIN_CELLS_PER_GROUP]
md &lt;- md[good_groups, on=.(celltype_use, timepoint, genotype), nomatch=0L]
seu_use &lt;- subset(seu_use, cells = md$cell)

md &lt;- as.data.table(seu_use@meta.data, keep.rownames = &quot;cell&quot;)

# -------------------------- expression matrix --------------------------------
Seurat::DefaultAssay(seu_use) &lt;- ASSAY_USE
expr &lt;- Seurat::GetAssayData(seu_use, slot = SLOT_USE)
if (!inherits(expr, &quot;dgCMatrix&quot;)) expr &lt;- as(expr, &quot;dgCMatrix&quot;)


rc_dna &lt;- function(dna) {
  as.character(Biostrings::reverseComplement(Biostrings::DNAString(dna)))
}

# ---------------------------- target models ----------------------------------
get_patterns_miRNA_canonical &lt;- function(seq_dna) {
  if (is.na(seq_dna) || nchar(seq_dna) &lt; 8) return(character(0))
  s7 &lt;- substr(seq_dna, 2, 8)  # 28
  s6 &lt;- substr(seq_dna, 2, 7)  # 27
  c(
    &quot;7mer-m8&quot; = rc_dna(s7),
    &quot;7mer-1A&quot; = paste0(&quot;A&quot;, rc_dna(s6)),
    &quot;8mer-1A&quot; = paste0(&quot;A&quot;, rc_dna(s7))
  )
}

get_patterns_piRNA_extended &lt;- function(seq_dna) {
  if (is.na(seq_dna) || nchar(seq_dna) &lt; 12) return(character(0))
  s7  &lt;- substr(seq_dna, 2, 8)
  s10 &lt;- substr(seq_dna, 2, 11)
  s11 &lt;- substr(seq_dna, 2, 12)
  c(
    &quot;seed_2_8&quot; = rc_dna(s7),
    &quot;ext_2_11&quot; = rc_dna(s10),
    &quot;ext_2_12&quot; = rc_dna(s11)
  )
}

get_patterns_offset_kmer &lt;- function(seq_dna, offset = 1, k = 7) {
  if (is.na(seq_dna) || nchar(seq_dna) &lt; (offset + k - 1)) return(character(0))
  s &lt;- substr(seq_dna, offset, offset + k - 1)
  setNames(rc_dna(s), paste0(k, &quot;mer_off&quot;, offset))
}

model_def &lt;- list(
  miRNA_canonical = function(seq_dna) {
    pats &lt;- get_patterns_miRNA_canonical(seq_dna)
    w &lt;- c(&quot;7mer-m8&quot;=2, &quot;7mer-1A&quot;=1, &quot;8mer-1A&quot;=3)
    list(patterns=pats, weights=w)
  },
  piRNA_extended = function(seq_dna) {
    pats &lt;- get_patterns_piRNA_extended(seq_dna)
    w &lt;- c(&quot;seed_2_8&quot;=1, &quot;ext_2_11&quot;=3, &quot;ext_2_12&quot;=4)
    list(patterns=pats, weights=w)
  },
  off1_7mer = function(seq_dna) {
    pats &lt;- get_patterns_offset_kmer(seq_dna, offset=1, k=7)
    w &lt;- setNames(2, names(pats))
    list(patterns=pats, weights=w)
  },
  off2_7mer = function(seq_dna) {
    pats &lt;- get_patterns_offset_kmer(seq_dna, offset=2, k=7)
    w &lt;- setNames(2, names(pats))
    list(patterns=pats, weights=w)
  },
  off3_7mer = function(seq_dna) {
    pats &lt;- get_patterns_offset_kmer(seq_dna, offset=3, k=7)
    w &lt;- setNames(2, names(pats))
    list(patterns=pats, weights=w)
  }
)

# ---------------------- fast scanning with PDict ------------------------------
count_weighted_hits &lt;- function(subject_seqs, patterns_named, weights_named, fixed = TRUE) {
  if (length(patterns_named) == 0) return(setNames(numeric(0), character(0)))
  
  nm &lt;- intersect(names(patterns_named), names(weights_named))
  patterns_named &lt;- patterns_named[nm]
  weights_named  &lt;- weights_named[nm]
  if (length(patterns_named) == 0) return(setNames(numeric(0), character(0)))
  
  subj_names &lt;- names(subject_seqs)
  if (is.null(subj_names)) subj_names &lt;- as.character(seq_along(subject_seqs))
  
  score &lt;- setNames(numeric(length(subject_seqs)), subj_names)
  
  wlen &lt;- nchar(unname(patterns_named))
  idx_by_len &lt;- split(seq_along(patterns_named), wlen)
  
  ns &lt;- length(subject_seqs)
  
  for (idx in idx_by_len) {
    pats &lt;- Biostrings::DNAStringSet(unname(patterns_named[idx]))
    names(pats) &lt;- names(patterns_named)[idx]
    np &lt;- length(pats)
    
    cnt &lt;- tryCatch(
      {
        pd &lt;- Biostrings::PDict(pats)
        Biostrings::vcountPDict(pd, subject_seqs, fixed = fixed)
      },
      error = function(e) {
        # vapply returns subjects  patterns when np &gt; 1
        vapply(seq_along(pats), function(i) {
          Biostrings::vcountPattern(pats[[i]], subject_seqs, fixed = fixed)
        }, FUN.VALUE = integer(ns))
      }
    )
    
    # ---- normalize cnt to patterns  subjects ----
    if (is.null(dim(cnt))) {
      # single pattern: vector of length ns
      cnt &lt;- matrix(as.integer(cnt), nrow = 1, ncol = ns)
    } else {
      cnt &lt;- as.matrix(cnt)
      # if subjects  patterns, transpose
      if (nrow(cnt) == ns &amp;&amp; ncol(cnt) == np) cnt &lt;- t(cnt)
    }
    
    # final sanity check
    if (nrow(cnt) != np || ncol(cnt) != ns) {
      stop(sprintf(
        &quot;Unexpected count matrix shape: %d%d; expected %d%d (patternssubjects).&quot;,
        nrow(cnt), ncol(cnt), np, ns
      ))
    }
    
    rownames(cnt) &lt;- names(pats)
    colnames(cnt) &lt;- subj_names
    
    w2 &lt;- as.numeric(weights_named[rownames(cnt)])
    w2[is.na(w2)] &lt;- 0
    
    score &lt;- score + as.numeric(matrix(w2, nrow = 1) %*% cnt)
  }
  
  score
}



scan_targets_genelevel &lt;- function(seq_dna,
                                   utr_seqs, cds_seqs, tx2gene_named,
                                   patterns, weights,
                                   use_cds = TRUE,
                                   cds_mult = 0.5,
                                   min_gene_score = 3,
                                   top_n_genes = 400) {
  if (is.na(seq_dna) || length(patterns) == 0) return(data.table(gene=character(0), weight=numeric(0)))
  
  utr_score &lt;- count_weighted_hits(utr_seqs, patterns, weights, fixed=FALSE)
  tx_score &lt;- utr_score
  
  if (isTRUE(use_cds)) {
    cds_score &lt;- count_weighted_hits(cds_seqs, patterns, weights, fixed=FALSE)
    # align / add
    tx_all &lt;- union(names(tx_score), names(cds_score))
    out &lt;- setNames(numeric(length(tx_all)), tx_all)
    out[names(tx_score)] &lt;- out[names(tx_score)] + tx_score
    out[names(cds_score)] &lt;- out[names(cds_score)] + cds_mult * cds_score
    tx_score &lt;- out
  }
  
  tx_keep &lt;- names(tx_score)[tx_score &gt;= min_gene_score]
  if (length(tx_keep) == 0) return(data.table(gene=character(0), weight=numeric(0)))
  
  g &lt;- as.character(tx2gene_named[tx_keep])
  ok &lt;- !is.na(g) &amp; nzchar(g)
  if (!any(ok)) return(data.table(gene=character(0), weight=numeric(0)))
  
  # sum transcript scores per gene
  gene_score &lt;- tapply(tx_score[tx_keep[ok]], g[ok], sum)
  gene_score &lt;- sort(gene_score, decreasing = TRUE)
  gene_score &lt;- gene_score[seq_len(min(length(gene_score), top_n_genes))]
  
  data.table(gene = names(gene_score), weight = as.numeric(gene_score))
}

# ----------------------- build / load target cache ----------------------------
srnas_to_run &lt;- unique(bulk_dir_tbl$sRNA)
srna_seq_tbl &lt;- data.table(sRNA = srnas_to_run)
srna_seq_tbl[, seq_dna := vapply(sRNA, extract_seq_from_id, character(1))]
#if (file.exists(TARGET_CACHE_RDS)) file.remove(TARGET_CACHE_RDS)

if (file.exists(TARGET_CACHE_RDS)) {
  message(&quot;Loading target cache: &quot;, TARGET_CACHE_RDS)
  target_cache &lt;- readRDS(TARGET_CACHE_RDS)
} else {
  message(&quot;Building targets (can be slow). Will save cache to: &quot;, TARGET_CACHE_RDS)
  
  target_cache &lt;- list()  # names: &quot;&lt;sRNA&gt;__&lt;model&gt;&quot; ; value: data.table(gene, weight)
  for (sid in srna_seq_tbl$sRNA) {
    seq_dna &lt;- srna_seq_tbl[sRNA == sid, seq_dna][1]
    if (is.na(seq_dna)) next
    
    for (m in TARGET_MODELS) {
      def &lt;- model_def[[m]](seq_dna)
      if (length(def$patterns) == 0) next
      
      tg &lt;- scan_targets_genelevel(
        seq_dna = seq_dna,
        utr_seqs = utr_tx_seq,
        cds_seqs = cds_tx_seq,
        tx2gene_named = tx2gene_map,
        patterns = def$patterns,
        weights = def$weights,
        use_cds = USE_CDS_IN_SCAN,
        cds_mult = CDS_WEIGHT_MULT,
        min_gene_score = MIN_GENE_SCORE,
        top_n_genes = TOP_N_GENES
      )
      
      # keep only genes present in scRNA matrix
      tg &lt;- tg[gene %in% rownames(expr)]
      if (nrow(tg) == 0) next
      
      key &lt;- paste0(sid, &quot;__&quot;, m)
      target_cache[[key]] &lt;- tg
    }
  }
  saveRDS(target_cache, TARGET_CACHE_RDS)
}

if (length(target_cache) == 0) stop(&quot;No targets in cache. Check sequence parsing and scan thresholds.&quot;)

#saveRDS(target_cache, &quot;G:/PhD_final/tables/srna_activity_sc/targets_cache_copy.rds&quot;)
#TARGET_CACHE_RDS &lt;- file.path(OUT_DIR, &quot;targets_cache.rds&quot;)
# ------------------ expression bins for control matching ----------------------
# Use global average expression to bin genes
# Use global average expression to bin genes
gene_means &lt;- Matrix::rowMeans(expr)

# Ensure gene IDs are present as names (robust even if Matrix drops them)
if (is.null(names(gene_means))) names(gene_means) &lt;- rownames(expr)

gene_means &lt;- gene_means[is.finite(gene_means)]
gene_means &lt;- gene_means[intersect(names(gene_means), rownames(expr))]

qs &lt;- quantile(gene_means, probs = seq(0, 1, length.out = N_BINS_EXPR + 1), na.rm = TRUE)
qs &lt;- unique(qs)
if (length(qs) &lt; 5) stop(&quot;Expression binning failed (too few unique quantiles).&quot;)

gene_bin &lt;- cut(gene_means, breaks = qs, include.lowest = TRUE, labels = FALSE)

# Fix: restore names so split() has gene IDs to split
names(gene_bin) &lt;- names(gene_means)

gene_bin &lt;- gene_bin[!is.na(gene_bin)]
genes_by_bin &lt;- split(names(gene_bin), gene_bin)


seed_from_string &lt;- function(s) {
  x &lt;- utf8ToInt(s)
  as.integer((sum(x) + 131 * length(x)) %% .Machine$integer.max)
}

pick_controls_matched &lt;- function(target_genes, ctrl_per_target = 20L, seed = 1L) {
  tg &lt;- unique(target_genes)
  tg &lt;- tg[tg %in% names(gene_bin)]
  if (length(tg) == 0) return(character(0))
  
  set.seed(seed)
  ctrl &lt;- character(0)
  for (g in tg) {
    b &lt;- gene_bin[[g]]
    pool &lt;- setdiff(genes_by_bin[[as.character(b)]], tg)
    if (length(pool) == 0) next
    take &lt;- min(length(pool), ctrl_per_target)
    ctrl &lt;- c(ctrl, sample(pool, size = take, replace = FALSE))
  }
  unique(ctrl)
}

# ---------------------- activity scoring (per cell) ---------------------------
# Score = (weighted mean target expr) - (mean matched-control expr)
# Activity (repression) = -Score, so that targets DOWN =&gt; activity increases.
weighted_mean_expr &lt;- function(expr_mat, genes, weights = NULL) {
  if (length(genes) == 0) return(rep(NA_real_, ncol(expr_mat)))
  genes &lt;- genes[genes %in% rownames(expr_mat)]
  if (length(genes) == 0) return(rep(NA_real_, ncol(expr_mat)))
  
  sub &lt;- expr_mat[genes, , drop = FALSE]
  if (is.null(weights)) {
    return(Matrix::colMeans(sub))
  }
  w &lt;- weights[match(genes, names(weights))]
  w[is.na(w)] &lt;- 0
  if (sum(w) &lt;= 0) return(Matrix::colMeans(sub))
  w &lt;- w / sum(w)
  
  # t(sub) %*% w  -&gt; vector per cell
  as.numeric(Matrix::t(sub) %*% w)
}

score_srna_activity &lt;- function(expr_mat, tg_dt, ctrl_per_target=20L, min_targets=15L, seed=1L) {
  tg &lt;- unique(tg_dt$gene)
  if (length(tg) &lt; min_targets) return(rep(NA_real_, ncol(expr_mat)))
  
  w &lt;- tg_dt$weight
  names(w) &lt;- tg_dt$gene
  w &lt;- w[w &gt; 0]
  
  ctrl &lt;- pick_controls_matched(tg, ctrl_per_target = ctrl_per_target, seed = seed)
  if (length(ctrl) &lt; min_targets) return(rep(NA_real_, ncol(expr_mat)))
  
  s_tg   &lt;- weighted_mean_expr(expr_mat, tg, weights = w)
  s_ctrl &lt;- weighted_mean_expr(expr_mat, ctrl, weights = NULL)
  
  score &lt;- s_tg - s_ctrl
  activity &lt;- -score
  activity
}

# ---------------------- permutation test helper -------------------------------
perm_test_delta_mean &lt;- function(x, g01, nperm=2000L, seed=1L, alternative=c(&quot;two.sided&quot;,&quot;greater&quot;,&quot;less&quot;)) {
  alternative &lt;- match.arg(alternative)
  ok &lt;- is.finite(x) &amp; !is.na(g01)
  x &lt;- x[ok]
  g01 &lt;- g01[ok]
  if (length(unique(g01)) != 2) return(list(p=NA_real_, obs=NA_real_))
  
  obs &lt;- mean(x[g01 == 1]) - mean(x[g01 == 0])
  
  set.seed(seed)
  n &lt;- length(x)
  g &lt;- as.integer(g01)
  null &lt;- numeric(nperm)
  for (i in seq_len(nperm)) {
    gp &lt;- sample(g, size = n, replace = FALSE)
    null[i] &lt;- mean(x[gp == 1]) - mean(x[gp == 0])
  }
  
  if (alternative == &quot;two.sided&quot;) {
    p &lt;- (1 + sum(abs(null) &gt;= abs(obs))) / (nperm + 1)
  } else if (alternative == &quot;greater&quot;) {
    p &lt;- (1 + sum(null &gt;= obs)) / (nperm + 1)
  } else {
    p &lt;- (1 + sum(null &lt;= obs)) / (nperm + 1)
  }
  
  list(p=p, obs=obs)
}

# ------------------- expected direction from bulk table -----------------------
if (!(&quot;expected_target_change&quot; %in% names(bulk_dir_tbl))) {
  if (!(&quot;bulk_log2FC_3dpa&quot; %in% names(bulk_dir_tbl))) stop(&quot;bulk_dir_tbl needs expected_target_change or bulk_log2FC_3dpa&quot;)
  bulk_dir_tbl[, expected_target_change := ifelse(bulk_log2FC_3dpa &gt; 0, &quot;DOWN_in_ELAC&quot;, &quot;UP_in_ELAC&quot;)]
}
# expected activity delta sign: DOWN_in_ELAC -&gt; activity higher in ELAC (+)
bulk_dir_tbl[, expected_activity_sign := ifelse(expected_target_change == &quot;DOWN_in_ELAC&quot;, +1, -1)]

# ------------------- run: per sRNA  model activity summary -------------------
# Prepare strata ids
md[, strata := paste(celltype_use, timepoint, sep=&quot;||&quot;)]
md[, geno01 := ifelse(genotype == &quot;ELAC&quot;, 1L, 0L)]

# Keep only strata with both genotypes present and enough cells
strata_ok &lt;- md[, .(n_WT = sum(geno01 == 0), n_ELAC = sum(geno01 == 1)), by=strata]
strata_ok &lt;- strata_ok[n_WT &gt;= MIN_CELLS_PER_GROUP &amp; n_ELAC &gt;= MIN_CELLS_PER_GROUP]
md &lt;- md[strata %in% strata_ok$strata]

if (nrow(strata_ok) == 0) stop(&quot;No strata pass MIN_CELLS_PER_GROUP for both WT and ELAC.&quot;)

# Main results collector
res_list &lt;- list()

keys &lt;- names(target_cache)
message(&quot;Scoring &quot;, length(keys), &quot; (sRNA,model) target sets.&quot;)


for (key in keys) {
  sid   &lt;- sub(&quot;__.*$&quot;, &quot;&quot;, key)
  model &lt;- sub(&quot;^.*__&quot;, &quot;&quot;, key)
  
  tg_dt &lt;- target_cache[[key]]
  if (is.null(tg_dt) || nrow(tg_dt) &lt; MIN_TARGETS_FOR_SCORE) next
  
  seed_key &lt;- seed_from_string(key)
  
  # score activity
  activity &lt;- score_srna_activity(
    expr_mat = expr,
    tg_dt = tg_dt,
    ctrl_per_target = CTRL_PER_TARGET,
    min_targets = MIN_TARGETS_FOR_SCORE,
    seed = seed_key
  )
  if (is.null(activity) || all(is.na(activity))) next
  
  # attach to metadata (keep only cells that exist in expr)
  dt &lt;- md[, .(cell, celltype_use, timepoint, genotype, geno01, strata)]
  dt &lt;- dt[cell %in% colnames(expr)]
  
  if (!is.null(names(activity))) {
    dt[, activity := activity[cell]]
  } else {
    dt[, activity := activity[match(cell, colnames(expr))]]
  }
  
  # summarize means per group
  sm &lt;- dt[, .(
    n = .N,
    mean_activity = mean(activity, na.rm = TRUE),
    sd_activity = sd(activity, na.rm = TRUE)
  ), by = .(celltype_use, timepoint, genotype, strata)]
  
  # wide tables
  smw  &lt;- data.table::dcast(sm,  celltype_use + timepoint + strata ~ genotype, value.var = &quot;mean_activity&quot;)
  smn  &lt;- data.table::dcast(sm,  celltype_use + timepoint + strata ~ genotype, value.var = &quot;n&quot;)
  smsd &lt;- data.table::dcast(sm,  celltype_use + timepoint + strata ~ genotype, value.var = &quot;sd_activity&quot;)
  
  # need WT and ELAC to compute delta
  if (!all(c(&quot;WT&quot;, &quot;ELAC&quot;) %in% names(smw))) next
  if (!all(c(&quot;WT&quot;, &quot;ELAC&quot;) %in% names(smn))) next
  if (!all(c(&quot;WT&quot;, &quot;ELAC&quot;) %in% names(smsd))) next
  
  smw[, delta_ELAC_minus_WT := ELAC - WT]
  smw[, n_WT   := smn[[&quot;WT&quot;]]]
  smw[, n_ELAC := smn[[&quot;ELAC&quot;]]]
  
  # effect size (Cohen&#39;s d) using pooled SD
  pooled_sd &lt;- sqrt(
    ((smw$n_WT - 1) * (smsd[[&quot;WT&quot;]]^2) + (smw$n_ELAC - 1) * (smsd[[&quot;ELAC&quot;]]^2)) /
      pmax(smw$n_WT + smw$n_ELAC - 2, 1)
  )
  pooled_sd &lt;- pmax(pooled_sd, 1e-8)
  smw[, cohen_d := delta_ELAC_minus_WT / pooled_sd]
  
  # expected direction info from bulk (3 dpa)
  exp &lt;- bulk_dir_tbl[sRNA == sid]
  if (nrow(exp) == 0) next
  
  exp_sign &lt;- exp$expected_activity_sign[1]
  smw[, expected_activity_sign := exp_sign]
  smw[, expected_activity_change := ifelse(exp_sign &gt; 0, &quot;DOWN_in_ELAC&quot;, &quot;UP_in_ELAC&quot;)]
  smw[, bulk_log2FC_3dpa := exp$bulk_log2FC_3dpa[1]]
  smw[, expected_target_change := exp$expected_target_change[1]]
  
  # expected-direction filter at stratum level
  smw[, delta_expected := delta_ELAC_minus_WT * expected_activity_sign]
  smw[, ok_dir := is.finite(delta_expected) &amp; (delta_expected &gt; 0)]
  
  # permutation p-values
  smw[, perm_p_two_sided := NA_real_]
  smw[, perm_p_expected  := NA_real_]
  
  if (isTRUE(DO_PERMUTATION)) {
    
    strata_to_test &lt;- unique(smw[ok_dir == TRUE, strata])
    
    for (st in strata_to_test) {
      sub &lt;- dt[strata == st &amp; is.finite(activity)]
      
      # require both groups to have enough cells
      n0 &lt;- sub[, sum(geno01 == 0L)]
      n1 &lt;- sub[, sum(geno01 == 1L)]
      if (n0 &lt; MIN_CELLS_PER_GROUP || n1 &lt; MIN_CELLS_PER_GROUP) next
      
      # two-sided
      pt2 &lt;- perm_test_delta_mean(
        x = sub$activity,
        g01 = sub$geno01,
        nperm = N_PERM,
        seed = seed_key + seed_from_string(st),
        alternative = &quot;two.sided&quot;
      )
      
      # directional (expected sign)
      alt &lt;- if (exp_sign &gt; 0) &quot;greater&quot; else &quot;less&quot;
      ptd &lt;- perm_test_delta_mean(
        x = sub$activity,
        g01 = sub$geno01,
        nperm = N_PERM,
        seed = seed_key + 7L + seed_from_string(st),
        alternative = alt
      )
      
      smw[strata == st, perm_p_two_sided := pt2$p]
      smw[strata == st, perm_p_expected  := ptd$p]
    }
  }
  
  # annotate and store
  smw[, sRNA := sid]
  smw[, model := model]
  smw[, n_targets := nrow(tg_dt)]
  
  res_list[[length(res_list) + 1L]] &lt;- smw
}

res &lt;- rbindlist(res_list, fill = TRUE)
if (nrow(res) == 0) stop(&quot;No results produced. Check target cache + scoring thresholds.&quot;)

# multiple testing correction within each (sRNA,model) over strata
res[, perm_p_expected_BH := p.adjust(perm_p_expected, method = &quot;BH&quot;), by=.(sRNA, model)]
res[, perm_p_two_sided_BH := p.adjust(perm_p_two_sided, method = &quot;BH&quot;), by=.(sRNA, model)]

# prioritization score that respects expected direction (only meaningful where perm_p_expected computed)
res[, score_expected := expected_activity_sign * delta_ELAC_minus_WT * (-log10(perm_p_expected_BH + 1e-300))]

# write outputs
#fwrite(res, file.path(OUT_DIR, &quot;srna_activity_moduleScore_controlMatched_72_only_correct_delta.tsv&quot;), sep = &quot;\t&quot;)
#save(res,file=&quot;G:/PhD_final/tables/srna_activity_moduleScore_controlMatched_72_only_correct_delta.RData&quot;)
#save(activity,file=&quot;G:/PhD_final/tables/srna_activity_72_only_correct_delta.RData&quot;)
# best hit per (sRNA,model) using BH directional p, then |delta|
best &lt;- res[order(perm_p_expected_BH, -abs(delta_ELAC_minus_WT))]
best &lt;- best[, .SD[1], by=.(sRNA, model)]
#fwrite(best, file.path(OUT_DIR, &quot;srna_activity_bestHit.tsv&quot;), sep = &quot;\t&quot;)

best$consistensy &lt;- ifelse(((best$ELAC&lt;best$GFP) &amp; (best$ELAC&lt;best$WT)) |
                             ((best$ELAC&gt;best$GFP) &amp; (best$ELAC&gt;best$WT)),
                           TRUE,FALSE)
best[best$consistensy==TRUE,]
#fwrite(best, file.path(OUT_DIR, &quot;srna_activity_bestHit.tsv&quot;), sep = &quot;\t&quot;)
best[best$sRNA==&quot;GCATCGGTGGTTCAGTGGTAGAATGCTCGCCT 5&#39;-tiRNA-Gly-GCC&quot;,]
load(&quot;G:/PhD_final/tables/srna_activity_72_only_correct_delta.RData&quot;)#activity

library(scCustomize)
result_obj


DETAILED_COLS &lt;- c(
  # --- Epidermis (blue) ---
  &quot;Early epidermal progenitor&quot;             = &quot;#ABCEDF&quot;,
  &quot;Late epidermal progenitor&quot;              = &quot;#6693C4&quot;,
  &quot;Epidermis (broad)&quot;                      = &quot;#5685BD&quot;,
  &quot;Epidermis (multiciliated)&quot;              = &quot;#3468B0&quot;,
  &quot;Epidermal progenitor (multiciliated)&quot;   = &quot;#4576B6&quot;,
  &quot;Epidermal secretory gland progenitor&quot;   = &quot;#99BFD8&quot;,
  
  # --- Eye (cyan) ---
  &quot;Eye progenitor&quot;                         = &quot;#00D3D3&quot;,
  
  # --- Intestine / immune-like (green) ---
  &quot;Basal cell&quot;                             = &quot;#D3E4BA&quot;,
  &quot;Goblet cell&quot;                            = &quot;#8DB180&quot;,
  &quot;Phagocyte (broad)&quot;                     = &quot;#497F46&quot;,
  
  
  # --- Pigment (brown) ---
  &quot;Body pigment progenitor&quot;                = &quot;#C08A5A&quot;,
  &quot;Body pigment cell&quot;                      = &quot;#8E5A3C&quot;,
  
  # --- Muscle (red) ---
  &quot;Muscle progenitor&quot;                      = &quot;#F2C7CA&quot;,
  &quot;BWM (dorsal midline)&quot;                   = &quot;#E6A3A6&quot;,
  &quot;ECM-producing muscle&quot;                   = &quot;#CC5C5D&quot;,
  &quot;Posterior pole/PCG muscle&quot;              = &quot;#C1393A&quot;,
  
  # --- Neoblasts (grey) ---
  &quot;-neoblast (broad-lineage)&quot;             = &quot;#E3E3E3&quot;,
  &quot;Muscle neoblast&quot;                        = &quot;#D5D5D5&quot;,
  &quot;Protonephridial neoblast&quot;               = &quot;#B8B8B8&quot;,
  &quot;Pharyngeal neoblast&quot;                    = &quot;#7F7F7F&quot;,
  &quot;-neoblast (intestinal-fated)&quot;          = &quot;#AAAAAA&quot;,
  &quot;-neoblast (epidermal-fated)&quot;           = &quot;#8D8D8D&quot;,
  &quot;-neoblast (neural-fated)&quot;              = &quot;#707070&quot;,
  &quot;GLIRP-1 parenchymal neoblast&quot;          = &quot;#B3B3B3&quot;,
  &quot;PGRN parenchymal neoblast&quot;             = &quot;#BEBEBE&quot;,
  &quot;FER3L-2 parenchymal neoblast&quot;          = &quot;#C7C7C7&quot;,
  
  # --- Neural lineage (violet) ---
  &quot;Neural progenitor (broad)&quot;              = &quot;#E9E4FA&quot;,
  &quot;Glutamatergic neural progenitor&quot;        = &quot;#DED5F6&quot;,
  &quot;Neuropeptidergic neural progenitor&quot;     = &quot;#D3C7F2&quot;,
  &quot;Mechanosensory neural progenitor&quot;       = &quot;#C9BAEE&quot;,
  &quot;PKD sensory neural progenitor&quot;         = &quot;#BFADE8&quot;,
  &quot;Glia&quot;                                   = &quot;#AF98D5&quot;,
  &quot;Brain branch neuron&quot;                    = &quot;#D8CCF3&quot;,
  &quot;Catecholaminergic neuron&quot;               = &quot;#CDBFEB&quot;,
  &quot;Cholinergic neuron&quot;                     = &quot;#C3B2E4&quot;,
  &quot;Glutamatergic neuron&quot;                   = &quot;#A58ACE&quot;,
  &quot;Mechanosensory neuron&quot;                  = &quot;#9171BF&quot;,
  &quot;Neuropeptidergic neuron&quot;                = &quot;#8764B8&quot;,
  &quot;PKD sensory neuron&quot;                    = &quot;#7349A9&quot;,
  &quot;Serotonergic neuron&quot;                    = &quot;#693CA2&quot;,
  
  # --- Parenchyma (sand) ---
  &quot;AQP parenchymal cell&quot;                  = &quot;#F9E29D&quot;,
  &quot;LDLRR-1 parenchymal cell&quot;              = &quot;#F3D38E&quot;,
  &quot;GLIRP-1 parenchymal progenitor&quot;        = &quot;#EDC281&quot;,
  &quot;PSAP parenchymal progenitor&quot;           = &quot;#F1D6A0&quot;,
  &quot;PSAP parenchymal cell&quot;                 = &quot;#EBB670&quot;,
  &quot;PGRN parenchymal cell&quot;                 = &quot;#EFC57F&quot;,
  &quot;FER3L-2 parenchymal progenitor&quot;        = &quot;#E8B567&quot;,
  &quot;NKX2 parenchymal progenitor&quot;           = &quot;#E39F55&quot;,
  &quot;PTF head parenchymal progenitor&quot;       = &quot;#E6A860&quot;,
  &quot;SSPO parenchymal progenitor&quot;           = &quot;#E19A51&quot;,
  &quot;SSPO parenchymal cell&quot;                 = &quot;#DD8B42&quot;,
  &quot;Abraada cell&quot;                          = &quot;#FAE8B4&quot;,
  
  # --- Pharynx (yellow) ---
  &quot;Pharyngeal epithelium&quot;                  = &quot;#FFFF00&quot;,
  &quot;Pharyngeal progenitor&quot;                  = &quot;#D9D900&quot;,
  &quot;Pharyngeal phagocytic-type cell&quot;        = &quot;#C9C900&quot;,
  
  # --- Protonephridia (wine) ---
  &quot;Protonephridial flame cell&quot;             = &quot;#874A68&quot;,
  &quot;Protonephridial tubule cell&quot;            = &quot;#87345F&quot;
)


################################################################################
# Rescaled plot_sncRNA_activity_umap
?scale_fill_gradient2
plot_sncRNA_activity_umap_rescaled &lt;- function(
    seu,
    activity,
    sid,
    model,
    focus_pops = c(&quot;Phagocyte (broad)&quot;, &quot;PGRN parenchymal cell&quot;),
    detailed_cols,
    reduction = &quot;umap.d33.nn100.md0.3&quot;,
    pop_col = &quot;final_population&quot;,
    cond_col = &quot;condition_correct&quot;,
    facet_map = NULL,
    facet_levels = NULL,
    title = NULL,
    rel_widths = c(1, 2),
    
    # palette (will be pastelized by default)
    low_col  = &quot;#A6CEE3&quot;,
    mid_col  = &quot;#FFFFFF&quot;,
    high_col = &quot;#FB9A99&quot;,
    pastelize = TRUE,
    pastel_strength = 0.2,   # 0..1, higher = lighter
    
    # point sizes
    pt_bg = 0.10,
    pt_pop = 0.25,
    pt_act = 0.55,
    
    # alphas and background
    alpha_bg = 0.45,
    alpha_act = 0.95,
    bg_col = &quot;grey88&quot;,
    
    # legends + text
    legend_dot_size = 3,
    strip_text_size = 11,
    legend_text_size  = 12,
    legend_title_size = 13,
    title_size        = 14,
    title_gap_lines   = 6,
    
    # activity visualization controls
    activity_mode = c(&quot;raw&quot;, &quot;delta_vs_ref&quot;),
    ref_condition = &quot;WT72&quot;,
    delta_within = c(&quot;pop&quot;, &quot;global&quot;),
    act_clip_q = c(0.05, 0.95),
    act_limits = NULL,
    diverging_symmetric = TRUE,
    midpoint = 0,
    
    # transform (new ggplot2 arg name is transform, not trans)
    act_transform = c(&quot;auto&quot;, &quot;identity&quot;, &quot;modulus&quot;),
    modulus_p = 0.7,
    
    # drawing style
    use_fill = FALSE,         # default FALSE to avoid dark outlines from shape 21
    outline_col = NA,         # NA removes border for shape 21
    outline_stroke = 0,
    order_by_abs = TRUE
) {
  # ---- helpers ----
  .mix_with_white &lt;- function(col, w = 0.55) {
    if (is.na(col) || !nzchar(col)) return(col)
    rgb &lt;- grDevices::col2rgb(col) / 255
    rgb2 &lt;- rgb * (1 - w) + 1 * w
    grDevices::rgb(rgb2[1], rgb2[2], rgb2[3])
  }
  
  # ---- checks ----
  stopifnot(inherits(seu, &quot;Seurat&quot;))
  stopifnot(!is.null(names(activity)))
  stopifnot(is.character(sid), length(sid) == 1)
  stopifnot(is.character(model), length(model) == 1)
  stopifnot(is.character(reduction), length(reduction) == 1)
  stopifnot(is.character(pop_col), length(pop_col) == 1)
  stopifnot(is.character(cond_col), length(cond_col) == 1)
  
  if (missing(detailed_cols) || is.null(detailed_cols)) {
    stop(&quot;Provide &#39;detailed_cols&#39; (named vector: population -&gt; color).&quot;)
  }
  if (!all(focus_pops %in% names(detailed_cols))) {
    stop(&quot;Some focus_pops are missing from names(detailed_cols): &quot;,
         paste(setdiff(focus_pops, names(detailed_cols)), collapse = &quot;, &quot;))
  }
  
  activity_mode &lt;- match.arg(activity_mode)
  delta_within  &lt;- match.arg(delta_within)
  act_transform &lt;- match.arg(act_transform)
  
  # ---- pastelize palette (reduces dark look on dense UMAPs) ----
  if (isTRUE(pastelize)) {
    w &lt;- max(0, min(1, pastel_strength))
    low_col  &lt;- .mix_with_white(low_col,  w = w)
    mid_col  &lt;- .mix_with_white(mid_col,  w = w / 2)   # keep midpoint close to white
    high_col &lt;- .mix_with_white(high_col, w = w)
  }
  
  # ---- activity column name ----
  act_col &lt;- paste0(&quot;act__&quot;, make.names(paste(sid, model, sep = &quot;__&quot;)))
  
  # ---- align activity to Seurat cells and store ----
  cells &lt;- Seurat::Cells(seu)
  act_vec &lt;- activity[cells]
  names(act_vec) &lt;- cells
  
  n_match &lt;- sum(is.finite(act_vec))
  if (n_match == 0) {
    stop(&quot;No overlap between names(activity) and Cells(seu). &quot;,
         &quot;Check: head(names(activity)) vs head(Cells(seu)).&quot;)
  }
  seu[[act_col]] &lt;- act_vec
  
  # ---- embeddings ----
  if (!reduction %in% names(seu@reductions)) {
    stop(&quot;Reduction &#39;&quot;, reduction, &quot;&#39; not found. Available: &quot;,
         paste(names(seu@reductions), collapse = &quot;, &quot;))
  }
  um &lt;- Seurat::Embeddings(seu, reduction = reduction)[, 1:2, drop = FALSE]
  colnames(um) &lt;- c(&quot;UMAP_1&quot;, &quot;UMAP_2&quot;)
  
  df &lt;- data.table::as.data.table(um, keep.rownames = &quot;cell&quot;)
  
  meta &lt;- Seurat::FetchData(seu, vars = c(pop_col, cond_col, act_col))
  meta$cell &lt;- rownames(meta)
  
  df &lt;- data.table::merge.data.table(
    df,
    data.table::as.data.table(meta),
    by = &quot;cell&quot;
  )
  
  data.table::setnames(df, pop_col, &quot;pop&quot;)
  data.table::setnames(df, cond_col, &quot;cond&quot;)
  data.table::setnames(df, act_col, &quot;activity_raw&quot;)
  
  # ---- facet labels (plotmath strings) ----
  if (is.null(facet_map)) {
    facet_map &lt;- c(
      &quot;ELAC72&quot; = &quot;paste(italic(&#39;Smed ELAC2&#39;), &#39; KD 72 hpa&#39;)&quot;,
      &quot;GFP72&quot;  = &quot;&#39;GFP mock 72 hpa&#39;&quot;,
      &quot;WT72&quot;   = &quot;&#39;WT 72 hpa&#39;&quot;
    )
  }
  
  df[, condition_facet := {
    cc &lt;- as.character(cond)
    out &lt;- unname(facet_map[cc])
    out[is.na(out)] &lt;- shQuote(cc[is.na(out)])
    out
  }]
  
  if (is.null(facet_levels)) {
    base_levels &lt;- unname(facet_map)
    extras &lt;- setdiff(unique(df$condition_facet), base_levels)
    facet_levels &lt;- c(base_levels, extras)
  }
  df[, condition_facet := factor(condition_facet, levels = facet_levels)]
  
  # ---- focus flags ----
  df[, is_focus := pop %in% focus_pops]
  
  # ---- compute activity to plot (raw or delta) ----
  df[, activity_plot := as.numeric(NA)]
  df[is_focus == TRUE, activity_plot := activity_raw]
  
  df_focus &lt;- df[is_focus == TRUE &amp; is.finite(activity_plot)]
  if (nrow(df_focus) == 0) stop(&quot;No finite activity values found within focus_pops.&quot;)
  
  if (activity_mode == &quot;delta_vs_ref&quot;) {
    if (!ref_condition %in% unique(df$cond)) {
      stop(&quot;ref_condition &#39;&quot;, ref_condition, &quot;&#39; not found in cond. Present: &quot;,
           paste(sort(unique(df$cond)), collapse = &quot;, &quot;))
    }
    
    ref_dt &lt;- df[is_focus == TRUE &amp; cond == ref_condition &amp; is.finite(activity_plot)]
    if (nrow(ref_dt) == 0) {
      stop(&quot;No finite focus activity values in ref_condition = &#39;&quot;, ref_condition, &quot;&#39;.&quot;)
    }
    
    if (delta_within == &quot;pop&quot;) {
      base &lt;- ref_dt[, .(baseline = stats::median(activity_plot, na.rm = TRUE)), by = pop]
      df &lt;- data.table::merge.data.table(df, base, by = &quot;pop&quot;, all.x = TRUE)
      df[is_focus == TRUE &amp; is.finite(activity_plot), activity_plot := activity_plot - baseline]
      df[, baseline := NULL]
    } else {
      baseline &lt;- stats::median(ref_dt$activity_plot, na.rm = TRUE)
      df[is_focus == TRUE &amp; is.finite(activity_plot), activity_plot := activity_plot - baseline]
    }
    
    df_focus &lt;- df[is_focus == TRUE &amp; is.finite(activity_plot)]
  }
  
  # ---- order so extremes draw on top ----
  if (order_by_abs) df_focus &lt;- df_focus[order(abs(activity_plot))]
  
  # ---- robust limits (clip + squish) ----
  vals &lt;- df_focus$activity_plot
  
  if (!is.null(act_limits)) {
    if (!is.numeric(act_limits) || length(act_limits) != 2) {
      stop(&quot;act_limits must be numeric length 2, e.g. c(-0.2, 0.2).&quot;)
    }
    lims &lt;- sort(as.numeric(act_limits))
  } else {
    qq &lt;- stats::quantile(vals, probs = act_clip_q, na.rm = TRUE, names = FALSE)
    lims &lt;- sort(as.numeric(qq))
  }
  
  if (diverging_symmetric) {
    max_abs &lt;- max(abs(lims - midpoint))
    lims &lt;- midpoint + c(-max_abs, max_abs)
  }
  
  # ---- pick transform object ----
  act_transform_obj &lt;- switch(
    act_transform,
    &quot;identity&quot; = &quot;identity&quot;,
    &quot;modulus&quot;  = scales::transform_modulus(p = modulus_p),
    &quot;auto&quot;     = if (activity_mode == &quot;delta_vs_ref&quot;) scales::transform_modulus(p = modulus_p) else &quot;identity&quot;
  )
  
  # ---- right panel background data ----
  df_nonfocus &lt;- df[is_focus == FALSE]
  df_focus_na &lt;- df[is_focus == TRUE &amp; !is.finite(activity_plot)]
  
  # ---- left: highlight focus pops ----
  p_left &lt;- ggplot2::ggplot(df, ggplot2::aes(UMAP_1, UMAP_2)) +
    ggplot2::geom_point(color = bg_col, size = pt_bg, alpha = alpha_bg) +
    ggplot2::geom_point(
      data = df[df$pop %in% focus_pops],
      ggplot2::aes(color = pop),
      size = pt_pop,
      alpha = 1
    ) +
    ggplot2::scale_color_manual(
      values = detailed_cols[focus_pops],
      breaks = focus_pops,
      name = &quot;Population&quot;
    ) +
    ggplot2::guides(
      color = ggplot2::guide_legend(override.aes = list(size = legend_dot_size, alpha = 1))
    ) +
    ggplot2::theme_void() +
    ggplot2::theme(
      legend.position = &quot;right&quot;,
      legend.title = ggplot2::element_text(size = legend_title_size),
      legend.text  = ggplot2::element_text(size = legend_text_size),
      text = ggplot2::element_text(size = 11)
    )
  
  # ---- right: non-focus grey, focus colored by activity_plot ----
  scale_name &lt;- if (activity_mode == &quot;delta_vs_ref&quot;) &quot; Activity&quot; else &quot;Activity&quot;
  
  if (use_fill) {
    p_right &lt;- ggplot2::ggplot(df, ggplot2::aes(UMAP_1, UMAP_2)) +
      ggplot2::geom_point(data = df_nonfocus, color = bg_col, size = pt_bg, alpha = alpha_bg) +
      ggplot2::geom_point(data = df_focus_na, color = bg_col, size = pt_bg, alpha = alpha_bg) +
      ggplot2::geom_point(
        data = df_focus,
        ggplot2::aes(fill = activity_plot),
        shape = 21,
        color = outline_col,
        stroke = outline_stroke,
        size = pt_act,
        alpha = alpha_act
      ) +
      ggplot2::scale_fill_gradient2(
        name = scale_name,
        low = low_col, mid = mid_col, high = high_col,
        midpoint = midpoint,
        limits = lims,
        oob = scales::squish,
        transform = act_transform_obj
      ) +
      ggplot2::facet_wrap(~ condition_facet, nrow = 1, labeller = ggplot2::label_parsed) +
      ggplot2::theme_void() +
      ggplot2::theme(
        plot.margin = ggplot2::margin(t = 0, r = 18, b = 0, l = 0),  # more space on the right
        legend.box.margin = ggplot2::margin(t = 0, r = 6, b = 0, l = 6),
        legend.title = ggplot2::element_text(size = legend_title_size),
        legend.text  = ggplot2::element_text(size = legend_text_size),
        strip.text   = ggplot2::element_text(size = strip_text_size)
      )
      # ggplot2::theme(
      #   legend.position = &quot;right&quot;,
      #   legend.title = ggplot2::element_text(size = legend_title_size),
      #   legend.text  = ggplot2::element_text(size = legend_text_size),
      #   strip.text   = ggplot2::element_text(size = strip_text_size)
      # )
  } else {
    p_right &lt;- ggplot2::ggplot(df, ggplot2::aes(UMAP_1, UMAP_2)) +
      ggplot2::geom_point(data = df_nonfocus, color = bg_col, size = pt_bg, alpha = alpha_bg) +
      ggplot2::geom_point(data = df_focus_na, color = bg_col, size = pt_bg, alpha = alpha_bg) +
      ggplot2::geom_point(
        data = df_focus,
        ggplot2::aes(color = activity_plot),
        size = pt_act,
        alpha = alpha_act
      ) +
      ggplot2::scale_color_gradient2(
        name = scale_name,
        low = low_col, mid = mid_col, high = high_col,
        midpoint = midpoint,
        limits = lims,
        oob = scales::squish,
        transform = act_transform_obj
      ) +
      ggplot2::facet_wrap(~ condition_facet, nrow = 1, labeller = ggplot2::label_parsed) +
      ggplot2::theme_void() +
      # ggplot2::theme(
      #   legend.position = &quot;right&quot;,
      #   legend.title = ggplot2::element_text(size = legend_title_size),
      #   legend.text  = ggplot2::element_text(size = legend_text_size),
      #   strip.text   = ggplot2::element_text(size = strip_text_size)
      # )
      ggplot2::theme(
        plot.margin = ggplot2::margin(t = 0, r = 18, b = 0, l = 0),  # more space on the right
        legend.box.margin = ggplot2::margin(t = 0, r = 6, b = 0, l = 6),
        legend.title = ggplot2::element_text(size = legend_title_size),
        legend.text  = ggplot2::element_text(size = legend_text_size),
        strip.text   = ggplot2::element_text(size = strip_text_size)
      )
  }
  
  # ---- combine + title ----
  core &lt;- cowplot::plot_grid(
    p_left, p_right,
    ncol = 2,
    rel_widths = rel_widths,
    align = &quot;h&quot;
  )
  
  if (is.null(title)) title &lt;- paste0(sid, &quot; | &quot;, model)
  
  title_grob &lt;- cowplot::ggdraw() +
    cowplot::draw_label(
      title,
      x = 0.05, y = 1,
      hjust = 0, vjust = 1.25,
      fontface = &quot;bold&quot;,
      size = title_size
    ) +
    ggplot2::theme(
      plot.margin = ggplot2::margin(t = 0, r = 0, b = title_gap_lines, l = 0)
    )
  
  final &lt;- cowplot::plot_grid(
    title_grob,
    core,
    ncol = 1,
    rel_heights = c(0.10, 1)
  )
  
  list(
    plot = final,
    p_left = p_left,
    p_right = p_right,
    act_col = act_col,
    df = df,
    df_focus = df_focus,
    seu = seu,
    activity_limits = lims,
    activity_mode = activity_mode,
    ref_condition = ref_condition,
    act_transform = act_transform_obj
  )
}

out1 &lt;- plot_sncRNA_activity_umap_rescaled(
  seu = seu_use,
  activity = activity,
  sid = &quot;GCATCGGTGGTTCAGTGGTAGAATGCTCGCCT 5&#39;-tiRNA-Gly-GCC&quot;,
  model = &quot;miRNA_canonical&quot;,
  focus_pops = c(&quot;PGRN parenchymal cell&quot;, &quot;Phagocyte (broad)&quot;),
  detailed_cols = DETAILED_COLS,
  title = &quot;5&#39;-tiRNA-Gly-GCC (GCATCGGTGGTTCAGTGGTAGAATGCTCGCCT)&quot;,
  activity_mode = &quot;delta_vs_ref&quot;,
  ref_condition = &quot;WT72&quot;,
  delta_within = &quot;pop&quot;,
  act_clip_q = c(0.10, 0.90),
  low_col = &quot;blue&quot;,
  high_col = &quot;red&quot;,
  mid_col = &quot;white&quot;
)
#out1_new$plot



out2 &lt;- plot_sncRNA_activity_umap_rescaled(
  seu = seu_use,
  activity = activity,
  sid = &quot;TCTTTGGTTTTCTAGC sme-miR-9a-5p&quot;,
  model = &quot;off1_7mer&quot;,
  focus_pops = c(&quot;Glutamatergic neuron&quot;),
  detailed_cols = DETAILED_COLS,
  title = &quot;miR-9a-5p (TCTTTGGTTTTCTAGC)&quot;,
  activity_mode = &quot;delta_vs_ref&quot;,
  ref_condition = &quot;WT72&quot;,
  delta_within = &quot;pop&quot;,
  act_clip_q = c(0.10, 0.90),
  low_col = &quot;blue&quot;,
  high_col = &quot;red&quot;,
  mid_col = &quot;white&quot;
)


out4 &lt;- plot_sncRNA_activity_umap_rescaled(
  seu = seu_use,
  activity = activity,
  sid = &quot;CACATGACATGTATACTCTACAAACGCAC piRNA&quot;,
  model = &quot;piRNA_extended&quot;,
  focus_pops = c(&quot;-neoblast (epidermal-fated)&quot;),
  detailed_cols = DETAILED_COLS,
  title = &quot;piRNA (CACATGACATGTATACTCTACAAACGCAC)&quot;,
  activity_mode = &quot;delta_vs_ref&quot;,
  ref_condition = &quot;WT72&quot;,
  delta_within = &quot;pop&quot;,
  act_clip_q = c(0.10, 0.90),
  low_col = &quot;blue&quot;,
  high_col = &quot;red&quot;,
  mid_col = &quot;white&quot;
)

out3 &lt;- plot_sncRNA_activity_umap_rescaled(
  seu = seu_use,
  activity = activity,
  sid = &quot;ACCACTGACCGAGCATATCC sme-miR-190a-3p&quot;,
  model = &quot;off1_7mer&quot;,
  focus_pops = c(&quot;Late epidermal progenitor&quot;),
  detailed_cols = DETAILED_COLS,
  title = &quot;miR-190a-3p (ACCACTGACCGAGCATATCC)&quot;,
  activity_mode = &quot;delta_vs_ref&quot;,
  ref_condition = &quot;WT72&quot;,
  delta_within = &quot;pop&quot;,
  act_clip_q = c(0.10, 0.90),
  low_col = &quot;blue&quot;,
  high_col = &quot;red&quot;,
  mid_col = &quot;white&quot;
)


library(ggpubr)
ggarrange(out1$plot,
          out2$plot,
          out3$plot,
          out4$plot,
          ncol = 1,
          labels = c(&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;),
          common.legend = TRUE)
</code></pre>
</div>
</div>



</div>
</div>

</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open');
  });
});
</script>

<!-- code folding -->

<script>
$(document).ready(function ()  {

    // temporarily add toc-ignore selector to headers for the consistency with Pandoc
    $('.unlisted.unnumbered').addClass('toc-ignore')

    // move toc-ignore selectors from section div to header
    $('div.section.toc-ignore')
        .removeClass('toc-ignore')
        .children('h1,h2,h3,h4,h5').addClass('toc-ignore');

    // establish options
    var options = {
      selectors: "h1,h2,h3",
      theme: "bootstrap3",
      context: '.toc-content',
      hashGenerator: function (text) {
        return text.replace(/[.\\/?&!#<>]/g, '').replace(/\s/g, '_');
      },
      ignoreSelector: ".toc-ignore",
      scrollTo: 0
    };
    options.showAndHide = true;
    options.smoothScroll = true;

    // tocify
    var toc = $("#TOC").tocify(options).data("toc-tocify");
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
